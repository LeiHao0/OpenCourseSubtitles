1
00:00:00,030 --> 00:00:03,860

welcome to MIT course 6 s 0 9 9

2
00:00:03,860 --> 00:00:03,870
welcome to MIT course 6 s 0 9 9
 

3
00:00:03,870 --> 00:00:07,460
welcome to MIT course 6 s 0 9 9
artificial general intelligence today we

4
00:00:07,460 --> 00:00:07,470
artificial general intelligence today we
 

5
00:00:07,470 --> 00:00:10,610
artificial general intelligence today we
have Ray Kurzweil he is one of the

6
00:00:10,610 --> 00:00:10,620
have Ray Kurzweil he is one of the
 

7
00:00:10,620 --> 00:00:12,499
have Ray Kurzweil he is one of the
world's leading inventors thinkers and

8
00:00:12,499 --> 00:00:12,509
world's leading inventors thinkers and
 

9
00:00:12,509 --> 00:00:15,110
world's leading inventors thinkers and
futurists with a 30-year track record of

10
00:00:15,110 --> 00:00:15,120
futurists with a 30-year track record of
 

11
00:00:15,120 --> 00:00:17,689
futurists with a 30-year track record of
accurate predictions called the Restless

12
00:00:17,689 --> 00:00:17,699
accurate predictions called the Restless
 

13
00:00:17,699 --> 00:00:19,460
accurate predictions called the Restless
genius by The Wall Street Journal and

14
00:00:19,460 --> 00:00:19,470
genius by The Wall Street Journal and
 

15
00:00:19,470 --> 00:00:21,470
genius by The Wall Street Journal and
the ultimate thinking machine by Forbes

16
00:00:21,470 --> 00:00:21,480
the ultimate thinking machine by Forbes
 

17
00:00:21,480 --> 00:00:24,650
the ultimate thinking machine by Forbes
magazine he was selected as one of the

18
00:00:24,650 --> 00:00:24,660
magazine he was selected as one of the
 

19
00:00:24,660 --> 00:00:27,200
magazine he was selected as one of the
top entrepreneurs by Inc magazine which

20
00:00:27,200 --> 00:00:27,210
top entrepreneurs by Inc magazine which
 

21
00:00:27,210 --> 00:00:29,359
top entrepreneurs by Inc magazine which
described him as the rightful heir to

22
00:00:29,359 --> 00:00:29,369
described him as the rightful heir to
 

23
00:00:29,369 --> 00:00:32,840
described him as the rightful heir to
Thomas Edison PBS selected him as one of

24
00:00:32,840 --> 00:00:32,850
Thomas Edison PBS selected him as one of
 

25
00:00:32,850 --> 00:00:36,010
Thomas Edison PBS selected him as one of
the 16 revolutionaries who made America

26
00:00:36,010 --> 00:00:36,020
the 16 revolutionaries who made America
 

27
00:00:36,020 --> 00:00:38,959
the 16 revolutionaries who made America
Ray was the principal investigator of

28
00:00:38,959 --> 00:00:38,969
Ray was the principal investigator of
 

29
00:00:38,969 --> 00:00:41,389
Ray was the principal investigator of
the first ccd flatbed scanner the first

30
00:00:41,389 --> 00:00:41,399
the first ccd flatbed scanner the first
 

31
00:00:41,399 --> 00:00:43,549
the first ccd flatbed scanner the first
omni font optical character recognition

32
00:00:43,549 --> 00:00:43,559
omni font optical character recognition
 

33
00:00:43,559 --> 00:00:45,619
omni font optical character recognition
the first point to speech reading

34
00:00:45,619 --> 00:00:45,629
the first point to speech reading
 

35
00:00:45,629 --> 00:00:47,060
the first point to speech reading
machines for the blind the first

36
00:00:47,060 --> 00:00:47,070
machines for the blind the first
 

37
00:00:47,070 --> 00:00:49,430
machines for the blind the first
text-to-speech synthesizer the first

38
00:00:49,430 --> 00:00:49,440
text-to-speech synthesizer the first
 

39
00:00:49,440 --> 00:00:51,740
text-to-speech synthesizer the first
music synthesizer capable of creating

40
00:00:51,740 --> 00:00:51,750
music synthesizer capable of creating
 

41
00:00:51,750 --> 00:00:54,139
music synthesizer capable of creating
the grand piano and other orchestral

42
00:00:54,139 --> 00:00:54,149
the grand piano and other orchestral
 

43
00:00:54,149 --> 00:00:56,090
the grand piano and other orchestral
instruments and the first commercially

44
00:00:56,090 --> 00:00:56,100
instruments and the first commercially
 

45
00:00:56,100 --> 00:00:57,889
instruments and the first commercially
marketed large vocabulary speech

46
00:00:57,889 --> 00:00:57,899
marketed large vocabulary speech
 

47
00:00:57,899 --> 00:01:00,650
marketed large vocabulary speech
recognition among his many honors he

48
00:01:00,650 --> 00:01:00,660
recognition among his many honors he
 

49
00:01:00,660 --> 00:01:03,229
recognition among his many honors he
received a Grammy Award for outstanding

50
00:01:03,229 --> 00:01:03,239
received a Grammy Award for outstanding
 

51
00:01:03,239 --> 00:01:05,119
received a Grammy Award for outstanding
achievements in music technology he's

52
00:01:05,119 --> 00:01:05,129
achievements in music technology he's
 

53
00:01:05,129 --> 00:01:06,770
achievements in music technology he's
the recipient of the National Medal of

54
00:01:06,770 --> 00:01:06,780
the recipient of the National Medal of
 

55
00:01:06,780 --> 00:01:08,780
the recipient of the National Medal of
Technology was inducted into the

56
00:01:08,780 --> 00:01:08,790
Technology was inducted into the
 

57
00:01:08,790 --> 00:01:11,840
Technology was inducted into the
National Inventors Hall of Fame holds 21

58
00:01:11,840 --> 00:01:11,850
National Inventors Hall of Fame holds 21
 

59
00:01:11,850 --> 00:01:14,420
National Inventors Hall of Fame holds 21
honorary doctorates and honors from

60
00:01:14,420 --> 00:01:14,430
honorary doctorates and honors from
 

61
00:01:14,430 --> 00:01:17,810
honorary doctorates and honors from
three u.s. presidents Ray has written

62
00:01:17,810 --> 00:01:17,820
three u.s. presidents Ray has written
 

63
00:01:17,820 --> 00:01:20,620
three u.s. presidents Ray has written
five national best-selling books

64
00:01:20,620 --> 00:01:20,630
five national best-selling books
 

65
00:01:20,630 --> 00:01:23,060
five national best-selling books
including the New York Times bestsellers

66
00:01:23,060 --> 00:01:23,070
including the New York Times bestsellers
 

67
00:01:23,070 --> 00:01:25,460
including the New York Times bestsellers
The Singularity is near from 2005 and

68
00:01:25,460 --> 00:01:25,470
The Singularity is near from 2005 and
 

69
00:01:25,470 --> 00:01:29,060
The Singularity is near from 2005 and
how to create a mind from 2012 he is

70
00:01:29,060 --> 00:01:29,070
how to create a mind from 2012 he is
 

71
00:01:29,070 --> 00:01:31,910
how to create a mind from 2012 he is
co-founder and Chancellor of singularity

72
00:01:31,910 --> 00:01:31,920
co-founder and Chancellor of singularity
 

73
00:01:31,920 --> 00:01:34,039
co-founder and Chancellor of singularity
University and a director of engineering

74
00:01:34,039 --> 00:01:34,049
University and a director of engineering
 

75
00:01:34,049 --> 00:01:37,340
University and a director of engineering
at Google heading up a team developing

76
00:01:37,340 --> 00:01:37,350
at Google heading up a team developing
 

77
00:01:37,350 --> 00:01:39,200
at Google heading up a team developing
machine intelligence and natural

78
00:01:39,200 --> 00:01:39,210
machine intelligence and natural
 

79
00:01:39,210 --> 00:01:40,249
machine intelligence and natural
language understanding

80
00:01:40,249 --> 00:01:40,259
language understanding
 

81
00:01:40,259 --> 00:01:42,470
language understanding
please give ray a warm welcome

82
00:01:42,470 --> 00:01:42,480
please give ray a warm welcome
 

83
00:01:42,480 --> 00:01:43,660
please give ray a warm welcome
[Applause]

84
00:01:43,660 --> 00:01:43,670
[Applause]
 

85
00:01:43,670 --> 00:01:49,069
[Applause]
[Music]

86
00:01:49,069 --> 00:01:49,079

 

87
00:01:49,079 --> 00:01:53,550

it's good to be back I've been in this

88
00:01:53,550 --> 00:01:53,560
it's good to be back I've been in this
 

89
00:01:53,560 --> 00:01:56,520
it's good to be back I've been in this
lecture hall many times and walked the

90
00:01:56,520 --> 00:01:56,530
lecture hall many times and walked the
 

91
00:01:56,530 --> 00:01:59,819
lecture hall many times and walked the
infinite Carter I came here as an

92
00:01:59,819 --> 00:01:59,829
infinite Carter I came here as an
 

93
00:01:59,829 --> 00:02:04,139
infinite Carter I came here as an
undergraduate in 1965 within a year of

94
00:02:04,139 --> 00:02:04,149
undergraduate in 1965 within a year of
 

95
00:02:04,149 --> 00:02:06,559
undergraduate in 1965 within a year of
my being here they started a new major

96
00:02:06,559 --> 00:02:06,569
my being here they started a new major
 

97
00:02:06,569 --> 00:02:11,100
my being here they started a new major
called computer science it did not get

98
00:02:11,100 --> 00:02:11,110
called computer science it did not get
 

99
00:02:11,110 --> 00:02:15,300
called computer science it did not get
its own course number that's 6 1 even

100
00:02:15,300 --> 00:02:15,310
its own course number that's 6 1 even
 

101
00:02:15,310 --> 00:02:17,190
its own course number that's 6 1 even
biotechnology recently got its own

102
00:02:17,190 --> 00:02:17,200
biotechnology recently got its own
 

103
00:02:17,200 --> 00:02:19,890
biotechnology recently got its own
course number but how many of you are CS

104
00:02:19,890 --> 00:02:19,900
course number but how many of you are CS
 

105
00:02:19,900 --> 00:02:24,539
course number but how many of you are CS
majors ok how many of you do work in

106
00:02:24,539 --> 00:02:24,549
majors ok how many of you do work in
 

107
00:02:24,549 --> 00:02:28,319
majors ok how many of you do work in
deep learning how many of you have heard

108
00:02:28,319 --> 00:02:28,329
deep learning how many of you have heard
 

109
00:02:28,329 --> 00:02:33,410
deep learning how many of you have heard
of deep learning here I came here first

110
00:02:33,410 --> 00:02:33,420
of deep learning here I came here first
 

111
00:02:33,420 --> 00:02:39,420
of deep learning here I came here first
in 1952 when I was 14 I became excited

112
00:02:39,420 --> 00:02:39,430
in 1952 when I was 14 I became excited
 

113
00:02:39,430 --> 00:02:42,539
in 1952 when I was 14 I became excited
about artificial intelligence it had

114
00:02:42,539 --> 00:02:42,549
about artificial intelligence it had
 

115
00:02:42,549 --> 00:02:45,270
about artificial intelligence it had
only gotten its name six years earlier

116
00:02:45,270 --> 00:02:45,280
only gotten its name six years earlier
 

117
00:02:45,280 --> 00:02:50,069
only gotten its name six years earlier
the 1956 Dartmouth conference by Marvin

118
00:02:50,069 --> 00:02:50,079
the 1956 Dartmouth conference by Marvin
 

119
00:02:50,079 --> 00:02:53,840
the 1956 Dartmouth conference by Marvin
Minsky and John McCarthy so I wrote

120
00:02:53,840 --> 00:02:53,850
Minsky and John McCarthy so I wrote
 

121
00:02:53,850 --> 00:02:57,629
Minsky and John McCarthy so I wrote
Minsky a letter there was no email back

122
00:02:57,629 --> 00:02:57,639
Minsky a letter there was no email back
 

123
00:02:57,639 --> 00:03:00,990
Minsky a letter there was no email back
then and he invited me up he spent all

124
00:03:00,990 --> 00:03:01,000
then and he invited me up he spent all
 

125
00:03:01,000 --> 00:03:02,610
then and he invited me up he spent all
day with me as if he had nothing else to

126
00:03:02,610 --> 00:03:02,620
day with me as if he had nothing else to
 

127
00:03:02,620 --> 00:03:07,040
day with me as if he had nothing else to
do he was a consummate educator

128
00:03:07,040 --> 00:03:07,050
do he was a consummate educator
 

129
00:03:07,050 --> 00:03:10,700
do he was a consummate educator
I then and the AI field had already

130
00:03:10,700 --> 00:03:10,710
I then and the AI field had already
 

131
00:03:10,710 --> 00:03:14,330
I then and the AI field had already
bifurcated into two warring camps the

132
00:03:14,330 --> 00:03:14,340
bifurcated into two warring camps the
 

133
00:03:14,340 --> 00:03:16,390
bifurcated into two warring camps the
symbolic school which Minsk II was

134
00:03:16,390 --> 00:03:16,400
symbolic school which Minsk II was
 

135
00:03:16,400 --> 00:03:19,970
symbolic school which Minsk II was
associated with and the connectionist

136
00:03:19,970 --> 00:03:19,980
associated with and the connectionist
 

137
00:03:19,980 --> 00:03:23,060
associated with and the connectionist
school was not widely known in fact I

138
00:03:23,060 --> 00:03:23,070
school was not widely known in fact I
 

139
00:03:23,070 --> 00:03:24,440
school was not widely known in fact I
think it's still not widely known that

140
00:03:24,440 --> 00:03:24,450
think it's still not widely known that
 

141
00:03:24,450 --> 00:03:26,810
think it's still not widely known that
Minsk II actually invented the neural

142
00:03:26,810 --> 00:03:26,820
Minsk II actually invented the neural
 

143
00:03:26,820 --> 00:03:30,830
Minsk II actually invented the neural
net in 1953 but he had become negative

144
00:03:30,830 --> 00:03:30,840
net in 1953 but he had become negative
 

145
00:03:30,840 --> 00:03:33,140
net in 1953 but he had become negative
about it largely because there was a lot

146
00:03:33,140 --> 00:03:33,150
about it largely because there was a lot
 

147
00:03:33,150 --> 00:03:36,140
about it largely because there was a lot
of hype that these giant branes could

148
00:03:36,140 --> 00:03:36,150
of hype that these giant branes could
 

149
00:03:36,150 --> 00:03:38,200
of hype that these giant branes could
solve any problem

150
00:03:38,200 --> 00:03:38,210
solve any problem
 

151
00:03:38,210 --> 00:03:42,470
solve any problem
so the first popular neural nets the

152
00:03:42,470 --> 00:03:42,480
so the first popular neural nets the
 

153
00:03:42,480 --> 00:03:46,580
so the first popular neural nets the
perceptron was being promulgated by

154
00:03:46,580 --> 00:03:46,590
perceptron was being promulgated by
 

155
00:03:46,590 --> 00:03:49,880
perceptron was being promulgated by
Frank Rosenblatt at Cornell so Minsky

156
00:03:49,880 --> 00:03:49,890
Frank Rosenblatt at Cornell so Minsky
 

157
00:03:49,890 --> 00:03:50,810
Frank Rosenblatt at Cornell so Minsky
set out what are you going now and

158
00:03:50,810 --> 00:03:50,820
set out what are you going now and
 

159
00:03:50,820 --> 00:03:54,650
set out what are you going now and
saying I said to see Rosenblatt at core

160
00:03:54,650 --> 00:03:54,660
saying I said to see Rosenblatt at core
 

161
00:03:54,660 --> 00:03:56,620
saying I said to see Rosenblatt at core
now is that don't bother doing that and

162
00:03:56,620 --> 00:03:56,630
now is that don't bother doing that and
 

163
00:03:56,630 --> 00:04:01,190
now is that don't bother doing that and
I went there and Rosenblatt was touting

164
00:04:01,190 --> 00:04:01,200
I went there and Rosenblatt was touting
 

165
00:04:01,200 --> 00:04:03,020
I went there and Rosenblatt was touting
the perceptron that it ultimately would

166
00:04:03,020 --> 00:04:03,030
the perceptron that it ultimately would
 

167
00:04:03,030 --> 00:04:06,080
the perceptron that it ultimately would
be able to solve any problem so I

168
00:04:06,080 --> 00:04:06,090
be able to solve any problem so I
 

169
00:04:06,090 --> 00:04:07,460
be able to solve any problem so I
brought some printed letters that had

170
00:04:07,460 --> 00:04:07,470
brought some printed letters that had
 

171
00:04:07,470 --> 00:04:09,290
brought some printed letters that had
the camera and it did a perfect job of

172
00:04:09,290 --> 00:04:09,300
the camera and it did a perfect job of
 

173
00:04:09,300 --> 00:04:11,570
the camera and it did a perfect job of
recognizing them as long as they were

174
00:04:11,570 --> 00:04:11,580
recognizing them as long as they were
 

175
00:04:11,580 --> 00:04:15,470
recognizing them as long as they were
courier ten different types I didn't

176
00:04:15,470 --> 00:04:15,480
courier ten different types I didn't
 

177
00:04:15,480 --> 00:04:17,780
courier ten different types I didn't
work at all and he said but don't worry

178
00:04:17,780 --> 00:04:17,790
work at all and he said but don't worry
 

179
00:04:17,790 --> 00:04:20,420
work at all and he said but don't worry
we can take the output of the perceptron

180
00:04:20,420 --> 00:04:20,430
we can take the output of the perceptron
 

181
00:04:20,430 --> 00:04:21,590
we can take the output of the perceptron
or feed it as the input to another

182
00:04:21,590 --> 00:04:21,600
or feed it as the input to another
 

183
00:04:21,600 --> 00:04:23,540
or feed it as the input to another
perceptron and take the output of that

184
00:04:23,540 --> 00:04:23,550
perceptron and take the output of that
 

185
00:04:23,550 --> 00:04:25,850
perceptron and take the output of that
and feed it to a third layer and as we

186
00:04:25,850 --> 00:04:25,860
and feed it to a third layer and as we
 

187
00:04:25,860 --> 00:04:27,530
and feed it to a third layer and as we
add more layers it'll get smarter and

188
00:04:27,530 --> 00:04:27,540
add more layers it'll get smarter and
 

189
00:04:27,540 --> 00:04:30,470
add more layers it'll get smarter and
smarter and generalize and so that's

190
00:04:30,470 --> 00:04:30,480
smarter and generalize and so that's
 

191
00:04:30,480 --> 00:04:32,060
smarter and generalize and so that's
interesting if you even tried that well

192
00:04:32,060 --> 00:04:32,070
interesting if you even tried that well
 

193
00:04:32,070 --> 00:04:34,450
interesting if you even tried that well
no but it's high on our research agenda

194
00:04:34,450 --> 00:04:34,460
no but it's high on our research agenda
 

195
00:04:34,460 --> 00:04:37,360
no but it's high on our research agenda
things did not move quite as quickly

196
00:04:37,360 --> 00:04:37,370
things did not move quite as quickly
 

197
00:04:37,370 --> 00:04:40,280
things did not move quite as quickly
back then as they do now he died nine

198
00:04:40,280 --> 00:04:40,290
back then as they do now he died nine
 

199
00:04:40,290 --> 00:04:43,330
back then as they do now he died nine
years later never having tried that idea

200
00:04:43,330 --> 00:04:43,340
years later never having tried that idea
 

201
00:04:43,340 --> 00:04:46,040
years later never having tried that idea
turns out to be remarkably prescient I

202
00:04:46,040 --> 00:04:46,050
turns out to be remarkably prescient I
 

203
00:04:46,050 --> 00:04:48,230
turns out to be remarkably prescient I
mean he never tried multi-layer neural

204
00:04:48,230 --> 00:04:48,240
mean he never tried multi-layer neural
 

205
00:04:48,240 --> 00:04:51,170
mean he never tried multi-layer neural
nets and all the excitement we see now

206
00:04:51,170 --> 00:04:51,180
nets and all the excitement we see now
 

207
00:04:51,180 --> 00:04:56,390
nets and all the excitement we see now
about deep learning comes from a

208
00:04:56,390 --> 00:04:56,400
about deep learning comes from a
 

209
00:04:56,400 --> 00:04:59,470
about deep learning comes from a
combination of two things

210
00:04:59,470 --> 00:04:59,480
combination of two things
 

211
00:04:59,480 --> 00:05:03,190
combination of two things
both many layer neural Nets and the law

212
00:05:03,190 --> 00:05:03,200
both many layer neural Nets and the law
 

213
00:05:03,200 --> 00:05:05,380
both many layer neural Nets and the law
of accelerating returns which I'll get

214
00:05:05,380 --> 00:05:05,390
of accelerating returns which I'll get
 

215
00:05:05,390 --> 00:05:08,050
of accelerating returns which I'll get
to a little bit later which is basically

216
00:05:08,050 --> 00:05:08,060
to a little bit later which is basically
 

217
00:05:08,060 --> 00:05:10,600
to a little bit later which is basically
the exponential growth of computing so

218
00:05:10,600 --> 00:05:10,610
the exponential growth of computing so
 

219
00:05:10,610 --> 00:05:12,670
the exponential growth of computing so
that we can run these massive nets and

220
00:05:12,670 --> 00:05:12,680
that we can run these massive nets and
 

221
00:05:12,680 --> 00:05:17,800
that we can run these massive nets and
handle massive amounts of data it would

222
00:05:17,800 --> 00:05:17,810
handle massive amounts of data it would
 

223
00:05:17,810 --> 00:05:21,480
handle massive amounts of data it would
be decades before that idea was tried

224
00:05:21,480 --> 00:05:21,490
be decades before that idea was tried
 

225
00:05:21,490 --> 00:05:24,160
be decades before that idea was tried
several decades later three level neural

226
00:05:24,160 --> 00:05:24,170
several decades later three level neural
 

227
00:05:24,170 --> 00:05:25,570
several decades later three level neural
nets were tried there were a little bit

228
00:05:25,570 --> 00:05:25,580
nets were tried there were a little bit
 

229
00:05:25,580 --> 00:05:26,740
nets were tried there were a little bit
better they could deal with multiple

230
00:05:26,740 --> 00:05:26,750
better they could deal with multiple
 

231
00:05:26,750 --> 00:05:30,420
better they could deal with multiple
type styles still weren't very flexible

232
00:05:30,420 --> 00:05:30,430
type styles still weren't very flexible
 

233
00:05:30,430 --> 00:05:33,700
type styles still weren't very flexible
that's not hard to add other layers it's

234
00:05:33,700 --> 00:05:33,710
that's not hard to add other layers it's
 

235
00:05:33,710 --> 00:05:36,490
that's not hard to add other layers it's
a very straightforward concept there was

236
00:05:36,490 --> 00:05:36,500
a very straightforward concept there was
 

237
00:05:36,500 --> 00:05:39,940
a very straightforward concept there was
a math problem the disappearing gradient

238
00:05:39,940 --> 00:05:39,950
a math problem the disappearing gradient
 

239
00:05:39,950 --> 00:05:42,250
a math problem the disappearing gradient
or the exploding gradient which I'm sure

240
00:05:42,250 --> 00:05:42,260
or the exploding gradient which I'm sure
 

241
00:05:42,260 --> 00:05:45,490
or the exploding gradient which I'm sure
many of you are familiar with basically

242
00:05:45,490 --> 00:05:45,500
many of you are familiar with basically
 

243
00:05:45,500 --> 00:05:51,190
many of you are familiar with basically
you need to take maximum advantage of

244
00:05:51,190 --> 00:05:51,200
you need to take maximum advantage of
 

245
00:05:51,200 --> 00:05:56,200
you need to take maximum advantage of
the range of values in the gradients and

246
00:05:56,200 --> 00:05:56,210
the range of values in the gradients and
 

247
00:05:56,210 --> 00:05:58,150
the range of values in the gradients and
not let them explode or disappear and

248
00:05:58,150 --> 00:05:58,160
not let them explode or disappear and
 

249
00:05:58,160 --> 00:06:01,600
not let them explode or disappear and
lose the resolution that's a fairly

250
00:06:01,600 --> 00:06:01,610
lose the resolution that's a fairly
 

251
00:06:01,610 --> 00:06:02,970
lose the resolution that's a fairly
straightforward mathematical

252
00:06:02,970 --> 00:06:02,980
straightforward mathematical
 

253
00:06:02,980 --> 00:06:05,860
straightforward mathematical
transformation with that insight we

254
00:06:05,860 --> 00:06:05,870
transformation with that insight we
 

255
00:06:05,870 --> 00:06:10,500
transformation with that insight we
could now go 200 layer neural nets and

256
00:06:10,500 --> 00:06:10,510
could now go 200 layer neural nets and
 

257
00:06:10,510 --> 00:06:13,090
could now go 200 layer neural nets and
that's behind sort of all the fantastic

258
00:06:13,090 --> 00:06:13,100
that's behind sort of all the fantastic
 

259
00:06:13,100 --> 00:06:17,040
that's behind sort of all the fantastic
gains that we've seen recently

260
00:06:17,040 --> 00:06:17,050
gains that we've seen recently
 

261
00:06:17,050 --> 00:06:23,290
gains that we've seen recently
alphago trained on every online game and

262
00:06:23,290 --> 00:06:23,300
alphago trained on every online game and
 

263
00:06:23,300 --> 00:06:28,270
alphago trained on every online game and
then became a fair go player it then

264
00:06:28,270 --> 00:06:28,280
then became a fair go player it then
 

265
00:06:28,280 --> 00:06:30,910
then became a fair go player it then
trained itself by playing itself and

266
00:06:30,910 --> 00:06:30,920
trained itself by playing itself and
 

267
00:06:30,920 --> 00:06:34,150
trained itself by playing itself and
soared past the best human alphago zero

268
00:06:34,150 --> 00:06:34,160
soared past the best human alphago zero
 

269
00:06:34,160 --> 00:06:36,520
soared past the best human alphago zero
started with no human input at all

270
00:06:36,520 --> 00:06:36,530
started with no human input at all
 

271
00:06:36,530 --> 00:06:41,560
started with no human input at all
within hours of iteration sort Pascal

272
00:06:41,560 --> 00:06:41,570
within hours of iteration sort Pascal
 

273
00:06:41,570 --> 00:06:46,060
within hours of iteration sort Pascal
phago also soared past the best just

274
00:06:46,060 --> 00:06:46,070
phago also soared past the best just
 

275
00:06:46,070 --> 00:06:49,410
phago also soared past the best just
programs they had another innovation

276
00:06:49,410 --> 00:06:49,420
programs they had another innovation
 

277
00:06:49,420 --> 00:06:52,450
programs they had another innovation
basically you need to evaluate the

278
00:06:52,450 --> 00:06:52,460
basically you need to evaluate the
 

279
00:06:52,460 --> 00:06:54,220
basically you need to evaluate the
quality of the board at each point they

280
00:06:54,220 --> 00:06:54,230
quality of the board at each point they
 

281
00:06:54,230 --> 00:06:57,730
quality of the board at each point they
used another hundred layer neural nets

282
00:06:57,730 --> 00:06:57,740
used another hundred layer neural nets
 

283
00:06:57,740 --> 00:07:04,480
used another hundred layer neural nets
to do that evaluation so there's still a

284
00:07:04,480 --> 00:07:04,490
to do that evaluation so there's still a
 

285
00:07:04,490 --> 00:07:08,410
to do that evaluation so there's still a
problem in the field which is there's a

286
00:07:08,410 --> 00:07:08,420
problem in the field which is there's a
 

287
00:07:08,420 --> 00:07:10,300
problem in the field which is there's a
motto that life begins at a billion

288
00:07:10,300 --> 00:07:10,310
motto that life begins at a billion
 

289
00:07:10,310 --> 00:07:11,960
motto that life begins at a billion
examples

290
00:07:11,960 --> 00:07:11,970
examples
 

291
00:07:11,970 --> 00:07:14,330
examples
one of the reasons I'm at Google is we

292
00:07:14,330 --> 00:07:14,340
one of the reasons I'm at Google is we
 

293
00:07:14,340 --> 00:07:16,940
one of the reasons I'm at Google is we
have a billion examples for examples of

294
00:07:16,940 --> 00:07:16,950
have a billion examples for examples of
 

295
00:07:16,950 --> 00:07:19,310
have a billion examples for examples of
pictures of dogs and cats that are

296
00:07:19,310 --> 00:07:19,320
pictures of dogs and cats that are
 

297
00:07:19,320 --> 00:07:21,290
pictures of dogs and cats that are
labeled so you got a picture of a cat

298
00:07:21,290 --> 00:07:21,300
labeled so you got a picture of a cat
 

299
00:07:21,300 --> 00:07:22,910
labeled so you got a picture of a cat
and it says cat and then you can learn

300
00:07:22,910 --> 00:07:22,920
and it says cat and then you can learn
 

301
00:07:22,920 --> 00:07:25,250
and it says cat and then you can learn
from it and you need a lot of them

302
00:07:25,250 --> 00:07:25,260
from it and you need a lot of them
 

303
00:07:25,260 --> 00:07:28,000
from it and you need a lot of them
alphago trained on a million online

304
00:07:28,000 --> 00:07:28,010
alphago trained on a million online
 

305
00:07:28,010 --> 00:07:31,640
alphago trained on a million online
moves that's how many we had of master

306
00:07:31,640 --> 00:07:31,650
moves that's how many we had of master
 

307
00:07:31,650 --> 00:07:36,680
moves that's how many we had of master
games and that only created a sort of

308
00:07:36,680 --> 00:07:36,690
games and that only created a sort of
 

309
00:07:36,690 --> 00:07:38,780
games and that only created a sort of
fair go player a good amateur could

310
00:07:38,780 --> 00:07:38,790
fair go player a good amateur could
 

311
00:07:38,790 --> 00:07:42,830
fair go player a good amateur could
defeated so they worked around that in

312
00:07:42,830 --> 00:07:42,840
defeated so they worked around that in
 

313
00:07:42,840 --> 00:07:45,790
defeated so they worked around that in
the case of go by basically generating

314
00:07:45,790 --> 00:07:45,800
the case of go by basically generating
 

315
00:07:45,800 --> 00:07:49,550
the case of go by basically generating
an infinite amount of data by having the

316
00:07:49,550 --> 00:07:49,560
an infinite amount of data by having the
 

317
00:07:49,560 --> 00:07:53,780
an infinite amount of data by having the
system play itself had a chat with

318
00:07:53,780 --> 00:07:53,790
system play itself had a chat with
 

319
00:07:53,790 --> 00:07:56,000
system play itself had a chat with
Denver's house office you know what kind

320
00:07:56,000 --> 00:07:56,010
Denver's house office you know what kind
 

321
00:07:56,010 --> 00:07:58,790
Denver's house office you know what kind
of situations can you do that with you

322
00:07:58,790 --> 00:07:58,800
of situations can you do that with you
 

323
00:07:58,800 --> 00:08:00,740
of situations can you do that with you
have to have some way of simulating the

324
00:08:00,740 --> 00:08:00,750
have to have some way of simulating the
 

325
00:08:00,750 --> 00:08:04,640
have to have some way of simulating the
world so go or chess are even though go

326
00:08:04,640 --> 00:08:04,650
world so go or chess are even though go
 

327
00:08:04,650 --> 00:08:06,950
world so go or chess are even though go
is considered a difficult game it's

328
00:08:06,950 --> 00:08:06,960
is considered a difficult game it's
 

329
00:08:06,960 --> 00:08:09,050
is considered a difficult game it's
a-you know the definition of it can

330
00:08:09,050 --> 00:08:09,060
a-you know the definition of it can
 

331
00:08:09,060 --> 00:08:12,860
a-you know the definition of it can
exist on one page so you can simulate it

332
00:08:12,860 --> 00:08:12,870
exist on one page so you can simulate it
 

333
00:08:12,870 --> 00:08:16,790
exist on one page so you can simulate it
that applies to math I mean amass axioms

334
00:08:16,790 --> 00:08:16,800
that applies to math I mean amass axioms
 

335
00:08:16,800 --> 00:08:19,190
that applies to math I mean amass axioms
are can be contained on a page or two

336
00:08:19,190 --> 00:08:19,200
are can be contained on a page or two
 

337
00:08:19,200 --> 00:08:22,640
are can be contained on a page or two
it's not very complicated it gets more

338
00:08:22,640 --> 00:08:22,650
it's not very complicated it gets more
 

339
00:08:22,650 --> 00:08:24,070
it's not very complicated it gets more
difficult when you have real-life

340
00:08:24,070 --> 00:08:24,080
difficult when you have real-life
 

341
00:08:24,080 --> 00:08:28,040
difficult when you have real-life
situations like biology so we have

342
00:08:28,040 --> 00:08:28,050
situations like biology so we have
 

343
00:08:28,050 --> 00:08:30,170
situations like biology so we have
biological simulators but the simulators

344
00:08:30,170 --> 00:08:30,180
biological simulators but the simulators
 

345
00:08:30,180 --> 00:08:32,390
biological simulators but the simulators
on perfect so learning from the

346
00:08:32,390 --> 00:08:32,400
on perfect so learning from the
 

347
00:08:32,400 --> 00:08:34,520
on perfect so learning from the
simulators will only be as good as the

348
00:08:34,520 --> 00:08:34,530
simulators will only be as good as the
 

349
00:08:34,530 --> 00:08:37,610
simulators will only be as good as the
simulators that's actually the key to

350
00:08:37,610 --> 00:08:37,620
simulators that's actually the key to
 

351
00:08:37,620 --> 00:08:39,200
simulators that's actually the key to
being able to do deep learning on

352
00:08:39,200 --> 00:08:39,210
being able to do deep learning on
 

353
00:08:39,210 --> 00:08:42,130
being able to do deep learning on
biology

354
00:08:42,130 --> 00:08:42,140

 

355
00:08:42,140 --> 00:08:44,960

autonomous vehicles you need real-life

356
00:08:44,960 --> 00:08:44,970
autonomous vehicles you need real-life
 

357
00:08:44,970 --> 00:08:49,310
autonomous vehicles you need real-life
data so the way mo systems have gone

358
00:08:49,310 --> 00:08:49,320
data so the way mo systems have gone
 

359
00:08:49,320 --> 00:08:52,070
data so the way mo systems have gone
three and a half million miles

360
00:08:52,070 --> 00:08:52,080
three and a half million miles
 

361
00:08:52,080 --> 00:08:54,199
three and a half million miles
that's good that's enough data to then

362
00:08:54,199 --> 00:08:54,209
that's good that's enough data to then
 

363
00:08:54,209 --> 00:08:56,870
that's good that's enough data to then
create a very good simulator so the

364
00:08:56,870 --> 00:08:56,880
create a very good simulator so the
 

365
00:08:56,880 --> 00:08:58,430
create a very good simulator so the
simulator is really quite realistic

366
00:08:58,430 --> 00:08:58,440
simulator is really quite realistic
 

367
00:08:58,440 --> 00:08:59,960
simulator is really quite realistic
because they had a lot of real-world

368
00:08:59,960 --> 00:08:59,970
because they had a lot of real-world
 

369
00:08:59,970 --> 00:09:03,260
because they had a lot of real-world
experience and the they've got a billion

370
00:09:03,260 --> 00:09:03,270
experience and the they've got a billion
 

371
00:09:03,270 --> 00:09:06,530
experience and the they've got a billion
miles in the simulator but we don't

372
00:09:06,530 --> 00:09:06,540
miles in the simulator but we don't
 

373
00:09:06,540 --> 00:09:09,380
miles in the simulator but we don't
always have that opportunity to either

374
00:09:09,380 --> 00:09:09,390
always have that opportunity to either
 

375
00:09:09,390 --> 00:09:13,780
always have that opportunity to either
create the data or have the data around

376
00:09:13,780 --> 00:09:13,790
create the data or have the data around
 

377
00:09:13,790 --> 00:09:16,760
create the data or have the data around
humans can learn from a small number of

378
00:09:16,760 --> 00:09:16,770
humans can learn from a small number of
 

379
00:09:16,770 --> 00:09:20,329
humans can learn from a small number of
examples your significant other your

380
00:09:20,329 --> 00:09:20,339
examples your significant other your
 

381
00:09:20,339 --> 00:09:23,240
examples your significant other your
professor your boss your investor can

382
00:09:23,240 --> 00:09:23,250
professor your boss your investor can
 

383
00:09:23,250 --> 00:09:25,610
professor your boss your investor can
tell you something once or twice and you

384
00:09:25,610 --> 00:09:25,620
tell you something once or twice and you
 

385
00:09:25,620 --> 00:09:27,260
tell you something once or twice and you
might actually learn from that some

386
00:09:27,260 --> 00:09:27,270
might actually learn from that some
 

387
00:09:27,270 --> 00:09:29,300
might actually learn from that some
humans have been reported to do that

388
00:09:29,300 --> 00:09:29,310
humans have been reported to do that
 

389
00:09:29,310 --> 00:09:33,260
humans have been reported to do that
and that's kind of the remaining

390
00:09:33,260 --> 00:09:33,270
and that's kind of the remaining
 

391
00:09:33,270 --> 00:09:36,829
and that's kind of the remaining
advantage of humans now there's actually

392
00:09:36,829 --> 00:09:36,839
advantage of humans now there's actually
 

393
00:09:36,839 --> 00:09:39,290
advantage of humans now there's actually
no back propagation in the human brain

394
00:09:39,290 --> 00:09:39,300
no back propagation in the human brain
 

395
00:09:39,300 --> 00:09:42,139
no back propagation in the human brain
it doesn't use deep learning it uses a

396
00:09:42,139 --> 00:09:42,149
it doesn't use deep learning it uses a
 

397
00:09:42,149 --> 00:09:45,380
it doesn't use deep learning it uses a
different architecture that same year in

398
00:09:45,380 --> 00:09:45,390
different architecture that same year in
 

399
00:09:45,390 --> 00:09:47,690
different architecture that same year in
1962 I wrote a paper how I thought the

400
00:09:47,690 --> 00:09:47,700
1962 I wrote a paper how I thought the
 

401
00:09:47,700 --> 00:09:50,000
1962 I wrote a paper how I thought the
human brain worked there was actually

402
00:09:50,000 --> 00:09:50,010
human brain worked there was actually
 

403
00:09:50,010 --> 00:09:52,550
human brain worked there was actually
very little neuroscience to go on there

404
00:09:52,550 --> 00:09:52,560
very little neuroscience to go on there
 

405
00:09:52,560 --> 00:09:54,829
very little neuroscience to go on there
was one neuroscientist Vernon mount

406
00:09:54,829 --> 00:09:54,839
was one neuroscientist Vernon mount
 

407
00:09:54,839 --> 00:09:56,300
was one neuroscientist Vernon mount
Castle that had something relevant to

408
00:09:56,300 --> 00:09:56,310
Castle that had something relevant to
 

409
00:09:56,310 --> 00:09:59,720
Castle that had something relevant to
say which as he did I mean there was a

410
00:09:59,720 --> 00:09:59,730
say which as he did I mean there was a
 

411
00:09:59,730 --> 00:10:01,880
say which as he did I mean there was a
the common wisdom at the time and

412
00:10:01,880 --> 00:10:01,890
the common wisdom at the time and
 

413
00:10:01,890 --> 00:10:03,170
the common wisdom at the time and
there's still a lot of neuroscience that

414
00:10:03,170 --> 00:10:03,180
there's still a lot of neuroscience that
 

415
00:10:03,180 --> 00:10:04,550
there's still a lot of neuroscience that
says say this that we have all these

416
00:10:04,550 --> 00:10:04,560
says say this that we have all these
 

417
00:10:04,560 --> 00:10:06,470
says say this that we have all these
different regions of the brain they do

418
00:10:06,470 --> 00:10:06,480
different regions of the brain they do
 

419
00:10:06,480 --> 00:10:09,699
different regions of the brain they do
different things they must be different

420
00:10:09,699 --> 00:10:09,709
different things they must be different
 

421
00:10:09,709 --> 00:10:12,260
different things they must be different
there's v1 in the back of the head where

422
00:10:12,260 --> 00:10:12,270
there's v1 in the back of the head where
 

423
00:10:12,270 --> 00:10:15,530
there's v1 in the back of the head where
the optic nerve spills into that can

424
00:10:15,530 --> 00:10:15,540
the optic nerve spills into that can
 

425
00:10:15,540 --> 00:10:17,590
the optic nerve spills into that can
tell that that's a curved line that

426
00:10:17,590 --> 00:10:17,600
tell that that's a curved line that
 

427
00:10:17,600 --> 00:10:20,780
tell that that's a curved line that
that's a straight line does these simple

428
00:10:20,780 --> 00:10:20,790
that's a straight line does these simple
 

429
00:10:20,790 --> 00:10:23,389
that's a straight line does these simple
feature extractions on visual images

430
00:10:23,389 --> 00:10:23,399
feature extractions on visual images
 

431
00:10:23,399 --> 00:10:24,829
feature extractions on visual images
it's actually a large part of the

432
00:10:24,829 --> 00:10:24,839
it's actually a large part of the
 

433
00:10:24,839 --> 00:10:27,620
it's actually a large part of the
neocortex does the fusiform gyrus up

434
00:10:27,620 --> 00:10:27,630
neocortex does the fusiform gyrus up
 

435
00:10:27,630 --> 00:10:31,610
neocortex does the fusiform gyrus up
here which can recognize faces we know

436
00:10:31,610 --> 00:10:31,620
here which can recognize faces we know
 

437
00:10:31,620 --> 00:10:33,170
here which can recognize faces we know
that because if it gets knocked out

438
00:10:33,170 --> 00:10:33,180
that because if it gets knocked out
 

439
00:10:33,180 --> 00:10:35,180
that because if it gets knocked out
through injury or stroke people can't

440
00:10:35,180 --> 00:10:35,190
through injury or stroke people can't
 

441
00:10:35,190 --> 00:10:37,340
through injury or stroke people can't
recognize faces they will learn it again

442
00:10:37,340 --> 00:10:37,350
recognize faces they will learn it again
 

443
00:10:37,350 --> 00:10:39,470
recognize faces they will learn it again
with a different region of the neocortex

444
00:10:39,470 --> 00:10:39,480
with a different region of the neocortex
 

445
00:10:39,480 --> 00:10:43,460
with a different region of the neocortex
is the famous frontal cortex which does

446
00:10:43,460 --> 00:10:43,470
is the famous frontal cortex which does
 

447
00:10:43,470 --> 00:10:46,610
is the famous frontal cortex which does
language in poetry and music so these

448
00:10:46,610 --> 00:10:46,620
language in poetry and music so these
 

449
00:10:46,620 --> 00:10:49,490
language in poetry and music so these
must work on different principles he did

450
00:10:49,490 --> 00:10:49,500
must work on different principles he did
 

451
00:10:49,500 --> 00:10:51,590
must work on different principles he did
autopsies on the neocortex and all these

452
00:10:51,590 --> 00:10:51,600
autopsies on the neocortex and all these
 

453
00:10:51,600 --> 00:10:53,030
autopsies on the neocortex and all these
different regions and found they all

454
00:10:53,030 --> 00:10:53,040
different regions and found they all
 

455
00:10:53,040 --> 00:10:54,440
different regions and found they all
looked the same they had the same

456
00:10:54,440 --> 00:10:54,450
looked the same they had the same
 

457
00:10:54,450 --> 00:10:57,470
looked the same they had the same
repeating pattern same interconnections

458
00:10:57,470 --> 00:10:57,480
repeating pattern same interconnections
 

459
00:10:57,480 --> 00:11:00,079
repeating pattern same interconnections
he said neocortex is neocortex so I had

460
00:11:00,079 --> 00:11:00,089
he said neocortex is neocortex so I had
 

461
00:11:00,089 --> 00:11:03,250
he said neocortex is neocortex so I had
that hint otherwise I can actually

462
00:11:03,250 --> 00:11:03,260
that hint otherwise I can actually
 

463
00:11:03,260 --> 00:11:06,050
that hint otherwise I can actually
observe human brains in action which I

464
00:11:06,050 --> 00:11:06,060
observe human brains in action which I
 

465
00:11:06,060 --> 00:11:08,600
observe human brains in action which I
did from time to time and there's a lot

466
00:11:08,600 --> 00:11:08,610
did from time to time and there's a lot
 

467
00:11:08,610 --> 00:11:11,269
did from time to time and there's a lot
of hints that you can get that way for

468
00:11:11,269 --> 00:11:11,279
of hints that you can get that way for
 

469
00:11:11,279 --> 00:11:13,069
of hints that you can get that way for
example if I ask you to recite the

470
00:11:13,069 --> 00:11:13,079
example if I ask you to recite the
 

471
00:11:13,079 --> 00:11:15,319
example if I ask you to recite the
alphabet you actually don't do it from A

472
00:11:15,319 --> 00:11:15,329
alphabet you actually don't do it from A
 

473
00:11:15,329 --> 00:11:17,300
alphabet you actually don't do it from A
to Z you do it as a sequence of

474
00:11:17,300 --> 00:11:17,310
to Z you do it as a sequence of
 

475
00:11:17,310 --> 00:11:22,819
to Z you do it as a sequence of
sequences ABCD efg hijk so we learn

476
00:11:22,819 --> 00:11:22,829
sequences ABCD efg hijk so we learn
 

477
00:11:22,829 --> 00:11:24,860
sequences ABCD efg hijk so we learn
things that secret forward sequences of

478
00:11:24,860 --> 00:11:24,870
things that secret forward sequences of
 

479
00:11:24,870 --> 00:11:27,560
things that secret forward sequences of
sequences forward because if I ask you

480
00:11:27,560 --> 00:11:27,570
sequences forward because if I ask you
 

481
00:11:27,570 --> 00:11:30,439
sequences forward because if I ask you
to recite the alphabet backwards you

482
00:11:30,439 --> 00:11:30,449
to recite the alphabet backwards you
 

483
00:11:30,449 --> 00:11:32,060
to recite the alphabet backwards you
can't do it unless you learn that as a

484
00:11:32,060 --> 00:11:32,070
can't do it unless you learn that as a
 

485
00:11:32,070 --> 00:11:34,160
can't do it unless you learn that as a
new sequence so these are all

486
00:11:34,160 --> 00:11:34,170
new sequence so these are all
 

487
00:11:34,170 --> 00:11:37,519
new sequence so these are all
interesting hints I wrote a paper that I

488
00:11:37,519 --> 00:11:37,529
interesting hints I wrote a paper that I
 

489
00:11:37,529 --> 00:11:40,490
interesting hints I wrote a paper that I
that the neocortex is organized as a

490
00:11:40,490 --> 00:11:40,500
that the neocortex is organized as a
 

491
00:11:40,500 --> 00:11:42,620
that the neocortex is organized as a
hierarchy of modules in each module can

492
00:11:42,620 --> 00:11:42,630
hierarchy of modules in each module can
 

493
00:11:42,630 --> 00:11:45,980
hierarchy of modules in each module can
learn a simple pattern and that's how I

494
00:11:45,980 --> 00:11:45,990
learn a simple pattern and that's how I
 

495
00:11:45,990 --> 00:11:48,889
learn a simple pattern and that's how I
got to meet President Johnson and that

496
00:11:48,889 --> 00:11:48,899
got to meet President Johnson and that
 

497
00:11:48,899 --> 00:11:52,819
got to meet President Johnson and that
initiated a half-century of thinking

498
00:11:52,819 --> 00:11:52,829
initiated a half-century of thinking
 

499
00:11:52,829 --> 00:11:56,540
initiated a half-century of thinking
about this issue I came to MIT to study

500
00:11:56,540 --> 00:11:56,550
about this issue I came to MIT to study
 

501
00:11:56,550 --> 00:11:58,819
about this issue I came to MIT to study
with Marvin Minsky actually came for two

502
00:11:58,819 --> 00:11:58,829
with Marvin Minsky actually came for two
 

503
00:11:58,829 --> 00:12:02,090
with Marvin Minsky actually came for two
reasons one the Minsky became my mentor

504
00:12:02,090 --> 00:12:02,100
reasons one the Minsky became my mentor
 

505
00:12:02,100 --> 00:12:04,009
reasons one the Minsky became my mentor
which was a mentorship that lasted for

506
00:12:04,009 --> 00:12:04,019
which was a mentorship that lasted for
 

507
00:12:04,019 --> 00:12:07,130
which was a mentorship that lasted for
over 50 years the fact that MIT was so

508
00:12:07,130 --> 00:12:07,140
over 50 years the fact that MIT was so
 

509
00:12:07,140 --> 00:12:09,400
over 50 years the fact that MIT was so
advanced it actually had a computer

510
00:12:09,400 --> 00:12:09,410
advanced it actually had a computer
 

511
00:12:09,410 --> 00:12:12,259
advanced it actually had a computer
which the other colleges I considered

512
00:12:12,259 --> 00:12:12,269
which the other colleges I considered
 

513
00:12:12,269 --> 00:12:17,480
which the other colleges I considered
didn't have it was an IBM 7090 for 32 K

514
00:12:17,480 --> 00:12:17,490
didn't have it was an IBM 7090 for 32 K
 

515
00:12:17,490 --> 00:12:21,230
didn't have it was an IBM 7090 for 32 K
of 36 bit words so it's 150 K of course

516
00:12:21,230 --> 00:12:21,240
of 36 bit words so it's 150 K of course
 

517
00:12:21,240 --> 00:12:24,290
of 36 bit words so it's 150 K of course
storage to microsecond cycle time two

518
00:12:24,290 --> 00:12:24,300
storage to microsecond cycle time two
 

519
00:12:24,300 --> 00:12:25,939
storage to microsecond cycle time two
cycles for instructions or a quarter of

520
00:12:25,939 --> 00:12:25,949
cycles for instructions or a quarter of
 

521
00:12:25,949 --> 00:12:29,840
cycles for instructions or a quarter of
a myth and that thousands of students

522
00:12:29,840 --> 00:12:29,850
a myth and that thousands of students
 

523
00:12:29,850 --> 00:12:32,019
a myth and that thousands of students
and professors shared that one machine

524
00:12:32,019 --> 00:12:32,029
and professors shared that one machine
 

525
00:12:32,029 --> 00:12:36,079
and professors shared that one machine
in 2012 I wrote a book about this thesis

526
00:12:36,079 --> 00:12:36,089
in 2012 I wrote a book about this thesis
 

527
00:12:36,089 --> 00:12:38,139
in 2012 I wrote a book about this thesis
is now actually an explosion of

528
00:12:38,139 --> 00:12:38,149
is now actually an explosion of
 

529
00:12:38,149 --> 00:12:40,699
is now actually an explosion of
neuroscience evidence to support it the

530
00:12:40,699 --> 00:12:40,709
neuroscience evidence to support it the
 

531
00:12:40,709 --> 00:12:42,680
neuroscience evidence to support it the
European brain reverse engineering

532
00:12:42,680 --> 00:12:42,690
European brain reverse engineering
 

533
00:12:42,690 --> 00:12:45,439
European brain reverse engineering
project has identified a repeating

534
00:12:45,439 --> 00:12:45,449
project has identified a repeating
 

535
00:12:45,449 --> 00:12:47,509
project has identified a repeating
module about a hundred neurons it's

536
00:12:47,509 --> 00:12:47,519
module about a hundred neurons it's
 

537
00:12:47,519 --> 00:12:50,030
module about a hundred neurons it's
repeated three hundred million times

538
00:12:50,030 --> 00:12:50,040
repeated three hundred million times
 

539
00:12:50,040 --> 00:12:51,889
repeated three hundred million times
it's about 30 billion neurons in the

540
00:12:51,889 --> 00:12:51,899
it's about 30 billion neurons in the
 

541
00:12:51,899 --> 00:12:54,199
it's about 30 billion neurons in the
neocortex the neocortex is the outer

542
00:12:54,199 --> 00:12:54,209
neocortex the neocortex is the outer
 

543
00:12:54,209 --> 00:12:56,240
neocortex the neocortex is the outer
layer of the brain that's part where we

544
00:12:56,240 --> 00:12:56,250
layer of the brain that's part where we
 

545
00:12:56,250 --> 00:12:59,720
layer of the brain that's part where we
do our thinking and they can see in each

546
00:12:59,720 --> 00:12:59,730
do our thinking and they can see in each
 

547
00:12:59,730 --> 00:13:02,680
do our thinking and they can see in each
module axons coming in from another

548
00:13:02,680 --> 00:13:02,690
module axons coming in from another
 

549
00:13:02,690 --> 00:13:06,110
module axons coming in from another
module and then the output acts the

550
00:13:06,110 --> 00:13:06,120
module and then the output acts the
 

551
00:13:06,120 --> 00:13:07,670
module and then the output acts the
single output accent of that

552
00:13:07,670 --> 00:13:07,680
single output accent of that
 

553
00:13:07,680 --> 00:13:09,980
single output accent of that
Jil goes as the input to another module

554
00:13:09,980 --> 00:13:09,990
Jil goes as the input to another module
 

555
00:13:09,990 --> 00:13:11,990
Jil goes as the input to another module
so we can see it organized as a

556
00:13:11,990 --> 00:13:12,000
so we can see it organized as a
 

557
00:13:12,000 --> 00:13:15,160
so we can see it organized as a
hierarchy it's not a physical hierarchy

558
00:13:15,160 --> 00:13:15,170
hierarchy it's not a physical hierarchy
 

559
00:13:15,170 --> 00:13:17,360
hierarchy it's not a physical hierarchy
it's the hierarchy comes from these

560
00:13:17,360 --> 00:13:17,370
it's the hierarchy comes from these
 

561
00:13:17,370 --> 00:13:19,970
it's the hierarchy comes from these
connections the neocortex is a very thin

562
00:13:19,970 --> 00:13:19,980
connections the neocortex is a very thin
 

563
00:13:19,980 --> 00:13:22,250
connections the neocortex is a very thin
structure it's actually one module thick

564
00:13:22,250 --> 00:13:22,260
structure it's actually one module thick
 

565
00:13:22,260 --> 00:13:25,550
structure it's actually one module thick
there's six layers of neurons but it

566
00:13:25,550 --> 00:13:25,560
there's six layers of neurons but it
 

567
00:13:25,560 --> 00:13:28,610
there's six layers of neurons but it
constitutes one module and we can see

568
00:13:28,610 --> 00:13:28,620
constitutes one module and we can see
 

569
00:13:28,620 --> 00:13:31,720
constitutes one module and we can see
that it learns in simple pattern and

570
00:13:31,720 --> 00:13:31,730
that it learns in simple pattern and
 

571
00:13:31,730 --> 00:13:34,760
that it learns in simple pattern and
various reasons I cite in the book the

572
00:13:34,760 --> 00:13:34,770
various reasons I cite in the book the
 

573
00:13:34,770 --> 00:13:37,280
various reasons I cite in the book the
pattern recognition model that's using

574
00:13:37,280 --> 00:13:37,290
pattern recognition model that's using
 

575
00:13:37,290 --> 00:13:40,430
pattern recognition model that's using
is basically a hidden Markov model how

576
00:13:40,430 --> 00:13:40,440
is basically a hidden Markov model how
 

577
00:13:40,440 --> 00:13:42,110
is basically a hidden Markov model how
many of you have worked with Markov

578
00:13:42,110 --> 00:13:42,120
many of you have worked with Markov
 

579
00:13:42,120 --> 00:13:45,889
many of you have worked with Markov
models okay

580
00:13:45,889 --> 00:13:45,899
models okay
 

581
00:13:45,899 --> 00:13:48,949
models okay
that's usually no hands go open I asked

582
00:13:48,949 --> 00:13:48,959
that's usually no hands go open I asked
 

583
00:13:48,959 --> 00:13:52,730
that's usually no hands go open I asked
that question but Markov model is not it

584
00:13:52,730 --> 00:13:52,740
that question but Markov model is not it
 

585
00:13:52,740 --> 00:13:56,060
that question but Markov model is not it
is learned but it's not back propagation

586
00:13:56,060 --> 00:13:56,070
is learned but it's not back propagation
 

587
00:13:56,070 --> 00:13:59,090
is learned but it's not back propagation
it can learn local features so it's very

588
00:13:59,090 --> 00:13:59,100
it can learn local features so it's very
 

589
00:13:59,100 --> 00:14:00,650
it can learn local features so it's very
good for speech recognition and the

590
00:14:00,650 --> 00:14:00,660
good for speech recognition and the
 

591
00:14:00,660 --> 00:14:02,470
good for speech recognition and the
speech recognition network I did in the

592
00:14:02,470 --> 00:14:02,480
speech recognition network I did in the
 

593
00:14:02,480 --> 00:14:05,870
speech recognition network I did in the
80s used these Markov models that became

594
00:14:05,870 --> 00:14:05,880
80s used these Markov models that became
 

595
00:14:05,880 --> 00:14:08,720
80s used these Markov models that became
the standard approach because it can

596
00:14:08,720 --> 00:14:08,730
the standard approach because it can
 

597
00:14:08,730 --> 00:14:11,990
the standard approach because it can
deal with local variations so the fact

598
00:14:11,990 --> 00:14:12,000
deal with local variations so the fact
 

599
00:14:12,000 --> 00:14:15,890
deal with local variations so the fact
that a vowel is stretched you can learn

600
00:14:15,890 --> 00:14:15,900
that a vowel is stretched you can learn
 

601
00:14:15,900 --> 00:14:18,680
that a vowel is stretched you can learn
that in a Markov model it doesn't learn

602
00:14:18,680 --> 00:14:18,690
that in a Markov model it doesn't learn
 

603
00:14:18,690 --> 00:14:21,769
that in a Markov model it doesn't learn
long distance relationships that's

604
00:14:21,769 --> 00:14:21,779
long distance relationships that's
 

605
00:14:21,779 --> 00:14:24,710
long distance relationships that's
handled by the hierarchy and something

606
00:14:24,710 --> 00:14:24,720
handled by the hierarchy and something
 

607
00:14:24,720 --> 00:14:26,840
handled by the hierarchy and something
we don't fully understand yet is exactly

608
00:14:26,840 --> 00:14:26,850
we don't fully understand yet is exactly
 

609
00:14:26,850 --> 00:14:29,540
we don't fully understand yet is exactly
how the neocortex creates that hierarchy

610
00:14:29,540 --> 00:14:29,550
how the neocortex creates that hierarchy
 

611
00:14:29,550 --> 00:14:32,720
how the neocortex creates that hierarchy
but we have figured out how it can

612
00:14:32,720 --> 00:14:32,730
but we have figured out how it can
 

613
00:14:32,730 --> 00:14:36,110
but we have figured out how it can
connect this module to this module does

614
00:14:36,110 --> 00:14:36,120
connect this module to this module does
 

615
00:14:36,120 --> 00:14:38,570
connect this module to this module does
it then grow I mean there's no virtual

616
00:14:38,570 --> 00:14:38,580
it then grow I mean there's no virtual
 

617
00:14:38,580 --> 00:14:40,699
it then grow I mean there's no virtual
communication or wireless communication

618
00:14:40,699 --> 00:14:40,709
communication or wireless communication
 

619
00:14:40,709 --> 00:14:43,640
communication or wireless communication
it's actually connection so does it grow

620
00:14:43,640 --> 00:14:43,650
it's actually connection so does it grow
 

621
00:14:43,650 --> 00:14:46,460
it's actually connection so does it grow
an axon you know from one place to

622
00:14:46,460 --> 00:14:46,470
an axon you know from one place to
 

623
00:14:46,470 --> 00:14:49,030
an axon you know from one place to
another which could be inches apart

624
00:14:49,030 --> 00:14:49,040
another which could be inches apart
 

625
00:14:49,040 --> 00:14:51,980
another which could be inches apart
actually they all all these connections

626
00:14:51,980 --> 00:14:51,990
actually they all all these connections
 

627
00:14:51,990 --> 00:14:55,730
actually they all all these connections
are there from birth like the streets

628
00:14:55,730 --> 00:14:55,740
are there from birth like the streets
 

629
00:14:55,740 --> 00:14:57,769
are there from birth like the streets
and avenues of Manhattan there's

630
00:14:57,769 --> 00:14:57,779
and avenues of Manhattan there's
 

631
00:14:57,779 --> 00:14:59,920
and avenues of Manhattan there's
vertical and horizontal connections so

632
00:14:59,920 --> 00:14:59,930
vertical and horizontal connections so
 

633
00:14:59,930 --> 00:15:03,230
vertical and horizontal connections so
if the it decides and how it makes that

634
00:15:03,230 --> 00:15:03,240
if the it decides and how it makes that
 

635
00:15:03,240 --> 00:15:04,780
if the it decides and how it makes that
decision it's still not fully understood

636
00:15:04,780 --> 00:15:04,790
decision it's still not fully understood
 

637
00:15:04,790 --> 00:15:07,220
decision it's still not fully understood
that it wants to connect this module to

638
00:15:07,220 --> 00:15:07,230
that it wants to connect this module to
 

639
00:15:07,230 --> 00:15:09,110
that it wants to connect this module to
this module there's already a vertical

640
00:15:09,110 --> 00:15:09,120
this module there's already a vertical
 

641
00:15:09,120 --> 00:15:11,329
this module there's already a vertical
horizontal and a vertical connection it

642
00:15:11,329 --> 00:15:11,339
horizontal and a vertical connection it
 

643
00:15:11,339 --> 00:15:14,420
horizontal and a vertical connection it
just activates them we can actually see

644
00:15:14,420 --> 00:15:14,430
just activates them we can actually see
 

645
00:15:14,430 --> 00:15:16,640
just activates them we can actually see
that now and I can see that happening in

646
00:15:16,640 --> 00:15:16,650
that now and I can see that happening in
 

647
00:15:16,650 --> 00:15:21,030
that now and I can see that happening in
real time on non-invasive brain scans

648
00:15:21,030 --> 00:15:21,040
real time on non-invasive brain scans
 

649
00:15:21,040 --> 00:15:22,889
real time on non-invasive brain scans
so there's a current amount of evidence

650
00:15:22,889 --> 00:15:22,899
so there's a current amount of evidence
 

651
00:15:22,899 --> 00:15:25,559
so there's a current amount of evidence
that's in fact the neocortex is a

652
00:15:25,559 --> 00:15:25,569
that's in fact the neocortex is a
 

653
00:15:25,569 --> 00:15:30,869
that's in fact the neocortex is a
hierarchy of modules that can learn each

654
00:15:30,869 --> 00:15:30,879
hierarchy of modules that can learn each
 

655
00:15:30,879 --> 00:15:33,449
hierarchy of modules that can learn each
module learns a simple sequential

656
00:15:33,449 --> 00:15:33,459
module learns a simple sequential
 

657
00:15:33,459 --> 00:15:36,799
module learns a simple sequential
pattern and even though the patterns we

658
00:15:36,799 --> 00:15:36,809
pattern and even though the patterns we
 

659
00:15:36,809 --> 00:15:39,749
pattern and even though the patterns we
perceived don't seem like sequences they

660
00:15:39,749 --> 00:15:39,759
perceived don't seem like sequences they
 

661
00:15:39,759 --> 00:15:41,789
perceived don't seem like sequences they
may seem three-dimensional or even more

662
00:15:41,789 --> 00:15:41,799
may seem three-dimensional or even more
 

663
00:15:41,799 --> 00:15:44,340
may seem three-dimensional or even more
complicated they are in fact represented

664
00:15:44,340 --> 00:15:44,350
complicated they are in fact represented
 

665
00:15:44,350 --> 00:15:47,429
complicated they are in fact represented
as sequences but the complexity comes in

666
00:15:47,429 --> 00:15:47,439
as sequences but the complexity comes in
 

667
00:15:47,439 --> 00:15:50,660
as sequences but the complexity comes in
with the hierarchy so the neocortex

668
00:15:50,660 --> 00:15:50,670
with the hierarchy so the neocortex
 

669
00:15:50,670 --> 00:15:54,569
with the hierarchy so the neocortex
emerged 200 million years ago with

670
00:15:54,569 --> 00:15:54,579
emerged 200 million years ago with
 

671
00:15:54,579 --> 00:15:56,249
emerged 200 million years ago with
mammals all mammals have a neocortex

672
00:15:56,249 --> 00:15:56,259
mammals all mammals have a neocortex
 

673
00:15:56,259 --> 00:15:58,889
mammals all mammals have a neocortex
it's one of the distinguishing features

674
00:15:58,889 --> 00:15:58,899
it's one of the distinguishing features
 

675
00:15:58,899 --> 00:16:01,769
it's one of the distinguishing features
of mammals these first mammals were

676
00:16:01,769 --> 00:16:01,779
of mammals these first mammals were
 

677
00:16:01,779 --> 00:16:05,220
of mammals these first mammals were
small they were rodents but they were

678
00:16:05,220 --> 00:16:05,230
small they were rodents but they were
 

679
00:16:05,230 --> 00:16:08,369
small they were rodents but they were
capable a new type of thinking other

680
00:16:08,369 --> 00:16:08,379
capable a new type of thinking other
 

681
00:16:08,379 --> 00:16:10,410
capable a new type of thinking other
non-mammalian animals had fixed

682
00:16:10,410 --> 00:16:10,420
non-mammalian animals had fixed
 

683
00:16:10,420 --> 00:16:12,299
non-mammalian animals had fixed
behaviors but those fixed behaviors were

684
00:16:12,299 --> 00:16:12,309
behaviors but those fixed behaviors were
 

685
00:16:12,309 --> 00:16:15,119
behaviors but those fixed behaviors were
very well adapted for their ecological

686
00:16:15,119 --> 00:16:15,129
very well adapted for their ecological
 

687
00:16:15,129 --> 00:16:18,840
very well adapted for their ecological
niche but these new mammals could invent

688
00:16:18,840 --> 00:16:18,850
niche but these new mammals could invent
 

689
00:16:18,850 --> 00:16:21,299
niche but these new mammals could invent
a new behavior so creativity and

690
00:16:21,299 --> 00:16:21,309
a new behavior so creativity and
 

691
00:16:21,309 --> 00:16:23,460
a new behavior so creativity and
innovation was one feature of the

692
00:16:23,460 --> 00:16:23,470
innovation was one feature of the
 

693
00:16:23,470 --> 00:16:26,039
innovation was one feature of the
neocortex so a mouse is escaping a

694
00:16:26,039 --> 00:16:26,049
neocortex so a mouse is escaping a
 

695
00:16:26,049 --> 00:16:28,530
neocortex so a mouse is escaping a
predator its usual escape path is

696
00:16:28,530 --> 00:16:28,540
predator its usual escape path is
 

697
00:16:28,540 --> 00:16:31,710
predator its usual escape path is
blocked it will invent a new behavior to

698
00:16:31,710 --> 00:16:31,720
blocked it will invent a new behavior to
 

699
00:16:31,720 --> 00:16:33,629
blocked it will invent a new behavior to
deal with it probably wouldn't work but

700
00:16:33,629 --> 00:16:33,639
deal with it probably wouldn't work but
 

701
00:16:33,639 --> 00:16:35,160
deal with it probably wouldn't work but
if it did work it would remember it and

702
00:16:35,160 --> 00:16:35,170
if it did work it would remember it and
 

703
00:16:35,170 --> 00:16:37,169
if it did work it would remember it and
would have a new behavior and that

704
00:16:37,169 --> 00:16:37,179
would have a new behavior and that
 

705
00:16:37,179 --> 00:16:38,549
would have a new behavior and that
behavior could spread virally through

706
00:16:38,549 --> 00:16:38,559
behavior could spread virally through
 

707
00:16:38,559 --> 00:16:40,710
behavior could spread virally through
the community another Mouse watching

708
00:16:40,710 --> 00:16:40,720
the community another Mouse watching
 

709
00:16:40,720 --> 00:16:43,319
the community another Mouse watching
this was with say to itself that was

710
00:16:43,319 --> 00:16:43,329
this was with say to itself that was
 

711
00:16:43,329 --> 00:16:45,090
this was with say to itself that was
really clever going around that rock I'm

712
00:16:45,090 --> 00:16:45,100
really clever going around that rock I'm
 

713
00:16:45,100 --> 00:16:48,629
really clever going around that rock I'm
gonna remember to do that and it would

714
00:16:48,629 --> 00:16:48,639
gonna remember to do that and it would
 

715
00:16:48,639 --> 00:16:52,679
gonna remember to do that and it would
have a new behavior didn't help these

716
00:16:52,679 --> 00:16:52,689
have a new behavior didn't help these
 

717
00:16:52,689 --> 00:16:54,809
have a new behavior didn't help these
early mammals that much because as I say

718
00:16:54,809 --> 00:16:54,819
early mammals that much because as I say
 

719
00:16:54,819 --> 00:16:57,179
early mammals that much because as I say
the non-mammalian animals were very well

720
00:16:57,179 --> 00:16:57,189
the non-mammalian animals were very well
 

721
00:16:57,189 --> 00:17:02,369
the non-mammalian animals were very well
adapted to their niches and nothing much

722
00:17:02,369 --> 00:17:02,379
adapted to their niches and nothing much
 

723
00:17:02,379 --> 00:17:04,470
adapted to their niches and nothing much
happened for a hundred and thirty five

724
00:17:04,470 --> 00:17:04,480
happened for a hundred and thirty five
 

725
00:17:04,480 --> 00:17:07,740
happened for a hundred and thirty five
million years but then 65 million years

726
00:17:07,740 --> 00:17:07,750
million years but then 65 million years
 

727
00:17:07,750 --> 00:17:09,899
million years but then 65 million years
ago something did happened there was a

728
00:17:09,899 --> 00:17:09,909
ago something did happened there was a
 

729
00:17:09,909 --> 00:17:11,990
ago something did happened there was a
sudden violent change to the environment

730
00:17:11,990 --> 00:17:12,000
sudden violent change to the environment
 

731
00:17:12,000 --> 00:17:14,760
sudden violent change to the environment
we now call it the Cretaceous extinction

732
00:17:14,760 --> 00:17:14,770
we now call it the Cretaceous extinction
 

733
00:17:14,770 --> 00:17:17,220
we now call it the Cretaceous extinction
event there's been debate as to whether

734
00:17:17,220 --> 00:17:17,230
event there's been debate as to whether
 

735
00:17:17,230 --> 00:17:20,480
event there's been debate as to whether
it was a media or an asteroid I mean a

736
00:17:20,480 --> 00:17:20,490
it was a media or an asteroid I mean a
 

737
00:17:20,490 --> 00:17:24,720
it was a media or an asteroid I mean a
meteor or a volcanic eruption the

738
00:17:24,720 --> 00:17:24,730
meteor or a volcanic eruption the
 

739
00:17:24,730 --> 00:17:27,870
meteor or a volcanic eruption the
asteroid or meteor hypothesis is in the

740
00:17:27,870 --> 00:17:27,880
asteroid or meteor hypothesis is in the
 

741
00:17:27,880 --> 00:17:31,289
asteroid or meteor hypothesis is in the
ascendancy but if you dig down to an

742
00:17:31,289 --> 00:17:31,299
ascendancy but if you dig down to an
 

743
00:17:31,299 --> 00:17:33,840
ascendancy but if you dig down to an
area of rock reflecting 65 million years

744
00:17:33,840 --> 00:17:33,850
area of rock reflecting 65 million years
 

745
00:17:33,850 --> 00:17:34,840
area of rock reflecting 65 million years
ago the

746
00:17:34,840 --> 00:17:34,850
ago the
 

747
00:17:34,850 --> 00:17:36,889
ago the
geologists will explain that it shows a

748
00:17:36,889 --> 00:17:36,899
geologists will explain that it shows a
 

749
00:17:36,899 --> 00:17:39,260
geologists will explain that it shows a
very violent sudden change to the

750
00:17:39,260 --> 00:17:39,270
very violent sudden change to the
 

751
00:17:39,270 --> 00:17:41,060
very violent sudden change to the
environment we see it all around the

752
00:17:41,060 --> 00:17:41,070
environment we see it all around the
 

753
00:17:41,070 --> 00:17:44,810
environment we see it all around the
globe so is a worldwide phenomenon the

754
00:17:44,810 --> 00:17:44,820
globe so is a worldwide phenomenon the
 

755
00:17:44,820 --> 00:17:48,080
globe so is a worldwide phenomenon the
reason we call it an extinction event is

756
00:17:48,080 --> 00:17:48,090
reason we call it an extinction event is
 

757
00:17:48,090 --> 00:17:50,440
reason we call it an extinction event is
that's when the dinosaurs went extinct

758
00:17:50,440 --> 00:17:50,450
that's when the dinosaurs went extinct
 

759
00:17:50,450 --> 00:17:54,740
that's when the dinosaurs went extinct
that's when 75% of all the animal and

760
00:17:54,740 --> 00:17:54,750
that's when 75% of all the animal and
 

761
00:17:54,750 --> 00:17:57,049
that's when 75% of all the animal and
plant species went extinct and that's

762
00:17:57,049 --> 00:17:57,059
plant species went extinct and that's
 

763
00:17:57,059 --> 00:17:58,669
plant species went extinct and that's
when mammals overtook their ecological

764
00:17:58,669 --> 00:17:58,679
when mammals overtook their ecological
 

765
00:17:58,679 --> 00:18:02,149
when mammals overtook their ecological
niche so to anthropomorphize biological

766
00:18:02,149 --> 00:18:02,159
niche so to anthropomorphize biological
 

767
00:18:02,159 --> 00:18:05,149
niche so to anthropomorphize biological
evolution said to itself this neocortex

768
00:18:05,149 --> 00:18:05,159
evolution said to itself this neocortex
 

769
00:18:05,159 --> 00:18:07,010
evolution said to itself this neocortex
is pretty good stuff and it began to

770
00:18:07,010 --> 00:18:07,020
is pretty good stuff and it began to
 

771
00:18:07,020 --> 00:18:09,799
is pretty good stuff and it began to
grow it so-now mammals got bigger their

772
00:18:09,799 --> 00:18:09,809
grow it so-now mammals got bigger their
 

773
00:18:09,809 --> 00:18:11,690
grow it so-now mammals got bigger their
brains got bigger at an even faster pace

774
00:18:11,690 --> 00:18:11,700
brains got bigger at an even faster pace
 

775
00:18:11,700 --> 00:18:13,430
brains got bigger at an even faster pace
taking up a larger fraction of their

776
00:18:13,430 --> 00:18:13,440
taking up a larger fraction of their
 

777
00:18:13,440 --> 00:18:16,279
taking up a larger fraction of their
body the neocortex got bigger even

778
00:18:16,279 --> 00:18:16,289
body the neocortex got bigger even
 

779
00:18:16,289 --> 00:18:18,350
body the neocortex got bigger even
faster than that and developed these

780
00:18:18,350 --> 00:18:18,360
faster than that and developed these
 

781
00:18:18,360 --> 00:18:21,039
faster than that and developed these
curvatures that are distinctive of a

782
00:18:21,039 --> 00:18:21,049
curvatures that are distinctive of a
 

783
00:18:21,049 --> 00:18:24,740
curvatures that are distinctive of a
primate brain basically to increase its

784
00:18:24,740 --> 00:18:24,750
primate brain basically to increase its
 

785
00:18:24,750 --> 00:18:26,740
primate brain basically to increase its
surface area but if you stretched it out

786
00:18:26,740 --> 00:18:26,750
surface area but if you stretched it out
 

787
00:18:26,750 --> 00:18:29,299
surface area but if you stretched it out
the human neocortex is still a flat

788
00:18:29,299 --> 00:18:29,309
the human neocortex is still a flat
 

789
00:18:29,309 --> 00:18:31,010
the human neocortex is still a flat
structure it's about the size of a table

790
00:18:31,010 --> 00:18:31,020
structure it's about the size of a table
 

791
00:18:31,020 --> 00:18:39,490
structure it's about the size of a table
napkin just as thin and it's basically

792
00:18:39,490 --> 00:18:39,500
napkin just as thin and it's basically
 

793
00:18:39,500 --> 00:18:44,269
napkin just as thin and it's basically
created primates which became dominance

794
00:18:44,269 --> 00:18:44,279
created primates which became dominance
 

795
00:18:44,279 --> 00:18:48,049
created primates which became dominance
in their ecological niche then something

796
00:18:48,049 --> 00:18:48,059
in their ecological niche then something
 

797
00:18:48,059 --> 00:18:49,250
in their ecological niche then something
else happened two million years ago

798
00:18:49,250 --> 00:18:49,260
else happened two million years ago
 

799
00:18:49,260 --> 00:18:53,000
else happened two million years ago
biological evolution decided to increase

800
00:18:53,000 --> 00:18:53,010
biological evolution decided to increase
 

801
00:18:53,010 --> 00:18:55,700
biological evolution decided to increase
the neocortex further and increase the

802
00:18:55,700 --> 00:18:55,710
the neocortex further and increase the
 

803
00:18:55,710 --> 00:18:57,919
the neocortex further and increase the
size of the enclosure and basically

804
00:18:57,919 --> 00:18:57,929
size of the enclosure and basically
 

805
00:18:57,929 --> 00:19:00,649
size of the enclosure and basically
filled up the frontal cortex with our

806
00:19:00,649 --> 00:19:00,659
filled up the frontal cortex with our
 

807
00:19:00,659 --> 00:19:04,250
filled up the frontal cortex with our
big skulls with more neocortex and up

808
00:19:04,250 --> 00:19:04,260
big skulls with more neocortex and up
 

809
00:19:04,260 --> 00:19:06,440
big skulls with more neocortex and up
until recently it was felt that as I

810
00:19:06,440 --> 00:19:06,450
until recently it was felt that as I
 

811
00:19:06,450 --> 00:19:08,600
until recently it was felt that as I
said that this was the frontal cortex

812
00:19:08,600 --> 00:19:08,610
said that this was the frontal cortex
 

813
00:19:08,610 --> 00:19:10,490
said that this was the frontal cortex
was different because it does these

814
00:19:10,490 --> 00:19:10,500
was different because it does these
 

815
00:19:10,500 --> 00:19:16,880
was different because it does these
qualitatively different things but we

816
00:19:16,880 --> 00:19:16,890
qualitatively different things but we
 

817
00:19:16,890 --> 00:19:19,460
qualitatively different things but we
now realize that it's really just

818
00:19:19,460 --> 00:19:19,470
now realize that it's really just
 

819
00:19:19,470 --> 00:19:26,389
now realize that it's really just
additional neocortex so remember what we

820
00:19:26,389 --> 00:19:26,399
additional neocortex so remember what we
 

821
00:19:26,399 --> 00:19:28,909
additional neocortex so remember what we
did with it we're already doing a very

822
00:19:28,909 --> 00:19:28,919
did with it we're already doing a very
 

823
00:19:28,919 --> 00:19:30,529
did with it we're already doing a very
good job of being primates so we put it

824
00:19:30,529 --> 00:19:30,539
good job of being primates so we put it
 

825
00:19:30,539 --> 00:19:32,990
good job of being primates so we put it
at the top of the neocortical hierarchy

826
00:19:32,990 --> 00:19:33,000
at the top of the neocortical hierarchy
 

827
00:19:33,000 --> 00:19:35,450
at the top of the neocortical hierarchy
and we increased the size of the

828
00:19:35,450 --> 00:19:35,460
and we increased the size of the
 

829
00:19:35,460 --> 00:19:38,060
and we increased the size of the
hierarchy it was maybe 20% more

830
00:19:38,060 --> 00:19:38,070
hierarchy it was maybe 20% more
 

831
00:19:38,070 --> 00:19:40,669
hierarchy it was maybe 20% more
neocortex but it doubled it tripled the

832
00:19:40,669 --> 00:19:40,679
neocortex but it doubled it tripled the
 

833
00:19:40,679 --> 00:19:42,529
neocortex but it doubled it tripled the
number of levels because as you go up

834
00:19:42,529 --> 00:19:42,539
number of levels because as you go up
 

835
00:19:42,539 --> 00:19:43,669
number of levels because as you go up
the hierarchy it's kind of like a

836
00:19:43,669 --> 00:19:43,679
the hierarchy it's kind of like a
 

837
00:19:43,679 --> 00:19:46,770
the hierarchy it's kind of like a
pyramid there's fewer and fewer modules

838
00:19:46,770 --> 00:19:46,780
pyramid there's fewer and fewer modules
 

839
00:19:46,780 --> 00:19:50,310
pyramid there's fewer and fewer modules
and that was the enabling factor for us

840
00:19:50,310 --> 00:19:50,320
and that was the enabling factor for us
 

841
00:19:50,320 --> 00:19:54,320
and that was the enabling factor for us
to invent language and art music every

842
00:19:54,320 --> 00:19:54,330
to invent language and art music every
 

843
00:19:54,330 --> 00:19:56,640
to invent language and art music every
human culture we've ever discovered has

844
00:19:56,640 --> 00:19:56,650
human culture we've ever discovered has
 

845
00:19:56,650 --> 00:19:58,620
human culture we've ever discovered has
music no primary culture really has

846
00:19:58,620 --> 00:19:58,630
music no primary culture really has
 

847
00:19:58,630 --> 00:20:01,050
music no primary culture really has
music there's debate about that but it's

848
00:20:01,050 --> 00:20:01,060
music there's debate about that but it's
 

849
00:20:01,060 --> 00:20:04,459
music there's debate about that but it's
really true

850
00:20:04,459 --> 00:20:04,469
really true
 

851
00:20:04,469 --> 00:20:08,369
really true
invention technology technology required

852
00:20:08,369 --> 00:20:08,379
invention technology technology required
 

853
00:20:08,379 --> 00:20:10,889
invention technology technology required
another evolutionary adaptation which is

854
00:20:10,889 --> 00:20:10,899
another evolutionary adaptation which is
 

855
00:20:10,899 --> 00:20:14,219
another evolutionary adaptation which is
this humble appendage here no other

856
00:20:14,219 --> 00:20:14,229
this humble appendage here no other
 

857
00:20:14,229 --> 00:20:15,869
this humble appendage here no other
animal has that if you look at a chimp

858
00:20:15,869 --> 00:20:15,879
animal has that if you look at a chimp
 

859
00:20:15,879 --> 00:20:16,859
animal has that if you look at a chimp
and see it looks like they have a

860
00:20:16,859 --> 00:20:16,869
and see it looks like they have a
 

861
00:20:16,869 --> 00:20:18,119
and see it looks like they have a
similar hand but the thumb is actually

862
00:20:18,119 --> 00:20:18,129
similar hand but the thumb is actually
 

863
00:20:18,129 --> 00:20:20,159
similar hand but the thumb is actually
down here doesn't work very well if you

864
00:20:20,159 --> 00:20:20,169
down here doesn't work very well if you
 

865
00:20:20,169 --> 00:20:23,009
down here doesn't work very well if you
watch them trying to grab a stick so we

866
00:20:23,009 --> 00:20:23,019
watch them trying to grab a stick so we
 

867
00:20:23,019 --> 00:20:26,190
watch them trying to grab a stick so we
could imagine creative solutions yeah I

868
00:20:26,190 --> 00:20:26,200
could imagine creative solutions yeah I
 

869
00:20:26,200 --> 00:20:28,949
could imagine creative solutions yeah I
could take that branch and strip off the

870
00:20:28,949 --> 00:20:28,959
could take that branch and strip off the
 

871
00:20:28,959 --> 00:20:31,139
could take that branch and strip off the
leaves and put a point on it and we

872
00:20:31,139 --> 00:20:31,149
leaves and put a point on it and we
 

873
00:20:31,149 --> 00:20:34,769
leaves and put a point on it and we
could actually carry out these ideas and

874
00:20:34,769 --> 00:20:34,779
could actually carry out these ideas and
 

875
00:20:34,779 --> 00:20:37,079
could actually carry out these ideas and
create tools and then use tools to

876
00:20:37,079 --> 00:20:37,089
create tools and then use tools to
 

877
00:20:37,089 --> 00:20:38,969
create tools and then use tools to
create new tools and it started a whole

878
00:20:38,969 --> 00:20:38,979
create new tools and it started a whole
 

879
00:20:38,979 --> 00:20:41,310
create new tools and it started a whole
nother evolutionary process of

880
00:20:41,310 --> 00:20:41,320
nother evolutionary process of
 

881
00:20:41,320 --> 00:20:43,739
nother evolutionary process of
tool-making and that all came with the

882
00:20:43,739 --> 00:20:43,749
tool-making and that all came with the
 

883
00:20:43,749 --> 00:20:46,369
tool-making and that all came with the
with the neocortex

884
00:20:46,369 --> 00:20:46,379
with the neocortex
 

885
00:20:46,379 --> 00:20:51,810
with the neocortex
so Larry Page read my book in 2012 and

886
00:20:51,810 --> 00:20:51,820
so Larry Page read my book in 2012 and
 

887
00:20:51,820 --> 00:20:53,879
so Larry Page read my book in 2012 and
liked it so I met with him in Essen for

888
00:20:53,879 --> 00:20:53,889
liked it so I met with him in Essen for
 

889
00:20:53,889 --> 00:20:56,969
liked it so I met with him in Essen for
an investment in a company I'd started

890
00:20:56,969 --> 00:20:56,979
an investment in a company I'd started
 

891
00:20:56,979 --> 00:21:00,060
an investment in a company I'd started
actually a couple weeks earlier to

892
00:21:00,060 --> 00:21:00,070
actually a couple weeks earlier to
 

893
00:21:00,070 --> 00:21:01,739
actually a couple weeks earlier to
develop those ideas commercially because

894
00:21:01,739 --> 00:21:01,749
develop those ideas commercially because
 

895
00:21:01,749 --> 00:21:03,289
develop those ideas commercially because
that's how I went about things as a

896
00:21:03,289 --> 00:21:03,299
that's how I went about things as a
 

897
00:21:03,299 --> 00:21:06,620
that's how I went about things as a
serial entrepreneur

898
00:21:06,620 --> 00:21:06,630
serial entrepreneur
 

899
00:21:06,630 --> 00:21:08,720
serial entrepreneur
and said well we'll invest but let me

900
00:21:08,720 --> 00:21:08,730
and said well we'll invest but let me
 

901
00:21:08,730 --> 00:21:10,100
and said well we'll invest but let me
give you a better idea what you do it

902
00:21:10,100 --> 00:21:10,110
give you a better idea what you do it
 

903
00:21:10,110 --> 00:21:12,260
give you a better idea what you do it
here at Google we have a billion

904
00:21:12,260 --> 00:21:12,270
here at Google we have a billion
 

905
00:21:12,270 --> 00:21:14,180
here at Google we have a billion
pictures of dogs and cats and we've got

906
00:21:14,180 --> 00:21:14,190
pictures of dogs and cats and we've got
 

907
00:21:14,190 --> 00:21:15,799
pictures of dogs and cats and we've got
a lot of other data and lots of

908
00:21:15,799 --> 00:21:15,809
a lot of other data and lots of
 

909
00:21:15,809 --> 00:21:18,020
a lot of other data and lots of
computers and lots of talent all of

910
00:21:18,020 --> 00:21:18,030
computers and lots of talent all of
 

911
00:21:18,030 --> 00:21:20,240
computers and lots of talent all of
which is true and says well I don't know

912
00:21:20,240 --> 00:21:20,250
which is true and says well I don't know
 

913
00:21:20,250 --> 00:21:23,600
which is true and says well I don't know
I just started this company to develop

914
00:21:23,600 --> 00:21:23,610
I just started this company to develop
 

915
00:21:23,610 --> 00:21:26,060
I just started this company to develop
this is well by your company and how you

916
00:21:26,060 --> 00:21:26,070
this is well by your company and how you
 

917
00:21:26,070 --> 00:21:27,620
this is well by your company and how you
got a value a company that hasn't done

918
00:21:27,620 --> 00:21:27,630
got a value a company that hasn't done
 

919
00:21:27,630 --> 00:21:29,779
got a value a company that hasn't done
anything just started a couple weeks ago

920
00:21:29,779 --> 00:21:29,789
anything just started a couple weeks ago
 

921
00:21:29,789 --> 00:21:34,730
anything just started a couple weeks ago
and he said we can value anything so I

922
00:21:34,730 --> 00:21:34,740
and he said we can value anything so I
 

923
00:21:34,740 --> 00:21:37,940
and he said we can value anything so I
took my first job five years ago and

924
00:21:37,940 --> 00:21:37,950
took my first job five years ago and
 

925
00:21:37,950 --> 00:21:40,750
took my first job five years ago and
I've been basically applying this model

926
00:21:40,750 --> 00:21:40,760
I've been basically applying this model
 

927
00:21:40,760 --> 00:21:45,890
I've been basically applying this model
this hierarchical model to understanding

928
00:21:45,890 --> 00:21:45,900
this hierarchical model to understanding
 

929
00:21:45,900 --> 00:21:47,600
this hierarchical model to understanding
language which i think really is the

930
00:21:47,600 --> 00:21:47,610
language which i think really is the
 

931
00:21:47,610 --> 00:21:51,440
language which i think really is the
holy grail of AI I think Turing was

932
00:21:51,440 --> 00:21:51,450
holy grail of AI I think Turing was
 

933
00:21:51,450 --> 00:21:55,610
holy grail of AI I think Turing was
correct in designating basically text

934
00:21:55,610 --> 00:21:55,620
correct in designating basically text
 

935
00:21:55,620 --> 00:22:00,049
correct in designating basically text
communication as what we now call a

936
00:22:00,049 --> 00:22:00,059
communication as what we now call a
 

937
00:22:00,059 --> 00:22:01,730
communication as what we now call a
turing-complete problem that requires

938
00:22:01,730 --> 00:22:01,740
turing-complete problem that requires
 

939
00:22:01,740 --> 00:22:04,820
turing-complete problem that requires
there's no simple NLP tricks it you can

940
00:22:04,820 --> 00:22:04,830
there's no simple NLP tricks it you can
 

941
00:22:04,830 --> 00:22:08,480
there's no simple NLP tricks it you can
apply to pass a valid Turing test with

942
00:22:08,480 --> 00:22:08,490
apply to pass a valid Turing test with
 

943
00:22:08,490 --> 00:22:10,970
apply to pass a valid Turing test with
an emphasis on the word valid mitch

944
00:22:10,970 --> 00:22:10,980
an emphasis on the word valid mitch
 

945
00:22:10,980 --> 00:22:13,789
an emphasis on the word valid mitch
kapor and i had a six month debate on

946
00:22:13,789 --> 00:22:13,799
kapor and i had a six month debate on
 

947
00:22:13,799 --> 00:22:15,830
kapor and i had a six month debate on
what the rules should be because if you

948
00:22:15,830 --> 00:22:15,840
what the rules should be because if you
 

949
00:22:15,840 --> 00:22:19,310
what the rules should be because if you
read Turing's 1950 paper he describes

950
00:22:19,310 --> 00:22:19,320
read Turing's 1950 paper he describes
 

951
00:22:19,320 --> 00:22:20,960
read Turing's 1950 paper he describes
this in a few paragraphs and doesn't

952
00:22:20,960 --> 00:22:20,970
this in a few paragraphs and doesn't
 

953
00:22:20,970 --> 00:22:22,899
this in a few paragraphs and doesn't
really describe how to go about it but

954
00:22:22,899 --> 00:22:22,909
really describe how to go about it but
 

955
00:22:22,909 --> 00:22:25,549
really describe how to go about it but
if it's a valid Turing test meaning it's

956
00:22:25,549 --> 00:22:25,559
if it's a valid Turing test meaning it's
 

957
00:22:25,559 --> 00:22:28,240
if it's a valid Turing test meaning it's
really convincing you through an

958
00:22:28,240 --> 00:22:28,250
really convincing you through an
 

959
00:22:28,250 --> 00:22:32,570
really convincing you through an
interrogation and dialogue that it's a

960
00:22:32,570 --> 00:22:32,580
interrogation and dialogue that it's a
 

961
00:22:32,580 --> 00:22:35,330
interrogation and dialogue that it's a
human that requires a full range of

962
00:22:35,330 --> 00:22:35,340
human that requires a full range of
 

963
00:22:35,340 --> 00:22:39,049
human that requires a full range of
human intelligence and I think that test

964
00:22:39,049 --> 00:22:39,059
human intelligence and I think that test
 

965
00:22:39,059 --> 00:22:42,680
human intelligence and I think that test
has to the test of time we're making

966
00:22:42,680 --> 00:22:42,690
has to the test of time we're making
 

967
00:22:42,690 --> 00:22:44,630
has to the test of time we're making
very good progress on that I mean just

968
00:22:44,630 --> 00:22:44,640
very good progress on that I mean just
 

969
00:22:44,640 --> 00:22:48,470
very good progress on that I mean just
last week you may have read that two

970
00:22:48,470 --> 00:22:48,480
last week you may have read that two
 

971
00:22:48,480 --> 00:22:51,529
last week you may have read that two
systems

972
00:22:51,529 --> 00:22:51,539

 

973
00:22:51,539 --> 00:22:54,889

asked paragraph comprehension test it's

974
00:22:54,889 --> 00:22:54,899
asked paragraph comprehension test it's
 

975
00:22:54,899 --> 00:22:57,440
asked paragraph comprehension test it's
really very impressive winning came to

976
00:22:57,440 --> 00:22:57,450
really very impressive winning came to
 

977
00:22:57,450 --> 00:22:59,539
really very impressive winning came to
Google we were trying to past these

978
00:22:59,539 --> 00:22:59,549
Google we were trying to past these
 

979
00:22:59,549 --> 00:23:02,119
Google we were trying to past these
paragraph comprehension tests we aced

980
00:23:02,119 --> 00:23:02,129
paragraph comprehension tests we aced
 

981
00:23:02,129 --> 00:23:06,109
paragraph comprehension tests we aced
the first the first grade test second

982
00:23:06,109 --> 00:23:06,119
the first the first grade test second
 

983
00:23:06,119 --> 00:23:07,489
the first the first grade test second
grade tests were kind of got average

984
00:23:07,489 --> 00:23:07,499
grade tests were kind of got average
 

985
00:23:07,499 --> 00:23:10,009
grade tests were kind of got average
performance and the third grade test had

986
00:23:10,009 --> 00:23:10,019
performance and the third grade test had
 

987
00:23:10,019 --> 00:23:12,830
performance and the third grade test had
too much inference already you had to

988
00:23:12,830 --> 00:23:12,840
too much inference already you had to
 

989
00:23:12,840 --> 00:23:15,680
too much inference already you had to
know some common-sense knowledge as it's

990
00:23:15,680 --> 00:23:15,690
know some common-sense knowledge as it's
 

991
00:23:15,690 --> 00:23:19,129
know some common-sense knowledge as it's
called and make implications of things

992
00:23:19,129 --> 00:23:19,139
called and make implications of things
 

993
00:23:19,139 --> 00:23:20,210
called and make implications of things
that were in different parts of the

994
00:23:20,210 --> 00:23:20,220
that were in different parts of the
 

995
00:23:20,220 --> 00:23:22,399
that were in different parts of the
paragraph and there's too much inference

996
00:23:22,399 --> 00:23:22,409
paragraph and there's too much inference
 

997
00:23:22,409 --> 00:23:24,589
paragraph and there's too much inference
and it really didn't didn't work so this

998
00:23:24,589 --> 00:23:24,599
and it really didn't didn't work so this
 

999
00:23:24,599 --> 00:23:27,919
and it really didn't didn't work so this
is now adult level it's just slightly

1000
00:23:27,919 --> 00:23:27,929
is now adult level it's just slightly
 

1001
00:23:27,929 --> 00:23:31,669
is now adult level it's just slightly
surpassed average human performance but

1002
00:23:31,669 --> 00:23:31,679
surpassed average human performance but
 

1003
00:23:31,679 --> 00:23:34,129
surpassed average human performance but
we've seen that once something an AI

1004
00:23:34,129 --> 00:23:34,139
we've seen that once something an AI
 

1005
00:23:34,139 --> 00:23:37,099
we've seen that once something an AI
does something it average human levels

1006
00:23:37,099 --> 00:23:37,109
does something it average human levels
 

1007
00:23:37,109 --> 00:23:39,609
does something it average human levels
it doesn't take long for it to soar past

1008
00:23:39,609 --> 00:23:39,619
it doesn't take long for it to soar past
 

1009
00:23:39,619 --> 00:23:41,749
it doesn't take long for it to soar past
average human levels I think it'll take

1010
00:23:41,749 --> 00:23:41,759
average human levels I think it'll take
 

1011
00:23:41,759 --> 00:23:43,729
average human levels I think it'll take
longer in language and it did in some

1012
00:23:43,729 --> 00:23:43,739
longer in language and it did in some
 

1013
00:23:43,739 --> 00:23:46,580
longer in language and it did in some
simple games like go but it's actually

1014
00:23:46,580 --> 00:23:46,590
simple games like go but it's actually
 

1015
00:23:46,590 --> 00:23:48,830
simple games like go but it's actually
very impressive that it surpasses now

1016
00:23:48,830 --> 00:23:48,840
very impressive that it surpasses now
 

1017
00:23:48,840 --> 00:23:52,639
very impressive that it surpasses now
average human performance used at LST M

1018
00:23:52,639 --> 00:23:52,649
average human performance used at LST M
 

1019
00:23:52,649 --> 00:23:56,810
average human performance used at LST M
long short temporal memory but if you

1020
00:23:56,810 --> 00:23:56,820
long short temporal memory but if you
 

1021
00:23:56,820 --> 00:23:58,909
long short temporal memory but if you
look at the adult test in order to

1022
00:23:58,909 --> 00:23:58,919
look at the adult test in order to
 

1023
00:23:58,919 --> 00:24:00,680
look at the adult test in order to
answer these questions it has to put

1024
00:24:00,680 --> 00:24:00,690
answer these questions it has to put
 

1025
00:24:00,690 --> 00:24:02,899
answer these questions it has to put
together inferences and implications of

1026
00:24:02,899 --> 00:24:02,909
together inferences and implications of
 

1027
00:24:02,909 --> 00:24:04,729
together inferences and implications of
several different things in the

1028
00:24:04,729 --> 00:24:04,739
several different things in the
 

1029
00:24:04,739 --> 00:24:06,739
several different things in the
paragraph with some common sense

1030
00:24:06,739 --> 00:24:06,749
paragraph with some common sense
 

1031
00:24:06,749 --> 00:24:10,219
paragraph with some common sense
knowledge is not explicitly stated so

1032
00:24:10,219 --> 00:24:10,229
knowledge is not explicitly stated so
 

1033
00:24:10,229 --> 00:24:12,519
knowledge is not explicitly stated so
that's I think a pretty impressive

1034
00:24:12,519 --> 00:24:12,529
that's I think a pretty impressive
 

1035
00:24:12,529 --> 00:24:16,700
that's I think a pretty impressive
milestone so I I've been developing I've

1036
00:24:16,700 --> 00:24:16,710
milestone so I I've been developing I've
 

1037
00:24:16,710 --> 00:24:21,019
milestone so I I've been developing I've
got a team of about 45 people and we've

1038
00:24:21,019 --> 00:24:21,029
got a team of about 45 people and we've
 

1039
00:24:21,029 --> 00:24:23,389
got a team of about 45 people and we've
been developing this hierarchical model

1040
00:24:23,389 --> 00:24:23,399
been developing this hierarchical model
 

1041
00:24:23,399 --> 00:24:26,450
been developing this hierarchical model
we don't use Markov models because we

1042
00:24:26,450 --> 00:24:26,460
we don't use Markov models because we
 

1043
00:24:26,460 --> 00:24:29,320
we don't use Markov models because we
can use deep learning for each module

1044
00:24:29,320 --> 00:24:29,330
can use deep learning for each module
 

1045
00:24:29,330 --> 00:24:31,820
can use deep learning for each module
and so we create an embedding for each

1046
00:24:31,820 --> 00:24:31,830
and so we create an embedding for each
 

1047
00:24:31,830 --> 00:24:34,249
and so we create an embedding for each
word and we create an embedding for each

1048
00:24:34,249 --> 00:24:34,259
word and we create an embedding for each
 

1049
00:24:34,259 --> 00:24:38,029
word and we create an embedding for each
sentence this is we have a I can talk

1050
00:24:38,029 --> 00:24:38,039
sentence this is we have a I can talk
 

1051
00:24:38,039 --> 00:24:39,169
sentence this is we have a I can talk
about it because we have a published

1052
00:24:39,169 --> 00:24:39,179
about it because we have a published
 

1053
00:24:39,179 --> 00:24:41,769
about it because we have a published
paper on it it can take into

1054
00:24:41,769 --> 00:24:41,779
paper on it it can take into
 

1055
00:24:41,779 --> 00:24:44,790
paper on it it can take into
consideration context

1056
00:24:44,790 --> 00:24:44,800
consideration context
 

1057
00:24:44,800 --> 00:24:48,600
consideration context
if you use smart reply on G confused

1058
00:24:48,600 --> 00:24:48,610
if you use smart reply on G confused
 

1059
00:24:48,610 --> 00:24:50,250
if you use smart reply on G confused
email on your phone you'll see it gives

1060
00:24:50,250 --> 00:24:50,260
email on your phone you'll see it gives
 

1061
00:24:50,260 --> 00:24:52,890
email on your phone you'll see it gives
you three suggestions for responses

1062
00:24:52,890 --> 00:24:52,900
you three suggestions for responses
 

1063
00:24:52,900 --> 00:24:56,100
you three suggestions for responses
that's called Smart reply there are

1064
00:24:56,100 --> 00:24:56,110
that's called Smart reply there are
 

1065
00:24:56,110 --> 00:25:00,000
that's called Smart reply there are
simple suggestions but it has to

1066
00:25:00,000 --> 00:25:00,010
simple suggestions but it has to
 

1067
00:25:00,010 --> 00:25:01,620
simple suggestions but it has to
actually understand perhaps a

1068
00:25:01,620 --> 00:25:01,630
actually understand perhaps a
 

1069
00:25:01,630 --> 00:25:04,530
actually understand perhaps a
complicated email and the quality of the

1070
00:25:04,530 --> 00:25:04,540
complicated email and the quality of the
 

1071
00:25:04,540 --> 00:25:06,750
complicated email and the quality of the
suggestions is really quite good quite

1072
00:25:06,750 --> 00:25:06,760
suggestions is really quite good quite
 

1073
00:25:06,760 --> 00:25:09,930
suggestions is really quite good quite
on point that's for my team using this

1074
00:25:09,930 --> 00:25:09,940
on point that's for my team using this
 

1075
00:25:09,940 --> 00:25:12,900
on point that's for my team using this
kind of hierarchical model so instead of

1076
00:25:12,900 --> 00:25:12,910
kind of hierarchical model so instead of
 

1077
00:25:12,910 --> 00:25:15,920
kind of hierarchical model so instead of
Markov models that uses embeddings

1078
00:25:15,920 --> 00:25:15,930
Markov models that uses embeddings
 

1079
00:25:15,930 --> 00:25:19,260
Markov models that uses embeddings
because we can use back propagation we

1080
00:25:19,260 --> 00:25:19,270
because we can use back propagation we
 

1081
00:25:19,270 --> 00:25:22,260
because we can use back propagation we
might as well use it but I think what's

1082
00:25:22,260 --> 00:25:22,270
might as well use it but I think what's
 

1083
00:25:22,270 --> 00:25:25,920
might as well use it but I think what's
missing from deep learning is this

1084
00:25:25,920 --> 00:25:25,930
missing from deep learning is this
 

1085
00:25:25,930 --> 00:25:29,130
missing from deep learning is this
hierarchical aspect of understanding

1086
00:25:29,130 --> 00:25:29,140
hierarchical aspect of understanding
 

1087
00:25:29,140 --> 00:25:30,810
hierarchical aspect of understanding
because the world is hierarchical that's

1088
00:25:30,810 --> 00:25:30,820
because the world is hierarchical that's
 

1089
00:25:30,820 --> 00:25:34,620
because the world is hierarchical that's
why evolution developed a hierarchical

1090
00:25:34,620 --> 00:25:34,630
why evolution developed a hierarchical
 

1091
00:25:34,630 --> 00:25:37,110
why evolution developed a hierarchical
brain structure to understand the

1092
00:25:37,110 --> 00:25:37,120
brain structure to understand the
 

1093
00:25:37,120 --> 00:25:40,580
brain structure to understand the
natural hierarchy in the world

1094
00:25:40,580 --> 00:25:40,590
natural hierarchy in the world
 

1095
00:25:40,590 --> 00:25:43,820
natural hierarchy in the world
and there are several problems with big

1096
00:25:43,820 --> 00:25:43,830
and there are several problems with big
 

1097
00:25:43,830 --> 00:25:45,980
and there are several problems with big
deep neural nets one is the fact that

1098
00:25:45,980 --> 00:25:45,990
deep neural nets one is the fact that
 

1099
00:25:45,990 --> 00:25:47,989
deep neural nets one is the fact that
you really do need a billion examples

1100
00:25:47,989 --> 00:25:47,999
you really do need a billion examples
 

1101
00:25:47,999 --> 00:25:49,909
you really do need a billion examples
and we don't sometimes we can generate

1102
00:25:49,909 --> 00:25:49,919
and we don't sometimes we can generate
 

1103
00:25:49,919 --> 00:25:52,879
and we don't sometimes we can generate
them it's in the case of NGO or if we

1104
00:25:52,879 --> 00:25:52,889
them it's in the case of NGO or if we
 

1105
00:25:52,889 --> 00:25:55,070
them it's in the case of NGO or if we
have a really good simulator as in the

1106
00:25:55,070 --> 00:25:55,080
have a really good simulator as in the
 

1107
00:25:55,080 --> 00:25:57,019
have a really good simulator as in the
case of autonomous vehicles not quite

1108
00:25:57,019 --> 00:25:57,029
case of autonomous vehicles not quite
 

1109
00:25:57,029 --> 00:26:00,590
case of autonomous vehicles not quite
the case yet in biology very often you

1110
00:26:00,590 --> 00:26:00,600
the case yet in biology very often you
 

1111
00:26:00,600 --> 00:26:02,930
the case yet in biology very often you
don't have a billion example if you

1112
00:26:02,930 --> 00:26:02,940
don't have a billion example if you
 

1113
00:26:02,940 --> 00:26:04,549
don't have a billion example if you
suddenly have billions of examples of

1114
00:26:04,549 --> 00:26:04,559
suddenly have billions of examples of
 

1115
00:26:04,559 --> 00:26:06,860
suddenly have billions of examples of
language but they're not annotated and

1116
00:26:06,860 --> 00:26:06,870
language but they're not annotated and
 

1117
00:26:06,870 --> 00:26:08,419
language but they're not annotated and
how would you annotate it anyway with

1118
00:26:08,419 --> 00:26:08,429
how would you annotate it anyway with
 

1119
00:26:08,429 --> 00:26:09,980
how would you annotate it anyway with
more language that we can't understand

1120
00:26:09,980 --> 00:26:09,990
more language that we can't understand
 

1121
00:26:09,990 --> 00:26:11,330
more language that we can't understand
in the first place so that's kind of a

1122
00:26:11,330 --> 00:26:11,340
in the first place so that's kind of a
 

1123
00:26:11,340 --> 00:26:15,499
in the first place so that's kind of a
chicken and an egg problem so I believe

1124
00:26:15,499 --> 00:26:15,509
chicken and an egg problem so I believe
 

1125
00:26:15,509 --> 00:26:17,029
chicken and an egg problem so I believe
this hierarchical structures needed

1126
00:26:17,029 --> 00:26:17,039
this hierarchical structures needed
 

1127
00:26:17,039 --> 00:26:19,340
this hierarchical structures needed
another criticism of deep neural Nets

1128
00:26:19,340 --> 00:26:19,350
another criticism of deep neural Nets
 

1129
00:26:19,350 --> 00:26:21,019
another criticism of deep neural Nets
they don't explain themselves very well

1130
00:26:21,019 --> 00:26:21,029
they don't explain themselves very well
 

1131
00:26:21,029 --> 00:26:24,940
they don't explain themselves very well
it's a big black box that gives you

1132
00:26:24,940 --> 00:26:24,950
it's a big black box that gives you
 

1133
00:26:24,950 --> 00:26:27,739
it's a big black box that gives you
pretty remarkable answers I mean in the

1134
00:26:27,739 --> 00:26:27,749
pretty remarkable answers I mean in the
 

1135
00:26:27,749 --> 00:26:31,100
pretty remarkable answers I mean in the
case of these games demos described it's

1136
00:26:31,100 --> 00:26:31,110
case of these games demos described it's
 

1137
00:26:31,110 --> 00:26:33,230
case of these games demos described it's
playing in both go and chess is almost

1138
00:26:33,230 --> 00:26:33,240
playing in both go and chess is almost
 

1139
00:26:33,240 --> 00:26:34,940
playing in both go and chess is almost
an alien intelligence because we do

1140
00:26:34,940 --> 00:26:34,950
an alien intelligence because we do
 

1141
00:26:34,950 --> 00:26:36,950
an alien intelligence because we do
things that were shocking to you and

1142
00:26:36,950 --> 00:26:36,960
things that were shocking to you and
 

1143
00:26:36,960 --> 00:26:39,799
things that were shocking to you and
experts like sacrificing a queen and a

1144
00:26:39,799 --> 00:26:39,809
experts like sacrificing a queen and a
 

1145
00:26:39,809 --> 00:26:42,830
experts like sacrificing a queen and a
bishop at the same time or in close

1146
00:26:42,830 --> 00:26:42,840
bishop at the same time or in close
 

1147
00:26:42,840 --> 00:26:46,190
bishop at the same time or in close
succession which shocked everybody but

1148
00:26:46,190 --> 00:26:46,200
succession which shocked everybody but
 

1149
00:26:46,200 --> 00:26:48,499
succession which shocked everybody but
then went on to win or early in a go

1150
00:26:48,499 --> 00:26:48,509
then went on to win or early in a go
 

1151
00:26:48,509 --> 00:26:50,680
then went on to win or early in a go
game putting a piece at the corner of

1152
00:26:50,680 --> 00:26:50,690
game putting a piece at the corner of
 

1153
00:26:50,690 --> 00:26:54,320
game putting a piece at the corner of
the board which is kind of crazy to most

1154
00:26:54,320 --> 00:26:54,330
the board which is kind of crazy to most
 

1155
00:26:54,330 --> 00:26:56,090
the board which is kind of crazy to most
experts because you really want to start

1156
00:26:56,090 --> 00:26:56,100
experts because you really want to start
 

1157
00:26:56,100 --> 00:26:58,549
experts because you really want to start
controlling territory and yet it on

1158
00:26:58,549 --> 00:26:58,559
controlling territory and yet it on
 

1159
00:26:58,559 --> 00:27:00,769
controlling territory and yet it on
reflection that was the brilliant move

1160
00:27:00,769 --> 00:27:00,779
reflection that was the brilliant move
 

1161
00:27:00,779 --> 00:27:05,509
reflection that was the brilliant move
that enabled it to win that game but it

1162
00:27:05,509 --> 00:27:05,519
that enabled it to win that game but it
 

1163
00:27:05,519 --> 00:27:07,159
that enabled it to win that game but it
doesn't really explain how it does these

1164
00:27:07,159 --> 00:27:07,169
doesn't really explain how it does these
 

1165
00:27:07,169 --> 00:27:08,690
doesn't really explain how it does these
things so if yeah if you have a

1166
00:27:08,690 --> 00:27:08,700
things so if yeah if you have a
 

1167
00:27:08,700 --> 00:27:10,999
things so if yeah if you have a
hierarchy it's much better at explaining

1168
00:27:10,999 --> 00:27:11,009
hierarchy it's much better at explaining
 

1169
00:27:11,009 --> 00:27:12,619
hierarchy it's much better at explaining
it because you could look at the content

1170
00:27:12,619 --> 00:27:12,629
it because you could look at the content
 

1171
00:27:12,629 --> 00:27:16,129
it because you could look at the content
of the of the modules in the hierarchy

1172
00:27:16,129 --> 00:27:16,139
of the of the modules in the hierarchy
 

1173
00:27:16,139 --> 00:27:18,950
of the of the modules in the hierarchy
and they'll explain what they're doing

1174
00:27:18,950 --> 00:27:18,960
and they'll explain what they're doing
 

1175
00:27:18,960 --> 00:27:25,369
and they'll explain what they're doing
and just and on the first application of

1176
00:27:25,369 --> 00:27:25,379
and just and on the first application of
 

1177
00:27:25,379 --> 00:27:27,399
and just and on the first application of
applying this to health and medicine

1178
00:27:27,399 --> 00:27:27,409
applying this to health and medicine
 

1179
00:27:27,409 --> 00:27:29,810
applying this to health and medicine
this will get into high gear and we're

1180
00:27:29,810 --> 00:27:29,820
this will get into high gear and we're
 

1181
00:27:29,820 --> 00:27:31,609
this will get into high gear and we're
going to really see us break out at the

1182
00:27:31,609 --> 00:27:31,619
going to really see us break out at the
 

1183
00:27:31,619 --> 00:27:35,840
going to really see us break out at the
linear extension to longevity that we've

1184
00:27:35,840 --> 00:27:35,850
linear extension to longevity that we've
 

1185
00:27:35,850 --> 00:27:38,480
linear extension to longevity that we've
experienced I believe we're only about a

1186
00:27:38,480 --> 00:27:38,490
experienced I believe we're only about a
 

1187
00:27:38,490 --> 00:27:40,430
experienced I believe we're only about a
decade away from longevity escape

1188
00:27:40,430 --> 00:27:40,440
decade away from longevity escape
 

1189
00:27:40,440 --> 00:27:43,609
decade away from longevity escape
velocity we're adding more time than is

1190
00:27:43,609 --> 00:27:43,619
velocity we're adding more time than is
 

1191
00:27:43,619 --> 00:27:45,560
velocity we're adding more time than is
going by not just the infant life

1192
00:27:45,560 --> 00:27:45,570
going by not just the infant life
 

1193
00:27:45,570 --> 00:27:47,930
going by not just the infant life
expectancy but to your remaining life

1194
00:27:47,930 --> 00:27:47,940
expectancy but to your remaining life
 

1195
00:27:47,940 --> 00:27:50,180
expectancy but to your remaining life
expectancy I think if someone is

1196
00:27:50,180 --> 00:27:50,190
expectancy I think if someone is
 

1197
00:27:50,190 --> 00:27:52,310
expectancy I think if someone is
diligent they can be there already I

1198
00:27:52,310 --> 00:27:52,320
diligent they can be there already I
 

1199
00:27:52,320 --> 00:27:53,210
diligent they can be there already I
think I've

1200
00:27:53,210 --> 00:27:53,220
think I've
 

1201
00:27:53,220 --> 00:27:58,190
think I've
at longevity escape velocity now a word

1202
00:27:58,190 --> 00:27:58,200
at longevity escape velocity now a word
 

1203
00:27:58,200 --> 00:28:01,430
at longevity escape velocity now a word
on what life expectancy means it used to

1204
00:28:01,430 --> 00:28:01,440
on what life expectancy means it used to
 

1205
00:28:01,440 --> 00:28:04,660
on what life expectancy means it used to
be assumed that not much would happen so

1206
00:28:04,660 --> 00:28:04,670
be assumed that not much would happen so
 

1207
00:28:04,670 --> 00:28:08,360
be assumed that not much would happen so
whatever your life expectancy is with or

1208
00:28:08,360 --> 00:28:08,370
whatever your life expectancy is with or
 

1209
00:28:08,370 --> 00:28:10,130
whatever your life expectancy is with or
without scientific progress it really

1210
00:28:10,130 --> 00:28:10,140
without scientific progress it really
 

1211
00:28:10,140 --> 00:28:12,680
without scientific progress it really
didn't matter now it matters a lot so

1212
00:28:12,680 --> 00:28:12,690
didn't matter now it matters a lot so
 

1213
00:28:12,690 --> 00:28:14,660
didn't matter now it matters a lot so
life expectancy really means you know

1214
00:28:14,660 --> 00:28:14,670
life expectancy really means you know
 

1215
00:28:14,670 --> 00:28:18,530
life expectancy really means you know
how long would you live what's the in

1216
00:28:18,530 --> 00:28:18,540
how long would you live what's the in
 

1217
00:28:18,540 --> 00:28:20,780
how long would you live what's the in
terms of a statistical likelihood if

1218
00:28:20,780 --> 00:28:20,790
terms of a statistical likelihood if
 

1219
00:28:20,790 --> 00:28:23,390
terms of a statistical likelihood if
there were not continued scientific

1220
00:28:23,390 --> 00:28:23,400
there were not continued scientific
 

1221
00:28:23,400 --> 00:28:25,310
there were not continued scientific
progress but that's a very inaccurate

1222
00:28:25,310 --> 00:28:25,320
progress but that's a very inaccurate
 

1223
00:28:25,320 --> 00:28:27,230
progress but that's a very inaccurate
assumption that scientific progress

1224
00:28:27,230 --> 00:28:27,240
assumption that scientific progress
 

1225
00:28:27,240 --> 00:28:30,020
assumption that scientific progress
is extremely rapid I mean just as an AI

1226
00:28:30,020 --> 00:28:30,030
is extremely rapid I mean just as an AI
 

1227
00:28:30,030 --> 00:28:33,320
is extremely rapid I mean just as an AI
in biotech there are advances now every

1228
00:28:33,320 --> 00:28:33,330
in biotech there are advances now every
 

1229
00:28:33,330 --> 00:28:37,180
in biotech there are advances now every
week is quite stunning

1230
00:28:37,180 --> 00:28:37,190
week is quite stunning
 

1231
00:28:37,190 --> 00:28:40,520
week is quite stunning
now you can have a computed life

1232
00:28:40,520 --> 00:28:40,530
now you can have a computed life
 

1233
00:28:40,530 --> 00:28:43,190
now you can have a computed life
expectancies let's say 30 years 50 years

1234
00:28:43,190 --> 00:28:43,200
expectancies let's say 30 years 50 years
 

1235
00:28:43,200 --> 00:28:46,910
expectancies let's say 30 years 50 years
70 years from now you can still be hit

1236
00:28:46,910 --> 00:28:46,920
70 years from now you can still be hit
 

1237
00:28:46,920 --> 00:28:49,520
70 years from now you can still be hit
by the proverbial bus tomorrow we're

1238
00:28:49,520 --> 00:28:49,530
by the proverbial bus tomorrow we're
 

1239
00:28:49,530 --> 00:28:51,140
by the proverbial bus tomorrow we're
working on that with self-driving

1240
00:28:51,140 --> 00:28:51,150
working on that with self-driving
 

1241
00:28:51,150 --> 00:28:56,090
working on that with self-driving
vehicles but we'll get we'll get to a

1242
00:28:56,090 --> 00:28:56,100
vehicles but we'll get we'll get to a
 

1243
00:28:56,100 --> 00:28:57,800
vehicles but we'll get we'll get to a
point I think if you're diligent you can

1244
00:28:57,800 --> 00:28:57,810
point I think if you're diligent you can
 

1245
00:28:57,810 --> 00:29:00,380
point I think if you're diligent you can
be there now in terms of basically

1246
00:29:00,380 --> 00:29:00,390
be there now in terms of basically
 

1247
00:29:00,390 --> 00:29:03,380
be there now in terms of basically
advancing your own statistical life

1248
00:29:03,380 --> 00:29:03,390
advancing your own statistical life
 

1249
00:29:03,390 --> 00:29:05,530
advancing your own statistical life
expectancy

1250
00:29:05,530 --> 00:29:05,540
expectancy
 

1251
00:29:05,540 --> 00:29:07,780
expectancy
at least to keep pace with the passage

1252
00:29:07,780 --> 00:29:07,790
at least to keep pace with the passage
 

1253
00:29:07,790 --> 00:29:10,740
at least to keep pace with the passage
of time I think it would be there for

1254
00:29:10,740 --> 00:29:10,750
of time I think it would be there for
 

1255
00:29:10,750 --> 00:29:13,360
of time I think it would be there for
most of the population at least if

1256
00:29:13,360 --> 00:29:13,370
most of the population at least if
 

1257
00:29:13,370 --> 00:29:16,169
most of the population at least if
they're diligent within about a decade

1258
00:29:16,169 --> 00:29:16,179
they're diligent within about a decade
 

1259
00:29:16,179 --> 00:29:19,840
they're diligent within about a decade
so if we can hang in there we may get to

1260
00:29:19,840 --> 00:29:19,850
so if we can hang in there we may get to
 

1261
00:29:19,850 --> 00:29:21,880
so if we can hang in there we may get to
see the remarkable century ahead thank

1262
00:29:21,880 --> 00:29:21,890
see the remarkable century ahead thank
 

1263
00:29:21,890 --> 00:29:28,630
see the remarkable century ahead thank
you very much no question please raise

1264
00:29:28,630 --> 00:29:28,640
you very much no question please raise
 

1265
00:29:28,640 --> 00:29:33,880
you very much no question please raise
your hand we'll get your mic hi

1266
00:29:33,880 --> 00:29:33,890
your hand we'll get your mic hi
 

1267
00:29:33,890 --> 00:29:36,940
your hand we'll get your mic hi
so you mentioned both neural neural

1268
00:29:36,940 --> 00:29:36,950
so you mentioned both neural neural
 

1269
00:29:36,950 --> 00:29:39,760
so you mentioned both neural neural
network models and symbolic models and I

1270
00:29:39,760 --> 00:29:39,770
network models and symbolic models and I
 

1271
00:29:39,770 --> 00:29:42,370
network models and symbolic models and I
was wondering how far have you been

1272
00:29:42,370 --> 00:29:42,380
was wondering how far have you been
 

1273
00:29:42,380 --> 00:29:44,020
was wondering how far have you been
thinking about combining these two

1274
00:29:44,020 --> 00:29:44,030
thinking about combining these two
 

1275
00:29:44,030 --> 00:29:46,200
thinking about combining these two
approaches creating a symbiosis between

1276
00:29:46,200 --> 00:29:46,210
approaches creating a symbiosis between
 

1277
00:29:46,210 --> 00:29:51,490
approaches creating a symbiosis between
neural models and symbolic ones I don't

1278
00:29:51,490 --> 00:29:51,500
neural models and symbolic ones I don't
 

1279
00:29:51,500 --> 00:29:54,460
neural models and symbolic ones I don't
think we want to use symbolic models as

1280
00:29:54,460 --> 00:29:54,470
think we want to use symbolic models as
 

1281
00:29:54,470 --> 00:29:59,440
think we want to use symbolic models as
they've been used how many are familiar

1282
00:29:59,440 --> 00:29:59,450
they've been used how many are familiar
 

1283
00:29:59,450 --> 00:30:03,120
they've been used how many are familiar
with the psych project

1284
00:30:03,120 --> 00:30:03,130

 

1285
00:30:03,130 --> 00:30:06,070

that was a very diligent effort in Texas

1286
00:30:06,070 --> 00:30:06,080
that was a very diligent effort in Texas
 

1287
00:30:06,080 --> 00:30:09,660
that was a very diligent effort in Texas
to define all of common-sense reasoning

1288
00:30:09,660 --> 00:30:09,670
to define all of common-sense reasoning
 

1289
00:30:09,670 --> 00:30:12,840
to define all of common-sense reasoning
and it kind of collapsed on itself and

1290
00:30:12,840 --> 00:30:12,850
and it kind of collapsed on itself and
 

1291
00:30:12,850 --> 00:30:16,990
and it kind of collapsed on itself and
became impossible to debug because you

1292
00:30:16,990 --> 00:30:17,000
became impossible to debug because you
 

1293
00:30:17,000 --> 00:30:18,640
became impossible to debug because you
fix one thing and it break three other

1294
00:30:18,640 --> 00:30:18,650
fix one thing and it break three other
 

1295
00:30:18,650 --> 00:30:21,970
fix one thing and it break three other
things that complexity ceiling has

1296
00:30:21,970 --> 00:30:21,980
things that complexity ceiling has
 

1297
00:30:21,980 --> 00:30:26,620
things that complexity ceiling has
become typical of of trying to define

1298
00:30:26,620 --> 00:30:26,630
become typical of of trying to define
 

1299
00:30:26,630 --> 00:30:31,570
become typical of of trying to define
things through logical rules now it does

1300
00:30:31,570 --> 00:30:31,580
things through logical rules now it does
 

1301
00:30:31,580 --> 00:30:33,700
things through logical rules now it does
seem that humans can understand logical

1302
00:30:33,700 --> 00:30:33,710
seem that humans can understand logical
 

1303
00:30:33,710 --> 00:30:35,620
seem that humans can understand logical
rules we have logical rules written down

1304
00:30:35,620 --> 00:30:35,630
rules we have logical rules written down
 

1305
00:30:35,630 --> 00:30:40,270
rules we have logical rules written down
for things like law and game playing and

1306
00:30:40,270 --> 00:30:40,280
for things like law and game playing and
 

1307
00:30:40,280 --> 00:30:44,160
for things like law and game playing and
so on but you can actually define a

1308
00:30:44,160 --> 00:30:44,170
so on but you can actually define a
 

1309
00:30:44,170 --> 00:30:48,810
so on but you can actually define a
connectionist system to have such a high

1310
00:30:48,810 --> 00:30:48,820
connectionist system to have such a high
 

1311
00:30:48,820 --> 00:30:52,960
connectionist system to have such a high
reliability on a certain type of action

1312
00:30:52,960 --> 00:30:52,970
reliability on a certain type of action
 

1313
00:30:52,970 --> 00:30:55,480
reliability on a certain type of action
that it looks like it's a symbolic rule

1314
00:30:55,480 --> 00:30:55,490
that it looks like it's a symbolic rule
 

1315
00:30:55,490 --> 00:30:58,690
that it looks like it's a symbolic rule
even though it's represented in a

1316
00:30:58,690 --> 00:30:58,700
even though it's represented in a
 

1317
00:30:58,700 --> 00:31:01,930
even though it's represented in a
connectionist way and connection systems

1318
00:31:01,930 --> 00:31:01,940
connectionist way and connection systems
 

1319
00:31:01,940 --> 00:31:05,530
connectionist way and connection systems
can both capture the soft edges because

1320
00:31:05,530 --> 00:31:05,540
can both capture the soft edges because
 

1321
00:31:05,540 --> 00:31:08,320
can both capture the soft edges because
many things in life are not sharply

1322
00:31:08,320 --> 00:31:08,330
many things in life are not sharply
 

1323
00:31:08,330 --> 00:31:10,540
many things in life are not sharply
defined they can also generate

1324
00:31:10,540 --> 00:31:10,550
defined they can also generate
 

1325
00:31:10,550 --> 00:31:13,390
defined they can also generate
exceptions so you you don't want to

1326
00:31:13,390 --> 00:31:13,400
exceptions so you you don't want to
 

1327
00:31:13,400 --> 00:31:15,670
exceptions so you you don't want to
sacrifice your queen in chess accept

1328
00:31:15,670 --> 00:31:15,680
sacrifice your queen in chess accept
 

1329
00:31:15,680 --> 00:31:17,500
sacrifice your queen in chess accept
certain situations that might be a good

1330
00:31:17,500 --> 00:31:17,510
certain situations that might be a good
 

1331
00:31:17,510 --> 00:31:20,170
certain situations that might be a good
idea so you can capture that kind of

1332
00:31:20,170 --> 00:31:20,180
idea so you can capture that kind of
 

1333
00:31:20,180 --> 00:31:24,730
idea so you can capture that kind of
complexity so we do want to be able to

1334
00:31:24,730 --> 00:31:24,740
complexity so we do want to be able to
 

1335
00:31:24,740 --> 00:31:28,030
complexity so we do want to be able to
learn from accumulated human wisdom that

1336
00:31:28,030 --> 00:31:28,040
learn from accumulated human wisdom that
 

1337
00:31:28,040 --> 00:31:31,120
learn from accumulated human wisdom that
looks like it's symbolic but I think

1338
00:31:31,120 --> 00:31:31,130
looks like it's symbolic but I think
 

1339
00:31:31,130 --> 00:31:33,400
looks like it's symbolic but I think
we'll do it with a connection system but

1340
00:31:33,400 --> 00:31:33,410
we'll do it with a connection system but
 

1341
00:31:33,410 --> 00:31:36,880
we'll do it with a connection system but
again I'm think the connection systems

1342
00:31:36,880 --> 00:31:36,890
again I'm think the connection systems
 

1343
00:31:36,890 --> 00:31:40,780
again I'm think the connection systems
should develop a sense of hierarchy and

1344
00:31:40,780 --> 00:31:40,790
should develop a sense of hierarchy and
 

1345
00:31:40,790 --> 00:31:43,980
should develop a sense of hierarchy and
not just be one big massive neural net

1346
00:31:43,980 --> 00:31:43,990
not just be one big massive neural net
 

1347
00:31:43,990 --> 00:31:47,500
not just be one big massive neural net
so I understand how we want you know use

1348
00:31:47,500 --> 00:31:47,510
so I understand how we want you know use
 

1349
00:31:47,510 --> 00:31:50,620
so I understand how we want you know use
the neocortex to extract useful stuff

1350
00:31:50,620 --> 00:31:50,630
the neocortex to extract useful stuff
 

1351
00:31:50,630 --> 00:31:51,970
the neocortex to extract useful stuff
and commercialize that but I'm wondering

1352
00:31:51,970 --> 00:31:51,980
and commercialize that but I'm wondering
 

1353
00:31:51,980 --> 00:31:55,210
and commercialize that but I'm wondering
how you know our middle brain and organs

1354
00:31:55,210 --> 00:31:55,220
how you know our middle brain and organs
 

1355
00:31:55,220 --> 00:31:57,280
how you know our middle brain and organs
that are below the neocortex will be

1356
00:31:57,280 --> 00:31:57,290
that are below the neocortex will be
 

1357
00:31:57,290 --> 00:32:01,210
that are below the neocortex will be
useful for you know turn that into what

1358
00:32:01,210 --> 00:32:01,220
useful for you know turn that into what
 

1359
00:32:01,220 --> 00:32:03,610
useful for you know turn that into what
you want to do something well the

1360
00:32:03,610 --> 00:32:03,620
you want to do something well the
 

1361
00:32:03,620 --> 00:32:05,440
you want to do something well the
cerebellum is an interesting case in

1362
00:32:05,440 --> 00:32:05,450
cerebellum is an interesting case in
 

1363
00:32:05,450 --> 00:32:08,320
cerebellum is an interesting case in
point it actually has more neurons than

1364
00:32:08,320 --> 00:32:08,330
point it actually has more neurons than
 

1365
00:32:08,330 --> 00:32:12,490
point it actually has more neurons than
the neocortex and it's used to

1366
00:32:12,490 --> 00:32:12,500
the neocortex and it's used to
 

1367
00:32:12,500 --> 00:32:16,510
the neocortex and it's used to
govern most of our behavior some things

1368
00:32:16,510 --> 00:32:16,520
govern most of our behavior some things
 

1369
00:32:16,520 --> 00:32:18,669
govern most of our behavior some things
if you write a signature that's actually

1370
00:32:18,669 --> 00:32:18,679
if you write a signature that's actually
 

1371
00:32:18,679 --> 00:32:21,399
if you write a signature that's actually
controlled by the cerebellum so a simple

1372
00:32:21,399 --> 00:32:21,409
controlled by the cerebellum so a simple
 

1373
00:32:21,409 --> 00:32:26,140
controlled by the cerebellum so a simple
sequence is stored in the cerebellum but

1374
00:32:26,140 --> 00:32:26,150
sequence is stored in the cerebellum but
 

1375
00:32:26,150 --> 00:32:28,419
sequence is stored in the cerebellum but
there's not many reasoning to it it's

1376
00:32:28,419 --> 00:32:28,429
there's not many reasoning to it it's
 

1377
00:32:28,429 --> 00:32:32,580
there's not many reasoning to it it's
basically a script and most of our

1378
00:32:32,580 --> 00:32:32,590
basically a script and most of our
 

1379
00:32:32,590 --> 00:32:35,320
basically a script and most of our
movement now has actually been migrated

1380
00:32:35,320 --> 00:32:35,330
movement now has actually been migrated
 

1381
00:32:35,330 --> 00:32:37,470
movement now has actually been migrated
from the center vellum to the neocortex

1382
00:32:37,470 --> 00:32:37,480
from the center vellum to the neocortex
 

1383
00:32:37,480 --> 00:32:41,080
from the center vellum to the neocortex
cerebellum is still there some people

1384
00:32:41,080 --> 00:32:41,090
cerebellum is still there some people
 

1385
00:32:41,090 --> 00:32:43,899
cerebellum is still there some people
the entire cerebellum is destroyed

1386
00:32:43,899 --> 00:32:43,909
the entire cerebellum is destroyed
 

1387
00:32:43,909 --> 00:32:46,419
the entire cerebellum is destroyed
through disease they still function

1388
00:32:46,419 --> 00:32:46,429
through disease they still function
 

1389
00:32:46,429 --> 00:32:49,270
through disease they still function
fairly normally their movement might be

1390
00:32:49,270 --> 00:32:49,280
fairly normally their movement might be
 

1391
00:32:49,280 --> 00:32:52,330
fairly normally their movement might be
a little erratic as our movements is

1392
00:32:52,330 --> 00:32:52,340
a little erratic as our movements is
 

1393
00:32:52,340 --> 00:32:54,430
a little erratic as our movements is
largely controlled by the neocortex but

1394
00:32:54,430 --> 00:32:54,440
largely controlled by the neocortex but
 

1395
00:32:54,440 --> 00:32:56,950
largely controlled by the neocortex but
some of the subtlety is a kind of

1396
00:32:56,950 --> 00:32:56,960
some of the subtlety is a kind of
 

1397
00:32:56,960 --> 00:32:59,710
some of the subtlety is a kind of
pre-programmed script and so they'll

1398
00:32:59,710 --> 00:32:59,720
pre-programmed script and so they'll
 

1399
00:32:59,720 --> 00:33:01,600
pre-programmed script and so they'll
look a little clumsy but they're

1400
00:33:01,600 --> 00:33:01,610
look a little clumsy but they're
 

1401
00:33:01,610 --> 00:33:05,529
look a little clumsy but they're
actually function okay a lot of other

1402
00:33:05,529 --> 00:33:05,539
actually function okay a lot of other
 

1403
00:33:05,539 --> 00:33:07,980
actually function okay a lot of other
areas of the brain control autonomic

1404
00:33:07,980 --> 00:33:07,990
areas of the brain control autonomic
 

1405
00:33:07,990 --> 00:33:11,560
areas of the brain control autonomic
functions like breathing and but our

1406
00:33:11,560 --> 00:33:11,570
functions like breathing and but our
 

1407
00:33:11,570 --> 00:33:13,539
functions like breathing and but our
thinking really is is controlled by the

1408
00:33:13,539 --> 00:33:13,549
thinking really is is controlled by the
 

1409
00:33:13,549 --> 00:33:17,520
thinking really is is controlled by the
neocortex in terms of mastering

1410
00:33:17,520 --> 00:33:17,530
neocortex in terms of mastering
 

1411
00:33:17,530 --> 00:33:20,740
neocortex in terms of mastering
intelligence I think the neocortex is

1412
00:33:20,740 --> 00:33:20,750
intelligence I think the neocortex is
 

1413
00:33:20,750 --> 00:33:25,960
intelligence I think the neocortex is
the brain region we want to study I'm

1414
00:33:25,960 --> 00:33:25,970
the brain region we want to study I'm
 

1415
00:33:25,970 --> 00:33:28,200
the brain region we want to study I'm
curious what you think might happen

1416
00:33:28,200 --> 00:33:28,210
curious what you think might happen
 

1417
00:33:28,210 --> 00:33:31,270
curious what you think might happen
after the singularity is reached in

1418
00:33:31,270 --> 00:33:31,280
after the singularity is reached in
 

1419
00:33:31,280 --> 00:33:32,860
after the singularity is reached in
terms of this exponential growth of

1420
00:33:32,860 --> 00:33:32,870
terms of this exponential growth of
 

1421
00:33:32,870 --> 00:33:37,210
terms of this exponential growth of
information yes do you think it will

1422
00:33:37,210 --> 00:33:37,220
information yes do you think it will
 

1423
00:33:37,220 --> 00:33:39,190
information yes do you think it will
continue or will there be a whole

1424
00:33:39,190 --> 00:33:39,200
continue or will there be a whole
 

1425
00:33:39,200 --> 00:33:42,399
continue or will there be a whole
paradigm shift what do you predict well

1426
00:33:42,399 --> 00:33:42,409
paradigm shift what do you predict well
 

1427
00:33:42,409 --> 00:33:44,380
paradigm shift what do you predict well
in the singularities near I talked about

1428
00:33:44,380 --> 00:33:44,390
in the singularities near I talked about
 

1429
00:33:44,390 --> 00:33:47,710
in the singularities near I talked about
the atomic limits based on molecular

1430
00:33:47,710 --> 00:33:47,720
the atomic limits based on molecular
 

1431
00:33:47,720 --> 00:33:51,430
the atomic limits based on molecular
computing as we understand it and it can

1432
00:33:51,430 --> 00:33:51,440
computing as we understand it and it can
 

1433
00:33:51,440 --> 00:33:53,950
computing as we understand it and it can
actually go well past 2045 and actually

1434
00:33:53,950 --> 00:33:53,960
actually go well past 2045 and actually
 

1435
00:33:53,960 --> 00:33:56,279
actually go well past 2045 and actually
go to trillions of trillions of times

1436
00:33:56,279 --> 00:33:56,289
go to trillions of trillions of times
 

1437
00:33:56,289 --> 00:33:58,899
go to trillions of trillions of times
greater computational capacity than we

1438
00:33:58,899 --> 00:33:58,909
greater computational capacity than we
 

1439
00:33:58,909 --> 00:34:01,049
greater computational capacity than we
have today

1440
00:34:01,049 --> 00:34:01,059
have today
 

1441
00:34:01,059 --> 00:34:04,720
have today
so I don't see that's stopping anytime

1442
00:34:04,720 --> 00:34:04,730
so I don't see that's stopping anytime
 

1443
00:34:04,730 --> 00:34:07,120
so I don't see that's stopping anytime
soon and we'll go you know way beyond

1444
00:34:07,120 --> 00:34:07,130
soon and we'll go you know way beyond
 

1445
00:34:07,130 --> 00:34:12,879
soon and we'll go you know way beyond
what we can imagine and it becomes an

1446
00:34:12,879 --> 00:34:12,889
what we can imagine and it becomes an
 

1447
00:34:12,889 --> 00:34:14,470
what we can imagine and it becomes an
interesting discussion what the impact

1448
00:34:14,470 --> 00:34:14,480
interesting discussion what the impact
 

1449
00:34:14,480 --> 00:34:19,990
interesting discussion what the impact
on human civilization will be so take it

1450
00:34:19,990 --> 00:34:20,000
on human civilization will be so take it
 

1451
00:34:20,000 --> 00:34:22,690
on human civilization will be so take it
may be slightly more mundane issue that

1452
00:34:22,690 --> 00:34:22,700
may be slightly more mundane issue that
 

1453
00:34:22,700 --> 00:34:25,180
may be slightly more mundane issue that
comes up as a kind of eliminates most

1454
00:34:25,180 --> 00:34:25,190
comes up as a kind of eliminates most
 

1455
00:34:25,190 --> 00:34:25,990
comes up as a kind of eliminates most
jobs or

1456
00:34:25,990 --> 00:34:26,000
jobs or
 

1457
00:34:26,000 --> 00:34:29,500
jobs or
jobs a point I make is it's not the

1458
00:34:29,500 --> 00:34:29,510
jobs a point I make is it's not the
 

1459
00:34:29,510 --> 00:34:31,240
jobs a point I make is it's not the
first time in human history you've done

1460
00:34:31,240 --> 00:34:31,250
first time in human history you've done
 

1461
00:34:31,250 --> 00:34:34,659
first time in human history you've done
that how many jobs circa 1900 exist

1462
00:34:34,659 --> 00:34:34,669
that how many jobs circa 1900 exist
 

1463
00:34:34,669 --> 00:34:39,159
that how many jobs circa 1900 exist
today and that was the feeling of the

1464
00:34:39,159 --> 00:34:39,169
today and that was the feeling of the
 

1465
00:34:39,169 --> 00:34:41,320
today and that was the feeling of the
Luddites which was an actual society

1466
00:34:41,320 --> 00:34:41,330
Luddites which was an actual society
 

1467
00:34:41,330 --> 00:34:43,810
Luddites which was an actual society
that formed in 1800 the automation of

1468
00:34:43,810 --> 00:34:43,820
that formed in 1800 the automation of
 

1469
00:34:43,820 --> 00:34:47,409
that formed in 1800 the automation of
the textile industry in England they

1470
00:34:47,409 --> 00:34:47,419
the textile industry in England they
 

1471
00:34:47,419 --> 00:34:48,820
the textile industry in England they
looked at all these jobs going away and

1472
00:34:48,820 --> 00:34:48,830
looked at all these jobs going away and
 

1473
00:34:48,830 --> 00:34:51,550
looked at all these jobs going away and
felt that employment is going to be just

1474
00:34:51,550 --> 00:34:51,560
felt that employment is going to be just
 

1475
00:34:51,560 --> 00:34:54,610
felt that employment is going to be just
limited to an elite indeed those jobs

1476
00:34:54,610 --> 00:34:54,620
limited to an elite indeed those jobs
 

1477
00:34:54,620 --> 00:34:57,060
limited to an elite indeed those jobs
didn't go away but new jobs were created

1478
00:34:57,060 --> 00:34:57,070
didn't go away but new jobs were created
 

1479
00:34:57,070 --> 00:35:00,490
didn't go away but new jobs were created
so if I were oppression Futures to 1900

1480
00:35:00,490 --> 00:35:00,500
so if I were oppression Futures to 1900
 

1481
00:35:00,500 --> 00:35:03,850
so if I were oppression Futures to 1900
I would say well 38% of you work on

1482
00:35:03,850 --> 00:35:03,860
I would say well 38% of you work on
 

1483
00:35:03,860 --> 00:35:07,180
I would say well 38% of you work on
farms and 25% work in factories it's 2/3

1484
00:35:07,180 --> 00:35:07,190
farms and 25% work in factories it's 2/3
 

1485
00:35:07,190 --> 00:35:13,330
farms and 25% work in factories it's 2/3
of the working force but I predict by

1486
00:35:13,330 --> 00:35:13,340
of the working force but I predict by
 

1487
00:35:13,340 --> 00:35:16,600
of the working force but I predict by
2015 115 years from now it's going to be

1488
00:35:16,600 --> 00:35:16,610
2015 115 years from now it's going to be
 

1489
00:35:16,610 --> 00:35:19,540
2015 115 years from now it's going to be
2% on farms and 9% factories and

1490
00:35:19,540 --> 00:35:19,550
2% on farms and 9% factories and
 

1491
00:35:19,550 --> 00:35:21,370
2% on farms and 9% factories and
everybody would go oh my God we're gonna

1492
00:35:21,370 --> 00:35:21,380
everybody would go oh my God we're gonna
 

1493
00:35:21,380 --> 00:35:23,170
everybody would go oh my God we're gonna
be out of work and I said well don't

1494
00:35:23,170 --> 00:35:23,180
be out of work and I said well don't
 

1495
00:35:23,180 --> 00:35:24,910
be out of work and I said well don't
worry for all these jobs we eliminate

1496
00:35:24,910 --> 00:35:24,920
worry for all these jobs we eliminate
 

1497
00:35:24,920 --> 00:35:26,230
worry for all these jobs we eliminate
through automation we're gonna invent

1498
00:35:26,230 --> 00:35:26,240
through automation we're gonna invent
 

1499
00:35:26,240 --> 00:35:29,290
through automation we're gonna invent
new jobs and say oh really what new jobs

1500
00:35:29,290 --> 00:35:29,300
new jobs and say oh really what new jobs
 

1501
00:35:29,300 --> 00:35:31,120
new jobs and say oh really what new jobs
and I'd say well I don't know we haven't

1502
00:35:31,120 --> 00:35:31,130
and I'd say well I don't know we haven't
 

1503
00:35:31,130 --> 00:35:34,150
and I'd say well I don't know we haven't
invented them yet that's the political

1504
00:35:34,150 --> 00:35:34,160
invented them yet that's the political
 

1505
00:35:34,160 --> 00:35:36,190
invented them yet that's the political
problem we could see jobs very clearly

1506
00:35:36,190 --> 00:35:36,200
problem we could see jobs very clearly
 

1507
00:35:36,200 --> 00:35:38,620
problem we could see jobs very clearly
going away fairly soon like driving a

1508
00:35:38,620 --> 00:35:38,630
going away fairly soon like driving a
 

1509
00:35:38,630 --> 00:35:42,220
going away fairly soon like driving a
car or truck and the new jobs haven't

1510
00:35:42,220 --> 00:35:42,230
car or truck and the new jobs haven't
 

1511
00:35:42,230 --> 00:35:43,510
car or truck and the new jobs haven't
been invented I mean just look at the

1512
00:35:43,510 --> 00:35:43,520
been invented I mean just look at the
 

1513
00:35:43,520 --> 00:35:46,780
been invented I mean just look at the
last five or six years as many a lot of

1514
00:35:46,780 --> 00:35:46,790
last five or six years as many a lot of
 

1515
00:35:46,790 --> 00:35:48,280
last five or six years as many a lot of
the increase in employment has been

1516
00:35:48,280 --> 00:35:48,290
the increase in employment has been
 

1517
00:35:48,290 --> 00:35:52,510
the increase in employment has been
through mobile app related types of ways

1518
00:35:52,510 --> 00:35:52,520
through mobile app related types of ways
 

1519
00:35:52,520 --> 00:35:54,280
through mobile app related types of ways
of making money that just weren't

1520
00:35:54,280 --> 00:35:54,290
of making money that just weren't
 

1521
00:35:54,290 --> 00:35:58,210
of making money that just weren't
contemplated even six years ago if I

1522
00:35:58,210 --> 00:35:58,220
contemplated even six years ago if I
 

1523
00:35:58,220 --> 00:35:59,770
contemplated even six years ago if I
really prescient I would say well you're

1524
00:35:59,770 --> 00:35:59,780
really prescient I would say well you're
 

1525
00:35:59,780 --> 00:36:01,690
really prescient I would say well you're
gonna get jobs creating mobile apps and

1526
00:36:01,690 --> 00:36:01,700
gonna get jobs creating mobile apps and
 

1527
00:36:01,700 --> 00:36:05,940
gonna get jobs creating mobile apps and
websites and doing data analytics and

1528
00:36:05,940 --> 00:36:05,950
websites and doing data analytics and
 

1529
00:36:05,950 --> 00:36:09,270
websites and doing data analytics and
self-driving cars cars what's a car and

1530
00:36:09,270 --> 00:36:09,280
self-driving cars cars what's a car and
 

1531
00:36:09,280 --> 00:36:11,380
self-driving cars cars what's a car and
nobody would have any idea what I'm

1532
00:36:11,380 --> 00:36:11,390
nobody would have any idea what I'm
 

1533
00:36:11,390 --> 00:36:16,030
nobody would have any idea what I'm
talking about now the new job

1534
00:36:16,030 --> 00:36:16,040
talking about now the new job
 

1535
00:36:16,040 --> 00:36:17,800
talking about now the new job
some people say yeah we created new jobs

1536
00:36:17,800 --> 00:36:17,810
some people say yeah we created new jobs
 

1537
00:36:17,810 --> 00:36:20,920
some people say yeah we created new jobs
but it's not as many actually we've gone

1538
00:36:20,920 --> 00:36:20,930
but it's not as many actually we've gone
 

1539
00:36:20,930 --> 00:36:22,950
but it's not as many actually we've gone
from 24 million jobs in nineteen hundred

1540
00:36:22,950 --> 00:36:22,960
from 24 million jobs in nineteen hundred
 

1541
00:36:22,960 --> 00:36:26,170
from 24 million jobs in nineteen hundred
242 million jobs today for 30 percent of

1542
00:36:26,170 --> 00:36:26,180
242 million jobs today for 30 percent of
 

1543
00:36:26,180 --> 00:36:27,850
242 million jobs today for 30 percent of
the population to forty five percent of

1544
00:36:27,850 --> 00:36:27,860
the population to forty five percent of
 

1545
00:36:27,860 --> 00:36:30,790
the population to forty five percent of
the population the new jobs pay eleven

1546
00:36:30,790 --> 00:36:30,800
the population the new jobs pay eleven
 

1547
00:36:30,800 --> 00:36:32,560
the population the new jobs pay eleven
times as much in constant dollars and

1548
00:36:32,560 --> 00:36:32,570
times as much in constant dollars and
 

1549
00:36:32,570 --> 00:36:34,840
times as much in constant dollars and
they're more interesting and as I talk

1550
00:36:34,840 --> 00:36:34,850
they're more interesting and as I talk
 

1551
00:36:34,850 --> 00:36:37,600
they're more interesting and as I talk
to people starting out their career now

1552
00:36:37,600 --> 00:36:37,610
to people starting out their career now
 

1553
00:36:37,610 --> 00:36:39,190
to people starting out their career now
they really want a career that gives

1554
00:36:39,190 --> 00:36:39,200
they really want a career that gives
 

1555
00:36:39,200 --> 00:36:39,740
they really want a career that gives
them some

1556
00:36:39,740 --> 00:36:39,750
them some
 

1557
00:36:39,750 --> 00:36:42,530
them some
life definition and purpose and

1558
00:36:42,530 --> 00:36:42,540
life definition and purpose and
 

1559
00:36:42,540 --> 00:36:44,630
life definition and purpose and
gratification we're moving up Maslow's

1560
00:36:44,630 --> 00:36:44,640
gratification we're moving up Maslow's
 

1561
00:36:44,640 --> 00:36:47,930
gratification we're moving up Maslow's
hierarchy hundred years ago you were

1562
00:36:47,930 --> 00:36:47,940
hierarchy hundred years ago you were
 

1563
00:36:47,940 --> 00:36:49,400
hierarchy hundred years ago you were
happy if you had a back-breaking job to

1564
00:36:49,400 --> 00:36:49,410
happy if you had a back-breaking job to
 

1565
00:36:49,410 --> 00:36:52,810
happy if you had a back-breaking job to
put food on your family's table so and

1566
00:36:52,810 --> 00:36:52,820
put food on your family's table so and
 

1567
00:36:52,820 --> 00:36:55,810
put food on your family's table so and
we couldn't do these new jobs without

1568
00:36:55,810 --> 00:36:55,820
we couldn't do these new jobs without
 

1569
00:36:55,820 --> 00:36:58,070
we couldn't do these new jobs without
enhancing our intelligence so we've been

1570
00:36:58,070 --> 00:36:58,080
enhancing our intelligence so we've been
 

1571
00:36:58,080 --> 00:37:01,190
enhancing our intelligence so we've been
doing that well for most of the last 100

1572
00:37:01,190 --> 00:37:01,200
doing that well for most of the last 100
 

1573
00:37:01,200 --> 00:37:03,470
doing that well for most of the last 100
years through education we've expanded

1574
00:37:03,470 --> 00:37:03,480
years through education we've expanded
 

1575
00:37:03,480 --> 00:37:05,360
years through education we've expanded
to K through 12 and constant dollars

1576
00:37:05,360 --> 00:37:05,370
to K through 12 and constant dollars
 

1577
00:37:05,370 --> 00:37:06,200
to K through 12 and constant dollars
tenfold

1578
00:37:06,200 --> 00:37:06,210
tenfold
 

1579
00:37:06,210 --> 00:37:10,250
tenfold
we've gone from 38,000 college students

1580
00:37:10,250 --> 00:37:10,260
we've gone from 38,000 college students
 

1581
00:37:10,260 --> 00:37:15,410
we've gone from 38,000 college students
in 1870 to 15 million today more

1582
00:37:15,410 --> 00:37:15,420
in 1870 to 15 million today more
 

1583
00:37:15,420 --> 00:37:18,020
in 1870 to 15 million today more
recently we have brain extenders and not

1584
00:37:18,020 --> 00:37:18,030
recently we have brain extenders and not
 

1585
00:37:18,030 --> 00:37:20,420
recently we have brain extenders and not
yet connected directly in our brain but

1586
00:37:20,420 --> 00:37:20,430
yet connected directly in our brain but
 

1587
00:37:20,430 --> 00:37:22,190
yet connected directly in our brain but
they're very close at hand when I was

1588
00:37:22,190 --> 00:37:22,200
they're very close at hand when I was
 

1589
00:37:22,200 --> 00:37:23,630
they're very close at hand when I was
here that my ta to take my bicycle

1590
00:37:23,630 --> 00:37:23,640
here that my ta to take my bicycle
 

1591
00:37:23,640 --> 00:37:26,420
here that my ta to take my bicycle
across campus to get to the computer and

1592
00:37:26,420 --> 00:37:26,430
across campus to get to the computer and
 

1593
00:37:26,430 --> 00:37:28,610
across campus to get to the computer and
show an ID to get in the building now we

1594
00:37:28,610 --> 00:37:28,620
show an ID to get in the building now we
 

1595
00:37:28,620 --> 00:37:31,700
show an ID to get in the building now we
carry them well you know in our in our

1596
00:37:31,700 --> 00:37:31,710
carry them well you know in our in our
 

1597
00:37:31,710 --> 00:37:34,090
carry them well you know in our in our
pockets and on our belts

1598
00:37:34,090 --> 00:37:34,100
pockets and on our belts
 

1599
00:37:34,100 --> 00:37:36,320
pockets and on our belts
they're going to go inside our bodies

1600
00:37:36,320 --> 00:37:36,330
they're going to go inside our bodies
 

1601
00:37:36,330 --> 00:37:38,990
they're going to go inside our bodies
and brains I think that's a notic really

1602
00:37:38,990 --> 00:37:39,000
and brains I think that's a notic really
 

1603
00:37:39,000 --> 00:37:41,660
and brains I think that's a notic really
important distinction but so we're

1604
00:37:41,660 --> 00:37:41,670
important distinction but so we're
 

1605
00:37:41,670 --> 00:37:43,190
important distinction but so we're
basically going to be continuing to

1606
00:37:43,190 --> 00:37:43,200
basically going to be continuing to
 

1607
00:37:43,200 --> 00:37:45,650
basically going to be continuing to
enhance our capability through merging

1608
00:37:45,650 --> 00:37:45,660
enhance our capability through merging
 

1609
00:37:45,660 --> 00:37:49,310
enhance our capability through merging
with AI and that's the I think ultimate

1610
00:37:49,310 --> 00:37:49,320
with AI and that's the I think ultimate
 

1611
00:37:49,320 --> 00:37:52,670
with AI and that's the I think ultimate
answer to the kind of dystopian view we

1612
00:37:52,670 --> 00:37:52,680
answer to the kind of dystopian view we
 

1613
00:37:52,680 --> 00:37:55,220
answer to the kind of dystopian view we
see in futures movies where it's the AI

1614
00:37:55,220 --> 00:37:55,230
see in futures movies where it's the AI
 

1615
00:37:55,230 --> 00:37:57,290
see in futures movies where it's the AI
versus a brave band of humans for

1616
00:37:57,290 --> 00:37:57,300
versus a brave band of humans for
 

1617
00:37:57,300 --> 00:37:59,480
versus a brave band of humans for
control of humanity we don't have one or

1618
00:37:59,480 --> 00:37:59,490
control of humanity we don't have one or
 

1619
00:37:59,490 --> 00:38:01,700
control of humanity we don't have one or
two a eyes in the world today we have

1620
00:38:01,700 --> 00:38:01,710
two a eyes in the world today we have
 

1621
00:38:01,710 --> 00:38:03,530
two a eyes in the world today we have
several billion three billion

1622
00:38:03,530 --> 00:38:03,540
several billion three billion
 

1623
00:38:03,540 --> 00:38:06,500
several billion three billion
smartphones and last count will be six

1624
00:38:06,500 --> 00:38:06,510
smartphones and last count will be six
 

1625
00:38:06,510 --> 00:38:07,940
smartphones and last count will be six
billion in just a couple of years

1626
00:38:07,940 --> 00:38:07,950
billion in just a couple of years
 

1627
00:38:07,950 --> 00:38:10,760
billion in just a couple of years
according to the projections so we're

1628
00:38:10,760 --> 00:38:10,770
according to the projections so we're
 

1629
00:38:10,770 --> 00:38:14,600
according to the projections so we're
already deeply integrated with this and

1630
00:38:14,600 --> 00:38:14,610
already deeply integrated with this and
 

1631
00:38:14,610 --> 00:38:16,160
already deeply integrated with this and
I think that's going to continue and

1632
00:38:16,160 --> 00:38:16,170
I think that's going to continue and
 

1633
00:38:16,170 --> 00:38:18,110
I think that's going to continue and
it's gonna continue to do things that

1634
00:38:18,110 --> 00:38:18,120
it's gonna continue to do things that
 

1635
00:38:18,120 --> 00:38:20,240
it's gonna continue to do things that
you can't even imagine today just as we

1636
00:38:20,240 --> 00:38:20,250
you can't even imagine today just as we
 

1637
00:38:20,250 --> 00:38:21,980
you can't even imagine today just as we
are doing today things we couldn't

1638
00:38:21,980 --> 00:38:21,990
are doing today things we couldn't
 

1639
00:38:21,990 --> 00:38:24,140
are doing today things we couldn't
imagine you know even twenty years ago

1640
00:38:24,140 --> 00:38:24,150
imagine you know even twenty years ago
 

1641
00:38:24,150 --> 00:38:28,520
imagine you know even twenty years ago
you showed many graphs that goes through

1642
00:38:28,520 --> 00:38:28,530
you showed many graphs that goes through
 

1643
00:38:28,530 --> 00:38:30,290
you showed many graphs that goes through
exponential growth but I haven't seen

1644
00:38:30,290 --> 00:38:30,300
exponential growth but I haven't seen
 

1645
00:38:30,300 --> 00:38:32,060
exponential growth but I haven't seen
one that isn't so I would be very

1646
00:38:32,060 --> 00:38:32,070
one that isn't so I would be very
 

1647
00:38:32,070 --> 00:38:34,160
one that isn't so I would be very
interested in hearing you haven't seen

1648
00:38:34,160 --> 00:38:34,170
interested in hearing you haven't seen
 

1649
00:38:34,170 --> 00:38:36,950
interested in hearing you haven't seen
that what that is not exponential so

1650
00:38:36,950 --> 00:38:36,960
that what that is not exponential so
 

1651
00:38:36,960 --> 00:38:39,410
that what that is not exponential so
tell me about regions that you've

1652
00:38:39,410 --> 00:38:39,420
tell me about regions that you've
 

1653
00:38:39,420 --> 00:38:41,440
tell me about regions that you've
investigated that have not seen

1654
00:38:41,440 --> 00:38:41,450
investigated that have not seen
 

1655
00:38:41,450 --> 00:38:43,670
investigated that have not seen
exponential growth and why do you think

1656
00:38:43,670 --> 00:38:43,680
exponential growth and why do you think
 

1657
00:38:43,680 --> 00:38:47,380
exponential growth and why do you think
that's the case well

1658
00:38:47,380 --> 00:38:47,390
that's the case well
 

1659
00:38:47,390 --> 00:38:49,270
that's the case well
price performance and capacity of

1660
00:38:49,270 --> 00:38:49,280
price performance and capacity of
 

1661
00:38:49,280 --> 00:38:51,910
price performance and capacity of
information technology invariably

1662
00:38:51,910 --> 00:38:51,920
information technology invariably
 

1663
00:38:51,920 --> 00:38:55,620
information technology invariably
follows a exponential when it impacts

1664
00:38:55,620 --> 00:38:55,630
follows a exponential when it impacts
 

1665
00:38:55,630 --> 00:38:58,900
follows a exponential when it impacts
human society it can be linear so for

1666
00:38:58,900 --> 00:38:58,910
human society it can be linear so for
 

1667
00:38:58,910 --> 00:39:02,950
human society it can be linear so for
example the growth of democracy has been

1668
00:39:02,950 --> 00:39:02,960
example the growth of democracy has been
 

1669
00:39:02,960 --> 00:39:06,190
example the growth of democracy has been
linear but still pretty steady you can

1670
00:39:06,190 --> 00:39:06,200
linear but still pretty steady you can
 

1671
00:39:06,200 --> 00:39:07,810
linear but still pretty steady you can
count the number of democracies on the

1672
00:39:07,810 --> 00:39:07,820
count the number of democracies on the
 

1673
00:39:07,820 --> 00:39:10,540
count the number of democracies on the
fingers of one hand a century ago two

1674
00:39:10,540 --> 00:39:10,550
fingers of one hand a century ago two
 

1675
00:39:10,550 --> 00:39:11,920
fingers of one hand a century ago two
centuries ago you can count the number

1676
00:39:11,920 --> 00:39:11,930
centuries ago you can count the number
 

1677
00:39:11,930 --> 00:39:13,480
centuries ago you can count the number
of democracies in the world on the

1678
00:39:13,480 --> 00:39:13,490
of democracies in the world on the
 

1679
00:39:13,490 --> 00:39:16,600
of democracies in the world on the
fingers of one finger now there are

1680
00:39:16,600 --> 00:39:16,610
fingers of one finger now there are
 

1681
00:39:16,610 --> 00:39:19,120
fingers of one finger now there are
dozens of them that this and it's become

1682
00:39:19,120 --> 00:39:19,130
dozens of them that this and it's become
 

1683
00:39:19,130 --> 00:39:20,830
dozens of them that this and it's become
kind of a consensus that that's how we

1684
00:39:20,830 --> 00:39:20,840
kind of a consensus that that's how we
 

1685
00:39:20,840 --> 00:39:24,300
kind of a consensus that that's how we
should be governed

1686
00:39:24,300 --> 00:39:24,310

 

1687
00:39:24,310 --> 00:39:28,920

so the and I attributed all this to the

1688
00:39:28,920 --> 00:39:28,930
so the and I attributed all this to the
 

1689
00:39:28,930 --> 00:39:30,560
so the and I attributed all this to the
growth and information technology

1690
00:39:30,560 --> 00:39:30,570
growth and information technology
 

1691
00:39:30,570 --> 00:39:34,340
growth and information technology
communication in particular for

1692
00:39:34,340 --> 00:39:34,350
communication in particular for
 

1693
00:39:34,350 --> 00:39:38,090
communication in particular for
progression of social cultural

1694
00:39:38,090 --> 00:39:38,100
progression of social cultural
 

1695
00:39:38,100 --> 00:39:42,660
progression of social cultural
institutions but information technology

1696
00:39:42,660 --> 00:39:42,670
institutions but information technology
 

1697
00:39:42,670 --> 00:39:45,210
institutions but information technology
because it ultimately depends on a

1698
00:39:45,210 --> 00:39:45,220
because it ultimately depends on a
 

1699
00:39:45,220 --> 00:39:49,860
because it ultimately depends on a
vanishingly small energy and material

1700
00:39:49,860 --> 00:39:49,870
vanishingly small energy and material
 

1701
00:39:49,870 --> 00:39:53,250
vanishingly small energy and material
requirement grows exponentially and will

1702
00:39:53,250 --> 00:39:53,260
requirement grows exponentially and will
 

1703
00:39:53,260 --> 00:39:56,340
requirement grows exponentially and will
for a long time there's recently a

1704
00:39:56,340 --> 00:39:56,350
for a long time there's recently a
 

1705
00:39:56,350 --> 00:39:58,410
for a long time there's recently a
criticism that well test scores have

1706
00:39:58,410 --> 00:39:58,420
criticism that well test scores have
 

1707
00:39:58,420 --> 00:40:02,370
criticism that well test scores have
it's actually a remarkably straight

1708
00:40:02,370 --> 00:40:02,380
it's actually a remarkably straight
 

1709
00:40:02,380 --> 00:40:06,750
it's actually a remarkably straight
linear progression so humans think it's

1710
00:40:06,750 --> 00:40:06,760
linear progression so humans think it's
 

1711
00:40:06,760 --> 00:40:08,910
linear progression so humans think it's
like twenty eight hundred and it just

1712
00:40:08,910 --> 00:40:08,920
like twenty eight hundred and it just
 

1713
00:40:08,920 --> 00:40:11,370
like twenty eight hundred and it just
sort passed out in 1997 with the blue

1714
00:40:11,370 --> 00:40:11,380
sort passed out in 1997 with the blue
 

1715
00:40:11,380 --> 00:40:14,820
sort passed out in 1997 with the blue
and it's kept going and remarkably

1716
00:40:14,820 --> 00:40:14,830
and it's kept going and remarkably
 

1717
00:40:14,830 --> 00:40:16,590
and it's kept going and remarkably
straight and saying well this is linear

1718
00:40:16,590 --> 00:40:16,600
straight and saying well this is linear
 

1719
00:40:16,600 --> 00:40:18,750
straight and saying well this is linear
not exponential but the chess score is a

1720
00:40:18,750 --> 00:40:18,760
not exponential but the chess score is a
 

1721
00:40:18,760 --> 00:40:24,690
not exponential but the chess score is a
logarithmic measurement so it really is

1722
00:40:24,690 --> 00:40:24,700
logarithmic measurement so it really is
 

1723
00:40:24,700 --> 00:40:29,010
logarithmic measurement so it really is
exponential progression so if you're

1724
00:40:29,010 --> 00:40:29,020
exponential progression so if you're
 

1725
00:40:29,020 --> 00:40:31,350
exponential progression so if you're
lhasa furs like to think a lot about the

1726
00:40:31,350 --> 00:40:31,360
lhasa furs like to think a lot about the
 

1727
00:40:31,360 --> 00:40:33,060
lhasa furs like to think a lot about the
meaning of things especially in the 20th

1728
00:40:33,060 --> 00:40:33,070
meaning of things especially in the 20th
 

1729
00:40:33,070 --> 00:40:35,610
meaning of things especially in the 20th
century so for instance Martin Heidegger

1730
00:40:35,610 --> 00:40:35,620
century so for instance Martin Heidegger
 

1731
00:40:35,620 --> 00:40:38,040
century so for instance Martin Heidegger
gave a couple of speeches and lectures

1732
00:40:38,040 --> 00:40:38,050
gave a couple of speeches and lectures
 

1733
00:40:38,050 --> 00:40:40,250
gave a couple of speeches and lectures
on the relationship of human society to

1734
00:40:40,250 --> 00:40:40,260
on the relationship of human society to
 

1735
00:40:40,260 --> 00:40:42,920
on the relationship of human society to
technology and he particularly

1736
00:40:42,920 --> 00:40:42,930
technology and he particularly
 

1737
00:40:42,930 --> 00:40:45,570
technology and he particularly
distinguished between the mode of

1738
00:40:45,570 --> 00:40:45,580
distinguished between the mode of
 

1739
00:40:45,580 --> 00:40:47,340
distinguished between the mode of
thinking which is calculating thinking

1740
00:40:47,340 --> 00:40:47,350
thinking which is calculating thinking
 

1741
00:40:47,350 --> 00:40:48,750
thinking which is calculating thinking
and a mode of thinking which is

1742
00:40:48,750 --> 00:40:48,760
and a mode of thinking which is
 

1743
00:40:48,760 --> 00:40:50,910
and a mode of thinking which is
reflective thinking or meditative

1744
00:40:50,910 --> 00:40:50,920
reflective thinking or meditative
 

1745
00:40:50,920 --> 00:40:54,090
reflective thinking or meditative
thinking and he posed this question what

1746
00:40:54,090 --> 00:40:54,100
thinking and he posed this question what
 

1747
00:40:54,100 --> 00:40:56,420
thinking and he posed this question what
is the the meaning and purpose of

1748
00:40:56,420 --> 00:40:56,430
is the the meaning and purpose of
 

1749
00:40:56,430 --> 00:40:58,770
is the the meaning and purpose of
technological development and he

1750
00:40:58,770 --> 00:40:58,780
technological development and he
 

1751
00:40:58,780 --> 00:41:00,510
technological development and he
couldn't find an answer he he

1752
00:41:00,510 --> 00:41:00,520
couldn't find an answer he he
 

1753
00:41:00,520 --> 00:41:03,120
couldn't find an answer he he
recommended to remain open to what he

1754
00:41:03,120 --> 00:41:03,130
recommended to remain open to what he
 

1755
00:41:03,130 --> 00:41:05,850
recommended to remain open to what he
called and he called this an openness to

1756
00:41:05,850 --> 00:41:05,860
called and he called this an openness to
 

1757
00:41:05,860 --> 00:41:08,250
called and he called this an openness to
the mystery I wonder whether you have

1758
00:41:08,250 --> 00:41:08,260
the mystery I wonder whether you have
 

1759
00:41:08,260 --> 00:41:10,500
the mystery I wonder whether you have
any thoughts on this is there is there a

1760
00:41:10,500 --> 00:41:10,510
any thoughts on this is there is there a
 

1761
00:41:10,510 --> 00:41:12,090
any thoughts on this is there is there a
meaning of purpose to technological

1762
00:41:12,090 --> 00:41:12,100
meaning of purpose to technological
 

1763
00:41:12,100 --> 00:41:15,000
meaning of purpose to technological
equipment and and is there a way for a

1764
00:41:15,000 --> 00:41:15,010
equipment and and is there a way for a
 

1765
00:41:15,010 --> 00:41:21,540
equipment and and is there a way for a
human success access that meaning well

1766
00:41:21,540 --> 00:41:21,550
human success access that meaning well
 

1767
00:41:21,550 --> 00:41:25,820
human success access that meaning well
we started using technology to shore up

1768
00:41:25,820 --> 00:41:25,830
we started using technology to shore up
 

1769
00:41:25,830 --> 00:41:29,940
we started using technology to shore up
weaknesses and our own capabilities so

1770
00:41:29,940 --> 00:41:29,950
weaknesses and our own capabilities so
 

1771
00:41:29,950 --> 00:41:32,220
weaknesses and our own capabilities so
physically I mean who here could build

1772
00:41:32,220 --> 00:41:32,230
physically I mean who here could build
 

1773
00:41:32,230 --> 00:41:34,170
physically I mean who here could build
this building so we've leveraged the

1774
00:41:34,170 --> 00:41:34,180
this building so we've leveraged the
 

1775
00:41:34,180 --> 00:41:37,690
this building so we've leveraged the
power of our muscles with machines

1776
00:41:37,690 --> 00:41:37,700
power of our muscles with machines
 

1777
00:41:37,700 --> 00:41:40,370
power of our muscles with machines
and we're in fact very bad at doing

1778
00:41:40,370 --> 00:41:40,380
and we're in fact very bad at doing
 

1779
00:41:40,380 --> 00:41:42,650
and we're in fact very bad at doing
things that you know the simplest

1780
00:41:42,650 --> 00:41:42,660
things that you know the simplest
 

1781
00:41:42,660 --> 00:41:46,880
things that you know the simplest
computers can do like factor numbers or

1782
00:41:46,880 --> 00:41:46,890
computers can do like factor numbers or
 

1783
00:41:46,890 --> 00:41:50,350
computers can do like factor numbers or
even just multiply two eight digit

1784
00:41:50,350 --> 00:41:50,360
even just multiply two eight digit
 

1785
00:41:50,360 --> 00:41:53,660
even just multiply two eight digit
numbers computers can do that trivially

1786
00:41:53,660 --> 00:41:53,670
numbers computers can do that trivially
 

1787
00:41:53,670 --> 00:41:55,550
numbers computers can do that trivially
we can't do it so we originally started

1788
00:41:55,550 --> 00:41:55,560
we can't do it so we originally started
 

1789
00:41:55,560 --> 00:41:59,540
we can't do it so we originally started
using computers to make up for that

1790
00:41:59,540 --> 00:41:59,550
using computers to make up for that
 

1791
00:41:59,550 --> 00:42:04,160
using computers to make up for that
weakness I think the essence of what

1792
00:42:04,160 --> 00:42:04,170
weakness I think the essence of what
 

1793
00:42:04,170 --> 00:42:06,770
weakness I think the essence of what
I've been writing about is to master the

1794
00:42:06,770 --> 00:42:06,780
I've been writing about is to master the
 

1795
00:42:06,780 --> 00:42:11,110
I've been writing about is to master the
unique strengths of humanity creating

1796
00:42:11,110 --> 00:42:11,120
unique strengths of humanity creating
 

1797
00:42:11,120 --> 00:42:13,730
unique strengths of humanity creating
loving expressions in poetry and music

1798
00:42:13,730 --> 00:42:13,740
loving expressions in poetry and music
 

1799
00:42:13,740 --> 00:42:16,880
loving expressions in poetry and music
and the kinds of things we associate

1800
00:42:16,880 --> 00:42:16,890
and the kinds of things we associate
 

1801
00:42:16,890 --> 00:42:19,090
and the kinds of things we associate
with the better qualities of humanity

1802
00:42:19,090 --> 00:42:19,100
with the better qualities of humanity
 

1803
00:42:19,100 --> 00:42:22,010
with the better qualities of humanity
with machines that's the to promise of

1804
00:42:22,010 --> 00:42:22,020
with machines that's the to promise of
 

1805
00:42:22,020 --> 00:42:25,700
with machines that's the to promise of
AI that we're not there yet but we're

1806
00:42:25,700 --> 00:42:25,710
AI that we're not there yet but we're
 

1807
00:42:25,710 --> 00:42:28,550
AI that we're not there yet but we're
making pretty stunning progress just in

1808
00:42:28,550 --> 00:42:28,560
making pretty stunning progress just in
 

1809
00:42:28,560 --> 00:42:30,650
making pretty stunning progress just in
the last year there's so many milestones

1810
00:42:30,650 --> 00:42:30,660
the last year there's so many milestones
 

1811
00:42:30,660 --> 00:42:33,140
the last year there's so many milestones
that are really significant including in

1812
00:42:33,140 --> 00:42:33,150
that are really significant including in
 

1813
00:42:33,150 --> 00:42:38,840
that are really significant including in
language and but I think of technology

1814
00:42:38,840 --> 00:42:38,850
language and but I think of technology
 

1815
00:42:38,850 --> 00:42:41,930
language and but I think of technology
as an expression of humanity it's part

1816
00:42:41,930 --> 00:42:41,940
as an expression of humanity it's part
 

1817
00:42:41,940 --> 00:42:45,080
as an expression of humanity it's part
of who we are and the human species is

1818
00:42:45,080 --> 00:42:45,090
of who we are and the human species is
 

1819
00:42:45,090 --> 00:42:48,730
of who we are and the human species is
already a biological technological

1820
00:42:48,730 --> 00:42:48,740
already a biological technological
 

1821
00:42:48,740 --> 00:42:51,410
already a biological technological
civilization and it's part of who we are

1822
00:42:51,410 --> 00:42:51,420
civilization and it's part of who we are
 

1823
00:42:51,420 --> 00:42:57,020
civilization and it's part of who we are
an AI is it's part of humans so AI is

1824
00:42:57,020 --> 00:42:57,030
an AI is it's part of humans so AI is
 

1825
00:42:57,030 --> 00:42:59,930
an AI is it's part of humans so AI is
human and it's it's part of the

1826
00:42:59,930 --> 00:42:59,940
human and it's it's part of the
 

1827
00:42:59,940 --> 00:43:02,270
human and it's it's part of the
technological expression of humanity and

1828
00:43:02,270 --> 00:43:02,280
technological expression of humanity and
 

1829
00:43:02,280 --> 00:43:05,770
technological expression of humanity and
we use technology to extend our reach

1830
00:43:05,770 --> 00:43:05,780
we use technology to extend our reach
 

1831
00:43:05,780 --> 00:43:08,000
we use technology to extend our reach
you know I couldn't reach that fruit at

1832
00:43:08,000 --> 00:43:08,010
you know I couldn't reach that fruit at
 

1833
00:43:08,010 --> 00:43:09,380
you know I couldn't reach that fruit at
that higher branch a thousand years ago

1834
00:43:09,380 --> 00:43:09,390
that higher branch a thousand years ago
 

1835
00:43:09,390 --> 00:43:11,210
that higher branch a thousand years ago
so we invented a tool to extend our

1836
00:43:11,210 --> 00:43:11,220
so we invented a tool to extend our
 

1837
00:43:11,220 --> 00:43:13,820
so we invented a tool to extend our
physical reach we now extend our mental

1838
00:43:13,820 --> 00:43:13,830
physical reach we now extend our mental
 

1839
00:43:13,830 --> 00:43:16,280
physical reach we now extend our mental
reach we can access all of human

1840
00:43:16,280 --> 00:43:16,290
reach we can access all of human
 

1841
00:43:16,290 --> 00:43:21,280
reach we can access all of human
knowledge with a few keystrokes and

1842
00:43:21,280 --> 00:43:21,290
knowledge with a few keystrokes and
 

1843
00:43:21,290 --> 00:43:23,870
knowledge with a few keystrokes and
we're going to make ourselves literally

1844
00:43:23,870 --> 00:43:23,880
we're going to make ourselves literally
 

1845
00:43:23,880 --> 00:43:32,390
we're going to make ourselves literally
smarter by merging with AI hi

1846
00:43:32,390 --> 00:43:32,400
smarter by merging with AI hi
 

1847
00:43:32,400 --> 00:43:34,950
smarter by merging with AI hi
first of all honor to hear you speak

1848
00:43:34,950 --> 00:43:34,960
first of all honor to hear you speak
 

1849
00:43:34,960 --> 00:43:38,670
first of all honor to hear you speak
here so I first read The Singularity is

1850
00:43:38,670 --> 00:43:38,680
here so I first read The Singularity is
 

1851
00:43:38,680 --> 00:43:42,870
here so I first read The Singularity is
near nine years ago or so and it changed

1852
00:43:42,870 --> 00:43:42,880
near nine years ago or so and it changed
 

1853
00:43:42,880 --> 00:43:45,900
near nine years ago or so and it changed
the way I thought entirely but something

1854
00:43:45,900 --> 00:43:45,910
the way I thought entirely but something
 

1855
00:43:45,910 --> 00:43:50,400
the way I thought entirely but something
I think it caused me to over steeply

1856
00:43:50,400 --> 00:43:50,410
I think it caused me to over steeply
 

1857
00:43:50,410 --> 00:43:56,720
I think it caused me to over steeply
discount was tail risk in geopolitics in

1858
00:43:56,720 --> 00:43:56,730
discount was tail risk in geopolitics in
 

1859
00:43:56,730 --> 00:44:01,470
discount was tail risk in geopolitics in
systems that span the entire globe and

1860
00:44:01,470 --> 00:44:01,480
systems that span the entire globe and
 

1861
00:44:01,480 --> 00:44:07,320
systems that span the entire globe and
my concern is that there are there is

1862
00:44:07,320 --> 00:44:07,330
my concern is that there are there is
 

1863
00:44:07,330 --> 00:44:12,200
my concern is that there are there is
obviously the possibility of tail risk

1864
00:44:12,200 --> 00:44:12,210
obviously the possibility of tail risk
 

1865
00:44:12,210 --> 00:44:15,930
obviously the possibility of tail risk
existential level events swamp in all of

1866
00:44:15,930 --> 00:44:15,940
existential level events swamp in all of
 

1867
00:44:15,940 --> 00:44:19,440
existential level events swamp in all of
these trends that are otherwise war

1868
00:44:19,440 --> 00:44:19,450
these trends that are otherwise war
 

1869
00:44:19,450 --> 00:44:22,770
these trends that are otherwise war
proof climate proof you name it so my

1870
00:44:22,770 --> 00:44:22,780
proof climate proof you name it so my
 

1871
00:44:22,780 --> 00:44:26,250
proof climate proof you name it so my
question for you is what steps do you

1872
00:44:26,250 --> 00:44:26,260
question for you is what steps do you
 

1873
00:44:26,260 --> 00:44:29,430
question for you is what steps do you
think we can take in designing

1874
00:44:29,430 --> 00:44:29,440
think we can take in designing
 

1875
00:44:29,440 --> 00:44:33,000
think we can take in designing
engineered systems in designing social

1876
00:44:33,000 --> 00:44:33,010
engineered systems in designing social
 

1877
00:44:33,010 --> 00:44:35,790
engineered systems in designing social
and economic institutions to kind of

1878
00:44:35,790 --> 00:44:35,800
and economic institutions to kind of
 

1879
00:44:35,800 --> 00:44:38,910
and economic institutions to kind of
minimize our exposure to these tail

1880
00:44:38,910 --> 00:44:38,920
minimize our exposure to these tail
 

1881
00:44:38,920 --> 00:44:42,360
minimize our exposure to these tail
risks and and and survive to make it to

1882
00:44:42,360 --> 00:44:42,370
risks and and and survive to make it to
 

1883
00:44:42,370 --> 00:44:46,530
risks and and and survive to make it to
UM you know a beautiful mind filled

1884
00:44:46,530 --> 00:44:46,540
UM you know a beautiful mind filled
 

1885
00:44:46,540 --> 00:44:53,160
UM you know a beautiful mind filled
future yeah well the world was first

1886
00:44:53,160 --> 00:44:53,170
future yeah well the world was first
 

1887
00:44:53,170 --> 00:44:55,670
future yeah well the world was first
introduced to a human-made

1888
00:44:55,670 --> 00:44:55,680
introduced to a human-made
 

1889
00:44:55,680 --> 00:44:58,890
introduced to a human-made
existential risk when I was in

1890
00:44:58,890 --> 00:44:58,900
existential risk when I was in
 

1891
00:44:58,900 --> 00:45:00,660
existential risk when I was in
elementary school we would have these

1892
00:45:00,660 --> 00:45:00,670
elementary school we would have these
 

1893
00:45:00,670 --> 00:45:02,790
elementary school we would have these
civil defense drills to get under our

1894
00:45:02,790 --> 00:45:02,800
civil defense drills to get under our
 

1895
00:45:02,800 --> 00:45:04,320
civil defense drills to get under our
desk and put our hands behind our head

1896
00:45:04,320 --> 00:45:04,330
desk and put our hands behind our head
 

1897
00:45:04,330 --> 00:45:07,880
desk and put our hands behind our head
to protect this from a thermonuclear war

1898
00:45:07,880 --> 00:45:07,890
to protect this from a thermonuclear war
 

1899
00:45:07,890 --> 00:45:13,290
to protect this from a thermonuclear war
and it worked we made it through but

1900
00:45:13,290 --> 00:45:13,300
and it worked we made it through but
 

1901
00:45:13,300 --> 00:45:15,150
and it worked we made it through but
that was really the first introduction

1902
00:45:15,150 --> 00:45:15,160
that was really the first introduction
 

1903
00:45:15,160 --> 00:45:19,260
that was really the first introduction
to an existential risk and those weapons

1904
00:45:19,260 --> 00:45:19,270
to an existential risk and those weapons
 

1905
00:45:19,270 --> 00:45:21,330
to an existential risk and those weapons
are still there by the way and they're

1906
00:45:21,330 --> 00:45:21,340
are still there by the way and they're
 

1907
00:45:21,340 --> 00:45:24,330
are still there by the way and they're
still on a hair-trigger and they don't

1908
00:45:24,330 --> 00:45:24,340
still on a hair-trigger and they don't
 

1909
00:45:24,340 --> 00:45:27,240
still on a hair-trigger and they don't
get that much attention there's been a

1910
00:45:27,240 --> 00:45:27,250
get that much attention there's been a
 

1911
00:45:27,250 --> 00:45:30,120
get that much attention there's been a
lot of discussion much of which I've

1912
00:45:30,120 --> 00:45:30,130
lot of discussion much of which I've
 

1913
00:45:30,130 --> 00:45:32,340
lot of discussion much of which I've
been in the forefront of initiating the

1914
00:45:32,340 --> 00:45:32,350
been in the forefront of initiating the
 

1915
00:45:32,350 --> 00:45:34,860
been in the forefront of initiating the
existential risks of what sometimes

1916
00:45:34,860 --> 00:45:34,870
existential risks of what sometimes
 

1917
00:45:34,870 --> 00:45:38,160
existential risks of what sometimes
referred to as GN rg4 genetics which is

1918
00:45:38,160 --> 00:45:38,170
referred to as GN rg4 genetics which is
 

1919
00:45:38,170 --> 00:45:40,530
referred to as GN rg4 genetics which is
biotechnology and for nanotechnology and

1920
00:45:40,530 --> 00:45:40,540
biotechnology and for nanotechnology and
 

1921
00:45:40,540 --> 00:45:44,160
biotechnology and for nanotechnology and
gray goo robotics which is a

1922
00:45:44,160 --> 00:45:44,170
gray goo robotics which is a
 

1923
00:45:44,170 --> 00:45:47,230
gray goo robotics which is a
and I've been accused of being an

1924
00:45:47,230 --> 00:45:47,240
and I've been accused of being an
 

1925
00:45:47,240 --> 00:45:49,390
and I've been accused of being an
optimist I think you have to be an

1926
00:45:49,390 --> 00:45:49,400
optimist I think you have to be an
 

1927
00:45:49,400 --> 00:45:51,400
optimist I think you have to be an
optimist to be an entrepreneur if you

1928
00:45:51,400 --> 00:45:51,410
optimist to be an entrepreneur if you
 

1929
00:45:51,410 --> 00:45:53,079
optimist to be an entrepreneur if you
knew all the problems you were going to

1930
00:45:53,079 --> 00:45:53,089
knew all the problems you were going to
 

1931
00:45:53,089 --> 00:45:55,089
knew all the problems you were going to
encounter you'd never start any project

1932
00:45:55,089 --> 00:45:55,099
encounter you'd never start any project
 

1933
00:45:55,099 --> 00:45:59,200
encounter you'd never start any project
but I've written a lot about the

1934
00:45:59,200 --> 00:45:59,210
but I've written a lot about the
 

1935
00:45:59,210 --> 00:46:03,540
but I've written a lot about the
downsides I remain optimistic there are

1936
00:46:03,540 --> 00:46:03,550
downsides I remain optimistic there are
 

1937
00:46:03,550 --> 00:46:06,280
downsides I remain optimistic there are
specific paradigms and not foolproof

1938
00:46:06,280 --> 00:46:06,290
specific paradigms and not foolproof
 

1939
00:46:06,290 --> 00:46:08,079
specific paradigms and not foolproof
that we can follow to keep these

1940
00:46:08,079 --> 00:46:08,089
that we can follow to keep these
 

1941
00:46:08,089 --> 00:46:12,670
that we can follow to keep these
technologies safe so for example over 40

1942
00:46:12,670 --> 00:46:12,680
technologies safe so for example over 40
 

1943
00:46:12,680 --> 00:46:15,099
technologies safe so for example over 40
years ago some visionaries recognized

1944
00:46:15,099 --> 00:46:15,109
years ago some visionaries recognized
 

1945
00:46:15,109 --> 00:46:18,460
years ago some visionaries recognized
the revolutionary potential both for

1946
00:46:18,460 --> 00:46:18,470
the revolutionary potential both for
 

1947
00:46:18,470 --> 00:46:21,660
the revolutionary potential both for
promise and peril of biotechnology

1948
00:46:21,660 --> 00:46:21,670
promise and peril of biotechnology
 

1949
00:46:21,670 --> 00:46:23,980
promise and peril of biotechnology
neither the promise no peril was

1950
00:46:23,980 --> 00:46:23,990
neither the promise no peril was
 

1951
00:46:23,990 --> 00:46:27,130
neither the promise no peril was
feasible 40 years ago but they had a

1952
00:46:27,130 --> 00:46:27,140
feasible 40 years ago but they had a
 

1953
00:46:27,140 --> 00:46:29,079
feasible 40 years ago but they had a
conference at the Asilomar conference

1954
00:46:29,079 --> 00:46:29,089
conference at the Asilomar conference
 

1955
00:46:29,089 --> 00:46:33,930
conference at the Asilomar conference
center in California and to develop both

1956
00:46:33,930 --> 00:46:33,940
center in California and to develop both
 

1957
00:46:33,940 --> 00:46:36,520
center in California and to develop both
professional ethics and strategies to

1958
00:46:36,520 --> 00:46:36,530
professional ethics and strategies to
 

1959
00:46:36,530 --> 00:46:39,220
professional ethics and strategies to
keep biotechnology safe and they've been

1960
00:46:39,220 --> 00:46:39,230
keep biotechnology safe and they've been
 

1961
00:46:39,230 --> 00:46:41,380
keep biotechnology safe and they've been
known as the Asilomar guidelines they've

1962
00:46:41,380 --> 00:46:41,390
known as the Asilomar guidelines they've
 

1963
00:46:41,390 --> 00:46:44,710
known as the Asilomar guidelines they've
been refined through successive sell

1964
00:46:44,710 --> 00:46:44,720
been refined through successive sell
 

1965
00:46:44,720 --> 00:46:46,780
been refined through successive sell
more conferences much of that's baked

1966
00:46:46,780 --> 00:46:46,790
more conferences much of that's baked
 

1967
00:46:46,790 --> 00:46:50,170
more conferences much of that's baked
into law and it in my opinion it's

1968
00:46:50,170 --> 00:46:50,180
into law and it in my opinion it's
 

1969
00:46:50,180 --> 00:46:51,790
into law and it in my opinion it's
worked quite well we're now as I

1970
00:46:51,790 --> 00:46:51,800
worked quite well we're now as I
 

1971
00:46:51,800 --> 00:46:54,220
worked quite well we're now as I
mentioned getting profound benefit it's

1972
00:46:54,220 --> 00:46:54,230
mentioned getting profound benefit it's
 

1973
00:46:54,230 --> 00:46:56,859
mentioned getting profound benefit it's
a trickle today it'll be a flood over

1974
00:46:56,859 --> 00:46:56,869
a trickle today it'll be a flood over
 

1975
00:46:56,869 --> 00:46:59,050
a trickle today it'll be a flood over
the next decade and the number of people

1976
00:46:59,050 --> 00:46:59,060
the next decade and the number of people
 

1977
00:46:59,060 --> 00:47:01,240
the next decade and the number of people
who have been harmed either through

1978
00:47:01,240 --> 00:47:01,250
who have been harmed either through
 

1979
00:47:01,250 --> 00:47:03,460
who have been harmed either through
intentional or accidental abuse of

1980
00:47:03,460 --> 00:47:03,470
intentional or accidental abuse of
 

1981
00:47:03,470 --> 00:47:06,460
intentional or accidental abuse of
biotechnology so far zero actually I

1982
00:47:06,460 --> 00:47:06,470
biotechnology so far zero actually I
 

1983
00:47:06,470 --> 00:47:08,170
biotechnology so far zero actually I
take that back there was one boy who

1984
00:47:08,170 --> 00:47:08,180
take that back there was one boy who
 

1985
00:47:08,180 --> 00:47:11,950
take that back there was one boy who
died in gene therapy trials but 12 years

1986
00:47:11,950 --> 00:47:11,960
died in gene therapy trials but 12 years
 

1987
00:47:11,960 --> 00:47:13,630
died in gene therapy trials but 12 years
ago and there's congressional hearings

1988
00:47:13,630 --> 00:47:13,640
ago and there's congressional hearings
 

1989
00:47:13,640 --> 00:47:18,130
ago and there's congressional hearings
and they cancelled all research for gene

1990
00:47:18,130 --> 00:47:18,140
and they cancelled all research for gene
 

1991
00:47:18,140 --> 00:47:20,890
and they cancelled all research for gene
therapy for a number of years you could

1992
00:47:20,890 --> 00:47:20,900
therapy for a number of years you could
 

1993
00:47:20,900 --> 00:47:22,960
therapy for a number of years you could
do an interesting master's thesis and

1994
00:47:22,960 --> 00:47:22,970
do an interesting master's thesis and
 

1995
00:47:22,970 --> 00:47:25,120
do an interesting master's thesis and
demonstrate that you know 300,000 people

1996
00:47:25,120 --> 00:47:25,130
demonstrate that you know 300,000 people
 

1997
00:47:25,130 --> 00:47:27,490
demonstrate that you know 300,000 people
died as a result of that delay but you

1998
00:47:27,490 --> 00:47:27,500
died as a result of that delay but you
 

1999
00:47:27,500 --> 00:47:29,740
died as a result of that delay but you
can't name them they can't go on CNN so

2000
00:47:29,740 --> 00:47:29,750
can't name them they can't go on CNN so
 

2001
00:47:29,750 --> 00:47:32,770
can't name them they can't go on CNN so
we don't know who they are but it has to

2002
00:47:32,770 --> 00:47:32,780
we don't know who they are but it has to
 

2003
00:47:32,780 --> 00:47:35,440
we don't know who they are but it has to
do with the balancing of risk but in

2004
00:47:35,440 --> 00:47:35,450
do with the balancing of risk but in
 

2005
00:47:35,450 --> 00:47:37,780
do with the balancing of risk but in
large measure virtually no one has been

2006
00:47:37,780 --> 00:47:37,790
large measure virtually no one has been
 

2007
00:47:37,790 --> 00:47:39,970
large measure virtually no one has been
hurt by biotechnology now that doesn't

2008
00:47:39,970 --> 00:47:39,980
hurt by biotechnology now that doesn't
 

2009
00:47:39,980 --> 00:47:41,230
hurt by biotechnology now that doesn't
mean you can cross on our front list

2010
00:47:41,230 --> 00:47:41,240
mean you can cross on our front list
 

2011
00:47:41,240 --> 00:47:43,900
mean you can cross on our front list
okay we took care of that one because

2012
00:47:43,900 --> 00:47:43,910
okay we took care of that one because
 

2013
00:47:43,910 --> 00:47:45,640
okay we took care of that one because
the technology keeps getting more

2014
00:47:45,640 --> 00:47:45,650
the technology keeps getting more
 

2015
00:47:45,650 --> 00:47:48,220
the technology keeps getting more
sophisticated and Christopher's great

2016
00:47:48,220 --> 00:47:48,230
sophisticated and Christopher's great
 

2017
00:47:48,230 --> 00:47:51,160
sophisticated and Christopher's great
opportunity there's hundreds of trials

2018
00:47:51,160 --> 00:47:51,170
opportunity there's hundreds of trials
 

2019
00:47:51,170 --> 00:47:53,859
opportunity there's hundreds of trials
of Christopher's technologies overcome

2020
00:47:53,859 --> 00:47:53,869
of Christopher's technologies overcome
 

2021
00:47:53,869 --> 00:47:56,770
of Christopher's technologies overcome
disease but it could be abused you can

2022
00:47:56,770 --> 00:47:56,780
disease but it could be abused you can
 

2023
00:47:56,780 --> 00:47:59,410
disease but it could be abused you can
describe scenarios so we have to keep

2024
00:47:59,410 --> 00:47:59,420
describe scenarios so we have to keep
 

2025
00:47:59,420 --> 00:48:02,800
describe scenarios so we have to keep
reinventing it January we had our first

2026
00:48:02,800 --> 00:48:02,810
reinventing it January we had our first
 

2027
00:48:02,810 --> 00:48:06,610
reinventing it January we had our first
Asilomar conference on AI ethics and so

2028
00:48:06,610 --> 00:48:06,620
Asilomar conference on AI ethics and so
 

2029
00:48:06,620 --> 00:48:08,380
Asilomar conference on AI ethics and so
I think this is a good paradigm it's not

2030
00:48:08,380 --> 00:48:08,390
I think this is a good paradigm it's not
 

2031
00:48:08,390 --> 00:48:14,380
I think this is a good paradigm it's not
foolproof I think the best way we can

2032
00:48:14,380 --> 00:48:14,390
foolproof I think the best way we can
 

2033
00:48:14,390 --> 00:48:18,880
foolproof I think the best way we can
assure a democratic future that includes

2034
00:48:18,880 --> 00:48:18,890
assure a democratic future that includes
 

2035
00:48:18,890 --> 00:48:21,040
assure a democratic future that includes
our ideas of Liberty is to practice that

2036
00:48:21,040 --> 00:48:21,050
our ideas of Liberty is to practice that
 

2037
00:48:21,050 --> 00:48:23,080
our ideas of Liberty is to practice that
in the world today because the future

2038
00:48:23,080 --> 00:48:23,090
in the world today because the future
 

2039
00:48:23,090 --> 00:48:25,120
in the world today because the future
world of the singularity which is a

2040
00:48:25,120 --> 00:48:25,130
world of the singularity which is a
 

2041
00:48:25,130 --> 00:48:27,760
world of the singularity which is a
merger of biological non-biological

2042
00:48:27,760 --> 00:48:27,770
merger of biological non-biological
 

2043
00:48:27,770 --> 00:48:30,310
merger of biological non-biological
intelligence it's not going to come from

2044
00:48:30,310 --> 00:48:30,320
intelligence it's not going to come from
 

2045
00:48:30,320 --> 00:48:32,080
intelligence it's not going to come from
Mars I mean it's going to emerge from

2046
00:48:32,080 --> 00:48:32,090
Mars I mean it's going to emerge from
 

2047
00:48:32,090 --> 00:48:34,960
Mars I mean it's going to emerge from
our society today so if we practice

2048
00:48:34,960 --> 00:48:34,970
our society today so if we practice
 

2049
00:48:34,970 --> 00:48:37,300
our society today so if we practice
these ideals today it's going to have a

2050
00:48:37,300 --> 00:48:37,310
these ideals today it's going to have a
 

2051
00:48:37,310 --> 00:48:39,340
these ideals today it's going to have a
higher chance of us practicing them as

2052
00:48:39,340 --> 00:48:39,350
higher chance of us practicing them as
 

2053
00:48:39,350 --> 00:48:42,730
higher chance of us practicing them as
we get more enhanced with technology if

2054
00:48:42,730 --> 00:48:42,740
we get more enhanced with technology if
 

2055
00:48:42,740 --> 00:48:44,440
we get more enhanced with technology if
that doesn't sound like a foolproof

2056
00:48:44,440 --> 00:48:44,450
that doesn't sound like a foolproof
 

2057
00:48:44,450 --> 00:48:46,960
that doesn't sound like a foolproof
solution it isn't but I think that's the

2058
00:48:46,960 --> 00:48:46,970
solution it isn't but I think that's the
 

2059
00:48:46,970 --> 00:48:49,120
solution it isn't but I think that's the
best approach in terms of technological

2060
00:48:49,120 --> 00:48:49,130
best approach in terms of technological
 

2061
00:48:49,130 --> 00:48:50,140
best approach in terms of technological
solutions

2062
00:48:50,140 --> 00:48:50,150
solutions
 

2063
00:48:50,150 --> 00:48:52,750
solutions
I mean AI is the most daunting you can

2064
00:48:52,750 --> 00:48:52,760
I mean AI is the most daunting you can
 

2065
00:48:52,760 --> 00:48:56,970
I mean AI is the most daunting you can
imagine there are technical solutions to

2066
00:48:56,970 --> 00:48:56,980
imagine there are technical solutions to
 

2067
00:48:56,980 --> 00:49:00,400
imagine there are technical solutions to
biotechnology and nanotechnology there's

2068
00:49:00,400 --> 00:49:00,410
biotechnology and nanotechnology there's
 

2069
00:49:00,410 --> 00:49:02,460
biotechnology and nanotechnology there's
really no subroutine you can put in your

2070
00:49:02,460 --> 00:49:02,470
really no subroutine you can put in your
 

2071
00:49:02,470 --> 00:49:06,310
really no subroutine you can put in your
AI software there will assure that it

2072
00:49:06,310 --> 00:49:06,320
AI software there will assure that it
 

2073
00:49:06,320 --> 00:49:08,380
AI software there will assure that it
remains safe intelligence it's

2074
00:49:08,380 --> 00:49:08,390
remains safe intelligence it's
 

2075
00:49:08,390 --> 00:49:10,080
remains safe intelligence it's
inherently not controllable

2076
00:49:10,080 --> 00:49:10,090
inherently not controllable
 

2077
00:49:10,090 --> 00:49:12,790
inherently not controllable
there's some AI that's much smarter than

2078
00:49:12,790 --> 00:49:12,800
there's some AI that's much smarter than
 

2079
00:49:12,800 --> 00:49:15,220
there's some AI that's much smarter than
you that's out for your destruction the

2080
00:49:15,220 --> 00:49:15,230
you that's out for your destruction the
 

2081
00:49:15,230 --> 00:49:16,990
you that's out for your destruction the
best way to deal with that is not to get

2082
00:49:16,990 --> 00:49:17,000
best way to deal with that is not to get
 

2083
00:49:17,000 --> 00:49:20,500
best way to deal with that is not to get
in that situation in the first place if

2084
00:49:20,500 --> 00:49:20,510
in that situation in the first place if
 

2085
00:49:20,510 --> 00:49:22,540
in that situation in the first place if
if you are in that situation and find

2086
00:49:22,540 --> 00:49:22,550
if you are in that situation and find
 

2087
00:49:22,550 --> 00:49:25,920
if you are in that situation and find
some AI that will be on your side but

2088
00:49:25,920 --> 00:49:25,930
some AI that will be on your side but
 

2089
00:49:25,930 --> 00:49:29,890
some AI that will be on your side but
basically it's going to eyeb Aleve

2090
00:49:29,890 --> 00:49:29,900
basically it's going to eyeb Aleve
 

2091
00:49:29,900 --> 00:49:32,250
basically it's going to eyeb Aleve
we have been headed through technology

2092
00:49:32,250 --> 00:49:32,260
we have been headed through technology
 

2093
00:49:32,260 --> 00:49:37,060
we have been headed through technology
to event to a better reality look around

2094
00:49:37,060 --> 00:49:37,070
to event to a better reality look around
 

2095
00:49:37,070 --> 00:49:38,380
to event to a better reality look around
the world and people really think things

2096
00:49:38,380 --> 00:49:38,390
the world and people really think things
 

2097
00:49:38,390 --> 00:49:41,290
the world and people really think things
are getting worse and I think that's

2098
00:49:41,290 --> 00:49:41,300
are getting worse and I think that's
 

2099
00:49:41,300 --> 00:49:42,670
are getting worse and I think that's
because our information about what's

2100
00:49:42,670 --> 00:49:42,680
because our information about what's
 

2101
00:49:42,680 --> 00:49:43,930
because our information about what's
wrong with the world is getting

2102
00:49:43,930 --> 00:49:43,940
wrong with the world is getting
 

2103
00:49:43,940 --> 00:49:46,630
wrong with the world is getting
exponentially better I say oh this is

2104
00:49:46,630 --> 00:49:46,640
exponentially better I say oh this is
 

2105
00:49:46,640 --> 00:49:48,130
exponentially better I say oh this is
the most peaceful time on you in history

2106
00:49:48,130 --> 00:49:48,140
the most peaceful time on you in history
 

2107
00:49:48,140 --> 00:49:50,380
the most peaceful time on you in history
if you say what are you crazy didn't you

2108
00:49:50,380 --> 00:49:50,390
if you say what are you crazy didn't you
 

2109
00:49:50,390 --> 00:49:52,030
if you say what are you crazy didn't you
hear about the event yesterday and last

2110
00:49:52,030 --> 00:49:52,040
hear about the event yesterday and last
 

2111
00:49:52,040 --> 00:49:55,780
hear about the event yesterday and last
week and well a hundred years ago there

2112
00:49:55,780 --> 00:49:55,790
week and well a hundred years ago there
 

2113
00:49:55,790 --> 00:49:57,070
week and well a hundred years ago there
could be a battle that wiped out the

2114
00:49:57,070 --> 00:49:57,080
could be a battle that wiped out the
 

2115
00:49:57,080 --> 00:49:58,510
could be a battle that wiped out the
next village in you wouldn't even hear

2116
00:49:58,510 --> 00:49:58,520
next village in you wouldn't even hear
 

2117
00:49:58,520 --> 00:50:00,410
next village in you wouldn't even hear
about it for months

2118
00:50:00,410 --> 00:50:00,420
about it for months
 

2119
00:50:00,420 --> 00:50:04,130
about it for months
of all these graphs on education and

2120
00:50:04,130 --> 00:50:04,140
of all these graphs on education and
 

2121
00:50:04,140 --> 00:50:07,690
of all these graphs on education and
literacy has gone from like 10% to 90%

2122
00:50:07,690 --> 00:50:07,700
literacy has gone from like 10% to 90%
 

2123
00:50:07,700 --> 00:50:15,790
literacy has gone from like 10% to 90%
over a century and health wealth

2124
00:50:15,790 --> 00:50:15,800
over a century and health wealth
 

2125
00:50:15,800 --> 00:50:20,000
over a century and health wealth
poverty's declined 95% in Asia over the

2126
00:50:20,000 --> 00:50:20,010
poverty's declined 95% in Asia over the
 

2127
00:50:20,010 --> 00:50:22,610
poverty's declined 95% in Asia over the
last 25 years document about the World

2128
00:50:22,610 --> 00:50:22,620
last 25 years document about the World
 

2129
00:50:22,620 --> 00:50:25,070
last 25 years document about the World
Bank all these trends are very smoothly

2130
00:50:25,070 --> 00:50:25,080
Bank all these trends are very smoothly
 

2131
00:50:25,080 --> 00:50:26,480
Bank all these trends are very smoothly
getting better and everybody thinks

2132
00:50:26,480 --> 00:50:26,490
getting better and everybody thinks
 

2133
00:50:26,490 --> 00:50:28,910
getting better and everybody thinks
things are getting worse but but but

2134
00:50:28,910 --> 00:50:28,920
things are getting worse but but but
 

2135
00:50:28,920 --> 00:50:31,760
things are getting worse but but but
you're right like on violence that curve

2136
00:50:31,760 --> 00:50:31,770
you're right like on violence that curve
 

2137
00:50:31,770 --> 00:50:35,390
you're right like on violence that curve
could be quite disrupted there's an

2138
00:50:35,390 --> 00:50:35,400
could be quite disrupted there's an
 

2139
00:50:35,400 --> 00:50:39,200
could be quite disrupted there's an
existential event as I say I'm

2140
00:50:39,200 --> 00:50:39,210
existential event as I say I'm
 

2141
00:50:39,210 --> 00:50:41,330
existential event as I say I'm
optimistic but I think that is something

2142
00:50:41,330 --> 00:50:41,340
optimistic but I think that is something
 

2143
00:50:41,340 --> 00:50:44,780
optimistic but I think that is something
if we need to deal with that a lot of it

2144
00:50:44,780 --> 00:50:44,790
if we need to deal with that a lot of it
 

2145
00:50:44,790 --> 00:50:46,520
if we need to deal with that a lot of it
is not technological it's dealing with

2146
00:50:46,520 --> 00:50:46,530
is not technological it's dealing with
 

2147
00:50:46,530 --> 00:50:52,400
is not technological it's dealing with
our social cultural institutions so you

2148
00:50:52,400 --> 00:50:52,410
our social cultural institutions so you
 

2149
00:50:52,410 --> 00:50:54,470
our social cultural institutions so you
mentioned also exponential growth of

2150
00:50:54,470 --> 00:50:54,480
mentioned also exponential growth of
 

2151
00:50:54,480 --> 00:50:57,050
mentioned also exponential growth of
software and IDs I guess related to

2152
00:50:57,050 --> 00:50:57,060
software and IDs I guess related to
 

2153
00:50:57,060 --> 00:50:59,600
software and IDs I guess related to
software so one of the reasons for which

2154
00:50:59,600 --> 00:50:59,610
software so one of the reasons for which
 

2155
00:50:59,610 --> 00:51:01,430
software so one of the reasons for which
you said that all that information

2156
00:51:01,430 --> 00:51:01,440
you said that all that information
 

2157
00:51:01,440 --> 00:51:03,380
you said that all that information
technology costs this exponential is

2158
00:51:03,380 --> 00:51:03,390
technology costs this exponential is
 

2159
00:51:03,390 --> 00:51:05,030
technology costs this exponential is
because of fundamental properties of

2160
00:51:05,030 --> 00:51:05,040
because of fundamental properties of
 

2161
00:51:05,040 --> 00:51:07,670
because of fundamental properties of
matter and energy but in the case of

2162
00:51:07,670 --> 00:51:07,680
matter and energy but in the case of
 

2163
00:51:07,680 --> 00:51:09,200
matter and energy but in the case of
ideas why would it have to be

2164
00:51:09,200 --> 00:51:09,210
ideas why would it have to be
 

2165
00:51:09,210 --> 00:51:12,740
ideas why would it have to be
exponential well a lot of ideas produce

2166
00:51:12,740 --> 00:51:12,750
exponential well a lot of ideas produce
 

2167
00:51:12,750 --> 00:51:16,810
exponential well a lot of ideas produce
exponential gains they don't increase

2168
00:51:16,810 --> 00:51:16,820
exponential gains they don't increase
 

2169
00:51:16,820 --> 00:51:19,340
exponential gains they don't increase
performance linearly there's actually

2170
00:51:19,340 --> 00:51:19,350
performance linearly there's actually
 

2171
00:51:19,350 --> 00:51:22,100
performance linearly there's actually
study during the Obama administration by

2172
00:51:22,100 --> 00:51:22,110
study during the Obama administration by
 

2173
00:51:22,110 --> 00:51:24,790
study during the Obama administration by
his scientific advisory board on

2174
00:51:24,790 --> 00:51:24,800
his scientific advisory board on
 

2175
00:51:24,800 --> 00:51:28,130
his scientific advisory board on
assessing this question how much gains

2176
00:51:28,130 --> 00:51:28,140
assessing this question how much gains
 

2177
00:51:28,140 --> 00:51:32,770
assessing this question how much gains
on 23 classical engineering problems

2178
00:51:32,770 --> 00:51:32,780
on 23 classical engineering problems
 

2179
00:51:32,780 --> 00:51:35,510
on 23 classical engineering problems
were gained through hardware

2180
00:51:35,510 --> 00:51:35,520
were gained through hardware
 

2181
00:51:35,520 --> 00:51:37,940
were gained through hardware
improvements over the last decade and

2182
00:51:37,940 --> 00:51:37,950
improvements over the last decade and
 

2183
00:51:37,950 --> 00:51:39,380
improvements over the last decade and
software improvements and there's about

2184
00:51:39,380 --> 00:51:39,390
software improvements and there's about
 

2185
00:51:39,390 --> 00:51:41,780
software improvements and there's about
a thousand to one improvement it's about

2186
00:51:41,780 --> 00:51:41,790
a thousand to one improvement it's about
 

2187
00:51:41,790 --> 00:51:44,180
a thousand to one improvement it's about
doubling every year from Hardware there

2188
00:51:44,180 --> 00:51:44,190
doubling every year from Hardware there
 

2189
00:51:44,190 --> 00:51:45,860
doubling every year from Hardware there
was an averages of like twenty six

2190
00:51:45,860 --> 00:51:45,870
was an averages of like twenty six
 

2191
00:51:45,870 --> 00:51:48,230
was an averages of like twenty six
thousand to one through softer

2192
00:51:48,230 --> 00:51:48,240
thousand to one through softer
 

2193
00:51:48,240 --> 00:51:52,900
thousand to one through softer
improvements algorithmic improvements so

2194
00:51:52,900 --> 00:51:52,910
improvements algorithmic improvements so
 

2195
00:51:52,910 --> 00:51:56,240
improvements algorithmic improvements so
we do see both and apparently if you

2196
00:51:56,240 --> 00:51:56,250
we do see both and apparently if you
 

2197
00:51:56,250 --> 00:51:58,790
we do see both and apparently if you
come up with in advance its it doubles

2198
00:51:58,790 --> 00:51:58,800
come up with in advance its it doubles
 

2199
00:51:58,800 --> 00:52:01,340
come up with in advance its it doubles
the performance or multiplies it by ten

2200
00:52:01,340 --> 00:52:01,350
the performance or multiplies it by ten
 

2201
00:52:01,350 --> 00:52:03,710
the performance or multiplies it by ten
we see basically exponential growth from

2202
00:52:03,710 --> 00:52:03,720
we see basically exponential growth from
 

2203
00:52:03,720 --> 00:52:07,180
we see basically exponential growth from
each innovation

2204
00:52:07,180 --> 00:52:07,190

 

2205
00:52:07,190 --> 00:52:09,550

so and we certainly see that in deep

2206
00:52:09,550 --> 00:52:09,560
so and we certainly see that in deep
 

2207
00:52:09,560 --> 00:52:12,580
so and we certainly see that in deep
learning the architectures are getting

2208
00:52:12,580 --> 00:52:12,590
learning the architectures are getting
 

2209
00:52:12,590 --> 00:52:13,180
learning the architectures are getting
better

2210
00:52:13,180 --> 00:52:13,190
better
 

2211
00:52:13,190 --> 00:52:15,190
better
while we also have more data and more

2212
00:52:15,190 --> 00:52:15,200
while we also have more data and more
 

2213
00:52:15,200 --> 00:52:17,320
while we also have more data and more
computation and more memory to throw in

2214
00:52:17,320 --> 00:52:17,330
computation and more memory to throw in
 

2215
00:52:17,330 --> 00:52:25,790
computation and more memory to throw in
these at these algorithms

2216
00:52:25,790 --> 00:52:25,800

 

2217
00:52:25,800 --> 00:52:28,580

thank you for being

